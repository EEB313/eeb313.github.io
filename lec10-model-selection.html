<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EEB313: Quantitative Methods in R for Biology - 12&nbsp; Model selection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./lec11-multivariate-stats.html" rel="next">
<link href="./lec09-mixed-effects-models.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./lec00-rstudio.html">Lectures</a></li><li class="breadcrumb-item"><a href="./lec10-model-selection.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model selection</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">EEB313: Quantitative Methods in R for Biology</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/EEB313/eeb313.github.io" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Syllabus</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about-us.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The 2023 teaching team</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./downloadingR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Downloading R</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec00-rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Getting started with RStudio and R Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec01-markdown-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Markdown, project workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec02-base-r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Base R: assignment, vectors, functions, and loops</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec03-dataframes-dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data frames, intro to dplyr</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec04-data-wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data wrangling in dplyr</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec05-data-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data visualization in ggplot</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec06-exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploratory data analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec07-intro-to-stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec08-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec09-mixed-effects-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Linear mixed models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec10-model-selection.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec11-multivariate-stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multivariate statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec12-command-line_git.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Command line &amp; Git(Hub)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec14-mathematical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Mathematical modeling I</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec15-mathematical-models-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Mathematical modeling II</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Assignment 01</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Assignment 02</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment-03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Assignment 03</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment-04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Assignment 04</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment-05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Assignment 05</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Project description</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./databases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Some open-access databases</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Miscellaneous notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tests-assignment-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">More on hypothesis testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./power-analysis-practice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Power analysis practice</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lesson-preamble" id="toc-lesson-preamble" class="nav-link active" data-scroll-target="#lesson-preamble"><span class="header-section-number">12.1</span> Lesson preamble</a></li>
  <li><a href="#model-selection-theory" id="toc-model-selection-theory" class="nav-link" data-scroll-target="#model-selection-theory"><span class="header-section-number">12.2</span> Model selection: theory</a>
  <ul class="collapse">
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="header-section-number">12.2.1</span> Examples</a></li>
  </ul></li>
  <li><a href="#common-model-selection-techniques" id="toc-common-model-selection-techniques" class="nav-link" data-scroll-target="#common-model-selection-techniques"><span class="header-section-number">12.3</span> Common model selection techniques</a>
  <ul class="collapse">
  <li><a href="#the-akaike-information-criterion-aic" id="toc-the-akaike-information-criterion-aic" class="nav-link" data-scroll-target="#the-akaike-information-criterion-aic"><span class="header-section-number">12.3.1</span> The Akaike information criterion (AIC)</a></li>
  <li><a href="#textaic_c-for-small-sample-sizes" id="toc-textaic_c-for-small-sample-sizes" class="nav-link" data-scroll-target="#textaic_c-for-small-sample-sizes"><span class="header-section-number">12.3.2</span> <span class="math inline">\(\text{AIC}_c\)</span> for small sample sizes</a></li>
  </ul></li>
  <li><a href="#stepwise-and-regularized-regression" id="toc-stepwise-and-regularized-regression" class="nav-link" data-scroll-target="#stepwise-and-regularized-regression"><span class="header-section-number">12.4</span> Stepwise and regularized regression</a></li>
  <li><a href="#stepwise-regressionand-why-you-should-not-use-it." id="toc-stepwise-regressionand-why-you-should-not-use-it." class="nav-link" data-scroll-target="#stepwise-regressionand-why-you-should-not-use-it."><span class="header-section-number">12.5</span> Stepwise regression…and why you should not use it.</a></li>
  <li><a href="#regularized-regression" id="toc-regularized-regression" class="nav-link" data-scroll-target="#regularized-regression"><span class="header-section-number">12.6</span> Regularized regression</a></li>
  <li><a href="#model-selection-for-lmms" id="toc-model-selection-for-lmms" class="nav-link" data-scroll-target="#model-selection-for-lmms"><span class="header-section-number">12.7</span> Model selection for LMMs</a>
  <ul class="collapse">
  <li><a href="#step-1-create-saturated-model" id="toc-step-1-create-saturated-model" class="nav-link" data-scroll-target="#step-1-create-saturated-model"><span class="header-section-number">12.7.1</span> Step 1: Create saturated model</a></li>
  <li><a href="#step-2-optimize-random-effect-structure" id="toc-step-2-optimize-random-effect-structure" class="nav-link" data-scroll-target="#step-2-optimize-random-effect-structure"><span class="header-section-number">12.7.2</span> Step 2: Optimize random-effect structure</a></li>
  <li><a href="#step-3-optimize-the-fixed-effect-structure" id="toc-step-3-optimize-the-fixed-effect-structure" class="nav-link" data-scroll-target="#step-3-optimize-the-fixed-effect-structure"><span class="header-section-number">12.7.3</span> Step 3: Optimize the fixed effect structure</a></li>
  <li><a href="#step-4-interpret-model-output" id="toc-step-4-interpret-model-output" class="nav-link" data-scroll-target="#step-4-interpret-model-output"><span class="header-section-number">12.7.4</span> Step 4: Interpret model output</a></li>
  </ul></li>
  <li><a href="#model-averaging" id="toc-model-averaging" class="nav-link" data-scroll-target="#model-averaging"><span class="header-section-number">12.8</span> Model averaging</a></li>
  <li><a href="#summaryand-some-words-of-caution" id="toc-summaryand-some-words-of-caution" class="nav-link" data-scroll-target="#summaryand-some-words-of-caution"><span class="header-section-number">12.9</span> Summary…and some words of caution</a></li>
  <li><a href="#references-and-additional-reading" id="toc-references-and-additional-reading" class="nav-link" data-scroll-target="#references-and-additional-reading"><span class="header-section-number">12.10</span> References and additional reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model selection</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="lesson-preamble" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="lesson-preamble"><span class="header-section-number">12.1</span> Lesson preamble</h2>
<blockquote class="blockquote">
<h3 id="learning-objectives" data-number="12.1.1" class="anchored"><span class="header-section-number">12.1.1</span> Learning objectives</h3>
<ul>
<li>Understand the difference between likelihood estimation/inference and model <em>selection</em></li>
<li>Develop familiarity with common model selection approaches</li>
<li>Understand intuition for and the use of common information theoretic model selection criteria</li>
<li>Perform model selection on the RIKZ data from last class</li>
</ul>
<h3 id="lesson-outline" data-number="12.1.2" class="anchored"><span class="header-section-number">12.1.2</span> Lesson outline</h3>
<ul>
<li>Brief intro to model selection (20 mins)</li>
<li>Understanding information theoretic criteria (20 mins)</li>
<li>Model selection of RIKZ dataset (40 mins)</li>
<li>Model dredging and averaging (30 mins)</li>
</ul>
<h3 id="required-packages" data-number="12.1.3" class="anchored"><span class="header-section-number">12.1.3</span> Required packages</h3>
<ul>
<li><code>tidyverse</code></li>
<li><code>lme4</code></li>
<li><code>lmerTest</code></li>
<li><code>MuMIn</code></li>
<li><code>glmnet</code></li>
</ul>
</blockquote>
</section>
<section id="model-selection-theory" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="model-selection-theory"><span class="header-section-number">12.2</span> Model selection: theory</h2>
<p>Statistics is about making decisions under uncertainty. <em>Estimation</em> involves deciding what parameter values were most likely to (under a model of the distribution of the data and, in some circumstances, any prior knowledge about the parameters) have given rise to that data. <em>Inference</em> involves quantifying the uncertain around our estimates using confidence intervals. As we have seen, however, to any confidence interval there is an associated hypothesis test. Inference and hypothesis testing, then, involve deciding if a particular set of parameter values could have plausibly given rise to the data.</p>
<p>It should come as no surprise, since both estimation and inference involve decision making, that in statistics we often interested in deciding if the models we build are appropriate descriptions of how the world works (given the data we have and use to fit those models), or what among a set of candidate models is the “best”. This practice is called <em>model selection</em> and is the focus of our lecture today.</p>
<section id="examples" class="level3" data-number="12.2.1">
<h3 data-number="12.2.1" class="anchored" data-anchor-id="examples"><span class="header-section-number">12.2.1</span> Examples</h3>
<ul>
<li><p>Hypothesis testing is a kind of model selection. For example, for data <span class="math inline">\(x_1,\dots,x_n \sim f(x|\theta)\)</span>, testing <span class="math inline">\(H_0 \colon \theta = \theta_0\)</span> vs <span class="math inline">\(H_1 \colon \theta \neq \theta_0\)</span> is equivalent to choosing between models <span class="math inline">\(\mathcal{M}_0 \colon f(x|\theta)\)</span> and <span class="math inline">\(\mathcal{M}_1 \colon f(x|\theta_0)\)</span>.</p></li>
<li><p>Suppose we regress <span class="math inline">\(y\)</span> on the 1st, 2nd, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(p\)</span>th powers of a covariate <span class="math inline">\(x\)</span>:</p></li>
</ul>
<p><span class="math display">\[y = \beta_0 + \beta_1 x + \beta_2 x^2 + \cdots + \beta_p x^p.\]</span></p>
<p>This gives rise to a sequence of models <span class="math inline">\(\mathcal{M}_1,\mathcal{M}_2,\dots,\mathcal{M}_p\)</span> of the data generative process. Which model is the best description of the data? Although the full model is more flexible in that it has more parameters than, say, the model in which all second and higher order terms are <span class="math inline">\(=0\)</span>, it is more prone to overfitting. Choosing between a sequence of nested linear models like this is a classic model selection problem.</p>
<ul>
<li>Suppose we would like to model the relationship between expression (i.e., the number of transcripts produced) of <em>each</em> coding gene in the human genome and, say, height. If there are <span class="math inline">\(p\)</span> genes for which we have measurements and only <span class="math inline">\(n \ll p\)</span> observations, it is not possible to fit a linear model of the form</li>
</ul>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_{1i} + \dots + \beta_p x_{pi}.\]</span></p>
<p>(The reason is that there are infinitely many solutions to the likelihood maximization problem.) In this case, we might want to select a subset of the covariates which best explain the available data. Of <span class="math inline">\(x_1,\dots,x_p\)</span>, which are most informative? This too is a kind of model selection problem. We will discuss methods to do “regularized” regression and feature selection (e.g., ridge and LASSO regression) today.</p>
</section>
</section>
<section id="common-model-selection-techniques" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="common-model-selection-techniques"><span class="header-section-number">12.3</span> Common model selection techniques</h2>
<ol type="1">
<li>AIC and related methods (BIC, <span class="math inline">\(C_p\)</span>)</li>
<li>Cross validation</li>
<li>Regularized regression (ridge, LASSO, elastic net)</li>
<li>Stepwise regression</li>
</ol>
<section id="the-akaike-information-criterion-aic" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="the-akaike-information-criterion-aic"><span class="header-section-number">12.3.1</span> The Akaike information criterion (AIC)</h3>
<p>Suppose we have data <span class="math inline">\(y_1,\dots,y_n\)</span> that are drawn from a distribution <span class="math inline">\(f\)</span> and a set of candidate models</p>
<p><span class="math display">\[\mathcal{M}_j = \{p_j(y|\theta_j)\}.\]</span></p>
<p>It is possible under this setup to find the maximum likelihood estimators for each of the candidate models; it is, however, difficult to compare these models in that the parameters underlying each model might not match (i.e., the models may not be nested). The <em>Akaike information criterion</em> overcomes this issue, and despite having a lengthy and complicated derivation, is a metric which balances two things: 1) the goodness-of-fit of the model and 2) the number of parameters fitted.</p>
<p>The intuition and formula for the AIC is as follows. If <span class="math inline">\(\hat{\theta}_{j,\text{MLE}}\)</span> is the MLE for <span class="math inline">\(\theta\)</span> under model <span class="math inline">\(\mathcal{M}_j\)</span>, then we can measure the distance between the ground truth (i.e., distribution <span class="math inline">\(f\)</span> of the data) and fitted model <span class="math inline">\(\hat{p}_j = p_j(y|\hat{\theta}_{j,\text{MLE}})\)</span> using a metric called the Kullback-Leibler divergence:</p>
<p><span class="math display">\[D_{KL}(p, \hat{p}_j) = \int p(y) \log p(y) \text{d} y - \int p(y) \log \hat{p_j}(y) \text{d} y. \]</span></p>
<p><strong>Minimizing the Kullback-Leibler divergence (distance) between the ground truth and density <span class="math inline">\(j\)</span> is a principled way to preform model selection, and forms the basis for the AIC.</strong> Note that minimizing only involves the second integral, and we can estimate the integral with an average</p>
<p><span class="math display">\[\frac{1}{n} \log L(\hat{\theta}_{j,\text{MLE}}) = \frac{1}{n} \sum_{i=1}^n \log p(y_i|\hat{\theta}_{j,\text{MLE}})\]</span></p>
<p>Importantly, AIC corrects for the fact this is an unbiased estimator of the divergence by adding <span class="math inline">\(d_j/n\)</span>, where <span class="math inline">\(d_j = \text{dim}(\mathcal{M}_j)\)</span>. This term is what penalizes models with a large number of parameters. So,</p>
<p><span class="math display">\[\text{AIC} = - 2 \log L(\hat{\theta}_{j,\text{MLE}}) + 2 d_j.\]</span></p>
<p>Notice we have multiplied the preceding quantities by <span class="math inline">\(-2n\)</span> to get the above expression; this does not change anything, and is largely for historical reasons. Based on the AIC expression, it is clear 1) the higher the likelihood, the lower the AIC; 2) introducing more parameters into the model without changing the likelihood results in a greater value for the AIC. The balance between goodness-of-fit (likelihood) and the number of parameters (the potential to overfit) is what AIC tries to optimize in choosing between candidate models. As we have shown here, that balance is struck by minimizing the distance between candidate models and the ground truth while correcting for bias introduced by having models of different dimensions.</p>
</section>
<section id="textaic_c-for-small-sample-sizes" class="level3" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="textaic_c-for-small-sample-sizes"><span class="header-section-number">12.3.2</span> <span class="math inline">\(\text{AIC}_c\)</span> for small sample sizes</h3>
<p>It is sometimes convenient to, when sample sizes are small (<span class="math inline">\(n &lt; 40\)</span> is a commonly used rule-of-thumb) use the following metric to choose between candidate models:</p>
<p><span class="math display">\[\text{AIC}_c = \text{AIC} + \frac{2d_j(d_j+1)}{n-d_j-1}\]</span></p>
</section>
</section>
<section id="stepwise-and-regularized-regression" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="stepwise-and-regularized-regression"><span class="header-section-number">12.4</span> Stepwise and regularized regression</h2>
<p>We will return to model selection via AIC later in the lecture, but in the meantime we will discuss two kinds of feature selection techniques that can help us choose between covariates in a linear model.</p>
</section>
<section id="stepwise-regressionand-why-you-should-not-use-it." class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="stepwise-regressionand-why-you-should-not-use-it."><span class="header-section-number">12.5</span> Stepwise regression…and why you should not use it.</h2>
<p>Stepwise selection involves iteratively adding and removing predictors according to some criterion (e.g., variance explained). The steps for forward stepwise regression are as follows:</p>
<ol type="1">
<li>Let <span class="math inline">\(\mathcal{M}_0\)</span> be a null model, i.e., one with no predictors.</li>
<li>For <span class="math inline">\(k=0,1,\dots,p-1\)</span>, fit all models which add one predictor to those in model <span class="math inline">\(\mathcal{M}_k\)</span>.</li>
<li>Choose the best among the <span class="math inline">\(p-k\)</span> models in step (2) and call it model <span class="math inline">\(\mathcal{M}_{k+1}\)</span>. This is done according to some criterion. We might, e.g., choose the model with the greatest <span class="math inline">\(R^2\)</span>.</li>
<li>Select from models <span class="math inline">\(\mathcal{M}_0,\dots,\mathcal{M}_p\)</span> using, for example, AIC.</li>
</ol>
<p><strong>We, however, urge you to AVOID stepwise selection and to be critical of analyses which use it. No statistics can be a substitute for good theory which is informative about the predictors which have predictive power <em>because</em> they are biologically meaningful. When choosing between models, careful consideration of the what predictors are informative and <em>why</em> is key.</strong></p>
<p>For more on the problems with automated stepwise selection methods, see <a href="https://stats.stackexchange.com/questions/20836/algorithms-for-automatic-model-selection?noredirect=1&amp;lq=1">here</a>.</p>
</section>
<section id="regularized-regression" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="regularized-regression"><span class="header-section-number">12.6</span> Regularized regression</h2>
<p>A more principled approach to linear model selection is so-called <em>regularized regression</em>. These approaches constrain the least squares problem (i.e., maximizing the likelihood function with respect to the regression coefficients) in some way. These constraints help “pull” the regression coefficients to zero and filter the features which are most informative about the response. The induced sparsity (i.e., many of the regression coefficients being <span class="math inline">\(=0\)</span>) is ideal in that it helps improve the interpretability and predictive power of the model.</p>
<p>Different types of constraint “regularize” the regression coefficients in different ways. Ridge regression fits the coefficients of a linear model <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}\)</span> subject to <span class="math inline">\(||\boldsymbol{\beta}||_2^2 = \beta_0^2 + \beta_2^2 + \cdots + \beta_p^2 \leqslant t.\)</span> The LASSO fits the same model, but subject to <span class="math inline">\(||\boldsymbol{\beta}||_1 = |\beta_0| + |\beta_2| + \cdots + |\beta_p| \leqslant t.\)</span> While ridge regression pulls coefficients close to zero, LASSO forces the fitted model to be sparse (i.e., most coefficients are exactly zero).</p>
<p>There are several packages which fit models subject to the ridge and LASSO constraints in R. The below example shows how to implement LASSO regression for simulated data using the function <code>glmnet</code>. (The syntax is similar for ridge and other forms of regularized regression.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">7</span>; n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>,<span class="dv">0</span>,<span class="fl">2.5</span>,<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">25</span>,<span class="dv">50</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span>p, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.1</span>), <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x <span class="sc">%*%</span> beta <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(<span class="at">y =</span> y, <span class="at">x =</span> x))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"y"</span>, <span class="fu">paste</span>(<span class="st">"x"</span>, <span class="dv">1</span><span class="sc">:</span>p, <span class="at">sep=</span><span class="st">""</span>))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>fit_lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="co"># alpha = 0 gives ridge constraint</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_lasso, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="lec10-model-selection_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># solution path shows how size of fitted coefficients changes as a function of the penalty</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># increasing lambda and t both result in more stringent constraint on the coeffs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>How to choose <span class="math inline">\(\lambda\)</span> (or, equivalently, <span class="math inline">\(t\)</span>)? Extreme values force the regression coefficients to be all <span class="math inline">\(=0\)</span>, but small values may give rise to an over-saturated model with too many predictors. There are a couple ways to decide what constraint is best to use, but <em>cross-validation</em> is quite popular. This involves splitting the data into “training” and “test” data and determining for which value of <span class="math inline">\(\lambda\)</span> the model minimizes, say, the mean squared error. The following implements so-called leave-one-out cross-validation:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>lambda_values <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">seq</span>(<span class="fu">log</span>(<span class="fl">0.001</span>), <span class="fu">log</span>(<span class="dv">1000</span>), <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>cross_val_lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">nfolds =</span> <span class="dv">10</span>, <span class="at">lambda =</span> lambda_values)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cross_val_lasso)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="lec10-model-selection_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>lasso_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(cross_val_lasso, </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                             <span class="at">s =</span> cross_val_lasso<span class="sc">$</span>lambda.min,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">type =</span> <span class="st">"coefficients"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>lasso_VS_truth <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">cbind</span>(beta, <span class="at">lasso =</span> lasso_predictions[<span class="sc">-</span><span class="dv">1</span>]), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(lasso_VS_truth) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"true coeff"</span>,<span class="st">"fitted coeff"</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(lasso_VS_truth) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(lasso_VS_truth)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">true coeff</th>
<th style="text-align: right;">fitted coeff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-10.0</td>
<td style="text-align: right;">-11.0474719</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">0.3741455</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2.5</td>
<td style="text-align: right;">3.5345977</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.0</td>
<td style="text-align: right;">4.3852927</td>
</tr>
<tr class="odd">
<td style="text-align: right;">10.0</td>
<td style="text-align: right;">9.8991121</td>
</tr>
<tr class="even">
<td style="text-align: right;">25.0</td>
<td style="text-align: right;">24.4243855</td>
</tr>
<tr class="odd">
<td style="text-align: right;">50.0</td>
<td style="text-align: right;">49.2153605</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>It appears the value of <span class="math inline">\(\lambda\)</span> that is ideal for the problem at hand is so small that LASSO regression returns the same coefficients as un-constrained least squares, i.e., the penalty does not affect estimation of the coefficients too much! The data we have used here are cherry-picked to illustrate how the method works with relative ease. Implementation of the LASSO is a bit trickier with more features. <strong>However, when you need to preform feature selection on a large number of covariates and have limited data (<span class="math inline">\(p\)</span> large), a combination of cross-validation and LASSO regression is the way to go.</strong></p>
</section>
<section id="model-selection-for-lmms" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="model-selection-for-lmms"><span class="header-section-number">12.7</span> Model selection for LMMs</h2>
<p>Model selection for mixed models is even more complicated, due to the addition of random effects. A procedure that is commonly used to preform selection of LMMs is as follows:</p>
<ol type="1">
<li><p>Create a <em>saturated model</em> that includes all fixed effects (and their interactions<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) and random effects you wish to test.</p></li>
<li><p>Optimize the random-effect structure by comparing models with the same saturated fixed effects structure but differing random effect structures. These models should be fitted using Restricted Maximum Likelihood (i.e., <code>REML = TRUE</code>), since varience component estimation will be biased otherwise. The <em>optimal</em> random effect structure is the one that provides the lowest AIC. Do <strong>not</strong> remove random effects if they are included to account for non-independence in your data. Skip this step if random effects must be included given the hierarchical structure (i.e., nestedness) in the data.</p></li>
<li><p>Optimize the fixed-effect structure by comparing models with the same optimized (or necessary) random effects but with differing fixed effect structures. These models should be fitted with Maximum Likelihood (i.e., <code>REML = FALSE</code>) to prevent biased fixed-effect parameter estimates. Models can be selected on the basis of AIC (the lower the better), by comparing nested models using a likelihood ratio test (LRT), or both.</p></li>
<li><p>Fit the final model with optimized fixed and random effects using REML and interpret your results.</p></li>
</ol>
<p>We can apply this procedure to the RIKZ data as follows.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>rikz_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"rikz_data.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="step-1-create-saturated-model" class="level3" data-number="12.7.1">
<h3 data-number="12.7.1" class="anchored" data-anchor-id="step-1-create-saturated-model"><span class="header-section-number">12.7.1</span> Step 1: Create saturated model</h3>
<p>Let’s recreate the random intercept and random intercept-slope models we created last class, and add in Exposure and the interaction between NAP and Exposure as additional fixed effects.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set `REML=TRUE` in anticipation of step 2 </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">*</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), <span class="at">REML=</span><span class="cn">TRUE</span>, <span class="at">data=</span>rikz_data)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>mixed_model_IntSlope <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">*</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">+</span>NAP<span class="sc">|</span>Beach), <span class="at">REML=</span><span class="cn">TRUE</span>, <span class="at">data=</span>rikz_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-2-optimize-random-effect-structure" class="level3" data-number="12.7.2">
<h3 data-number="12.7.2" class="anchored" data-anchor-id="step-2-optimize-random-effect-structure"><span class="header-section-number">12.7.2</span> Step 2: Optimize random-effect structure</h3>
<p>To optimize the random effects, we compare <code>mixed_model_IntSlope</code> with <code>mixed_model_IntOnly</code>. This will determine whether including a random slope for each beach improves the fit of the model to the observed data, and we couldn’t decide otherwise because there isn’t any prior research on whether we should expect the species richness and NAP relationship to differ by beach. We are <strong>NOT</strong> testing the <code>mixed_model_IntOnly</code> model against one in which there are no random effects since including a random intercept for each beach is required to account for the non-independence in the data.</p>
<p>Let’s get the <span class="math inline">\(\text{AIC}_c\)</span> for our two models are given by:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">AICc</span>(mixed_model_IntOnly, mixed_model_IntSlope)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                     df     AICc
mixed_model_IntOnly   6 235.2327
mixed_model_IntSlope  8 237.2527</code></pre>
</div>
</div>
<p>Based on the above, the random intercept only model is a better fit to the data (<span class="math inline">\(\text{AIC}_c\)</span> is lower by 2.0157 units<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>). The optimal random-effect structure is thus one that includes only a random intercept for each beach but not a random slope.</p>
</section>
<section id="step-3-optimize-the-fixed-effect-structure" class="level3" data-number="12.7.3">
<h3 data-number="12.7.3" class="anchored" data-anchor-id="step-3-optimize-the-fixed-effect-structure"><span class="header-section-number">12.7.3</span> Step 3: Optimize the fixed effect structure</h3>
<p>We now need to refit the model with the optimal random-effect structure using ML and compare different fixed effect structures. We will construct a series of models that captures all possible combinations of fixed effects terms in our saturated model in order to find the best one. Let’s fit these models below and check their <span class="math inline">\(\text{AIC}_c\)</span>s. Don’t forget to include a model that doesn’t have any fixed effects!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model with both fixed effects and their interaction</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_Full <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">*</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">REML=</span>F, <span class="at">data=</span>rikz_data)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># No interaction</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_NoInter <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">+</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">REML=</span>F, <span class="at">data=</span>rikz_data)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># No interaction or main effect of exposure</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_NAP <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), <span class="at">REML=</span>F, <span class="at">data=</span>rikz_data)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># No interaction or main effect of NAP</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_Exp <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), <span class="at">REML=</span>F, <span class="at">data=</span>rikz_data)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># No fixed effects</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_NoFix <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span><span class="dv">1</span><span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), <span class="at">REML=</span>F, <span class="at">data=</span>rikz_data)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="fu">AICc</span>(mixed_model_IntOnly_Full, mixed_model_IntOnly_NoInter,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    mixed_model_IntOnly_NAP, mixed_model_IntOnly_Exp,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    mixed_model_IntOnly_NoFix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            df     AICc
mixed_model_IntOnly_Full     6 236.5947
mixed_model_IntOnly_NoInter  5 238.1467
mixed_model_IntOnly_NAP      4 250.8291
mixed_model_IntOnly_Exp      4 261.7996
mixed_model_IntOnly_NoFix    3 269.8889</code></pre>
</div>
</div>
<p>Wow, that was a lot of typing! And we only have two predictors plus an interaction! We can see that this can easily get out of hand when the model structure becomes more complex. But fear not! Obviously there is a package with a function that deals with this exact situation. Our hero today is the <code>MuMIn</code> package and the <code>dredge</code> function, which automates this dropping-of-terms process and summarizes and outputs all of the model results in one table. It is highly flexible, you can customize the criterion used (AIC, BIC, etc.), how the output is reported, what’s included in the output (e.g., do you want F-stats and R<sup>2</sup> to be included?), whether some terms should be represented in all models, and even only include some terms in models if other terms are included (a.k.a. dependency chain). So handy!!! In fact, <em>soooooooooo handy</em>, it is the perfect tool for <span class="math inline">\(p\)</span>-hacking… but … we can trust one another, right???</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Argument `na.action="na.fail"` is required for `dredge` to run</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_Full <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">*</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), <span class="at">REML=</span>F, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">data=</span>rikz_data, <span class="at">na.action=</span><span class="st">"na.fail"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>mixed_model_dredge <span class="ot">&lt;-</span> <span class="fu">dredge</span>(mixed_model_IntOnly_Full, <span class="at">rank=</span>AICc)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>mixed_model_dredge</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Global model call: lmer(formula = Richness ~ NAP * Exposure + (1 | Beach), data = rikz_data, 
    REML = F, na.action = "na.fail")
---
Model selection table 
   (Int)    Exp     NAP Exp:NAP df   logLik  AICc delta weight
8 40.740 -3.340 -13.710   1.072  6 -111.192 236.6  0.00  0.684
4 37.290 -2.999  -2.725          5 -113.304 238.1  1.55  0.315
3  6.584         -2.576          4 -120.915 250.8 14.23  0.001
2 37.860 -3.147                  4 -126.400 261.8 25.20  0.000
1  5.689                         3 -131.652 269.9 33.29  0.000
Models ranked by AICc(x) 
Random terms (all models): 
  1 | Beach</code></pre>
</div>
</div>
<p>And voila! SO. MUCH. FASTER. And look! Isn’t this table just wonderful???</p>
<p>Based on the output above, it looks like the model that includes NAP, Exposure, and their interaction provides the overall best fit to the data. However, this model is indistinguishable from the model without the interaction term (<span class="math inline">\(\Delta \text{AIC}_c=1.552\)</span>).</p>
<p>Let’s try and see if we can resolve this using a <em>likelihood ratio test</em> (LRT), which we learned about in the introductory statistics lecture. Recall that the LR test statistic has an approximate <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom equal to the difference in dimensional between <em>nested</em> models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mixed_model_IntOnly_Full, mixed_model_IntOnly_NoInter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: rikz_data
Models:
mixed_model_IntOnly_NoInter: Richness ~ NAP + Exposure + (1 | Beach)
mixed_model_IntOnly_Full: Richness ~ NAP * Exposure + (1 | Beach)
                            npar    AIC    BIC  logLik deviance Chisq Df
mixed_model_IntOnly_NoInter    5 236.61 245.64 -113.30   226.61         
mixed_model_IntOnly_Full       6 234.38 245.22 -111.19   222.38 4.224  1
                            Pr(&gt;Chisq)  
mixed_model_IntOnly_NoInter             
mixed_model_IntOnly_Full       0.03986 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Ah-Ha! With <span class="math inline">\(p\)</span>-value of 0.040, we reject the null hypothesis (i.e., the simpler model is a better description of the data) in favor of alternative hypothesis (the more complex model!).</p>
</section>
<section id="step-4-interpret-model-output" class="level3" data-number="12.7.4">
<h3 data-number="12.7.4" class="anchored" data-anchor-id="step-4-interpret-model-output"><span class="header-section-number">12.7.4</span> Step 4: Interpret model output</h3>
<p>Finally, let’s re-fit the best-fitting model via REML:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>mixed_model_IntOnly_Full2 <span class="ot">&lt;-</span> <span class="fu">lmer</span>(Richness<span class="sc">~</span>NAP<span class="sc">*</span>Exposure<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Beach), </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">REML=</span>T, <span class="at">data=</span>rikz_data)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mixed_model_IntOnly_Full2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML. t-tests use Satterthwaite's method [
lmerModLmerTest]
Formula: Richness ~ NAP * Exposure + (1 | Beach)
   Data: rikz_data

REML criterion at convergence: 221

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.4138 -0.4394 -0.1063  0.1511  4.3635 

Random effects:
 Groups   Name        Variance Std.Dev.
 Beach    (Intercept) 0.3063   0.5534  
 Residual             8.7447   2.9571  
Number of obs: 45, groups:  Beach, 9

Fixed effects:
             Estimate Std. Error       df t value Pr(&gt;|t|)    
(Intercept)   40.7149     5.6164   7.9362   7.249 9.17e-05 ***
NAP          -13.5864     5.4298  36.5654  -2.502 0.016947 *  
Exposure      -3.3385     0.5485   7.9972  -6.087 0.000294 ***
NAP:Exposure   1.0625     0.5278  36.6843   2.013 0.051504 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) NAP    Exposr
NAP         -0.300              
Exposure    -0.996  0.301       
NAP:Exposur  0.302 -0.997 -0.306</code></pre>
</div>
</div>
<p>We see that increasing both NAP and Exposure results in a significant decrease in species richness (<span class="math inline">\(p&lt;0.05\)</span>). There is also a marginally insignificant interaction between NAP and Exposure which we won’t read too much into (<span class="math inline">\(p=0.051\)</span>!). Finally, while Beach is included in our model as a random effect, notice how little variation is attributed to differences between beaches relative to the model we ran in lecture 7 (~45% of residual variance vs.&nbsp;approx. 0). The only difference is that our current model includes Exposure as a fixed effect. This suggests that much of the variation between beaches in lecture 7 was likely attributable to differences in exposure, which is now being captured by the fixed effects.</p>
</section>
</section>
<section id="model-averaging" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="model-averaging"><span class="header-section-number">12.8</span> Model averaging</h2>
<p>In Assignment 4, you will use data from Santangelo <em>et al.</em> (2019) who were interested in understanding how insect herbivores and plant defenses influence the expression of plant floral traits. While that was one component of the study, the main question was whether herbivores, pollinators, and plant defenses alter the shape and strength of <em>natural selection</em> on plant floral traits. In other words, which of these 3 agents of selection (plant defenses, herbivores, or pollinators) are most important in driving the evolution of floral traits in plants?</p>
<p>The motivation for that experiment actually came a few year prior, in 2016, when Thompson and Johnson published an experiment examining how plant defenses alter natural selection on plant floral traits. They found some interesting patterns but it was unclear whether these were being driven by the plant’s interactions with herbivores, pollinators, or both. This was because they didn’t directly manipulate these agents: pollination was not quantified in their experiment and herbivore damage was measured observationally and thus these results were correlative. However, their experimental data provides a prime use of model selection in ecology and evolution.</p>
<p>The data consists of 140 observations (rows). Each row in the dataset corresponds to the mean trait value of one plant genotype (they had replicates for each genotype but took the average across these replicates) grown in a common garden. They measured 8 traits and quantified the total mass of seeds produced by plants as a measure of absolute fitness. Genotypes were either “cyanogenic” (i.e., containing plant defenses) or were “acyanogenic” (i.e., lacking plant defenses). In addition, they quantified the amount of herbivore damage (i.e., percent leaf area lost) on each plant twice throughout the growing season, although here we will only focus on the effects of plant defenses and avoid their herbivore damage measurements. We are going to estimate the strength of selection on each trait (controlling for correlations between traits due to the pleiotropic action of genes) and assess whether plant defenses alter the strength or direction of natural selection imposed on these traits. We developed the tools to do this in a previous lecture, where we learned that estimating different kinds of selection can be done by regressing fitness on standardized trait values (i.e., mean of 0 and standard deviation of 1).</p>
<p>Let’s start by loading in the data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 140
Columns: 38
$ Genotype     &lt;dbl&gt; 2, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22,…
$ cyanide      &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, …
$ linamarin    &lt;dbl&gt; 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, …
$ linamarase   &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, …
$ VegBiomass   &lt;dbl&gt; 1.16840, 4.42100, 0.79500, 4.44740, 1.17575, 2.70160, 2.4…
$ LatSpread    &lt;dbl&gt; 283.500, 995.400, 298.000, 1019.450, 271.000, 887.800, 76…
$ FrstFlwr     &lt;dbl&gt; 2.200000, 11.250000, 7.666667, 32.000000, 8.500000, 6.800…
$ BnrLgth      &lt;dbl&gt; 6.326250, 6.472500, 5.712500, 5.422500, 5.565000, 5.88625…
$ BnrWdt       &lt;dbl&gt; 3.568750, 3.700000, 2.961250, 3.222500, 3.350000, 3.29375…
$ InflHt       &lt;dbl&gt; 23.21750, 20.62000, 20.09500, 25.13500, 14.93000, 19.7116…
$ InflWdt      &lt;dbl&gt; 22.67250, 17.72833, 21.44250, 25.01000, 15.37000, 19.3916…
$ InflNum      &lt;dbl&gt; 4.20, 4.00, 3.00, 1.00, 1.75, 3.40, 2.20, 1.50, 1.80, 12.…
$ FlwrCt       &lt;dbl&gt; 32.75000, 29.50000, 21.50000, 59.25000, 56.00000, 35.4444…
$ SeedBm       &lt;dbl&gt; 0.030000, 0.038625, 0.004375, 0.014960, 0.025875, 0.03092…
$ AvgDMG1      &lt;dbl&gt; 43.26000, 21.95000, 43.17500, 21.72000, 30.16250, 27.4000…
$ AvgDMG2      &lt;dbl&gt; 21.3700, 17.5500, 24.4500, 15.9200, 37.3375, 20.2400, 22.…
$ VegGrowth    &lt;dbl&gt; -1.12177796, 0.88565970, -1.23438613, 0.92433034, -1.1345…
$ RFSeed       &lt;dbl&gt; 0.9282121, 1.1950731, 0.1353643, 0.4628684, 0.8005829, 0.…
$ FrstFlwr.T   &lt;dbl&gt; 1.483240, 3.354102, 2.768875, 5.656854, 2.915476, 2.60768…
$ InflHt.T     &lt;dbl&gt; 539.0523, 425.1844, 403.8090, 631.7682, 222.9049, 388.549…
$ SeedBm.T     &lt;dbl&gt; 0.17320508, 0.19653244, 0.06614378, 0.12231108, 0.1608570…
$ InflNum.T    &lt;dbl&gt; 1.6486586, 1.6094379, 1.3862944, 0.6931472, 1.0116009, 1.…
$ AvgDmg1.T    &lt;dbl&gt; 6.577233, 4.685083, 6.570769, 4.660472, 5.492040, 5.23450…
$ AvgDmg2.T    &lt;dbl&gt; 4.622770, 4.189272, 4.944694, 3.989987, 6.110442, 4.49888…
$ VegGrowth.T  &lt;dbl&gt; 0.7926046, 1.6234715, 0.7180626, 1.6353380, 0.7845251, 1.…
$ VegBiomass.T &lt;dbl&gt; 1.0809255, 2.1026174, 0.8916277, 2.1088860, 1.0843201, 1.…
$ LatSpread.T  &lt;dbl&gt; 16.83746, 31.54996, 17.26268, 31.92883, 16.46208, 29.7959…
$ FlwrCt.S     &lt;dbl&gt; -0.51866068, -0.84578217, -1.65100431, 2.14863763, 1.8215…
$ BnrLgth.S    &lt;dbl&gt; 0.98570003, 1.28769651, -0.28165272, -0.88048334, -0.5862…
$ BnrWdt.S     &lt;dbl&gt; 0.91616830, 1.41223922, -1.37993138, -0.39251403, 0.08938…
$ InflHt.S     &lt;dbl&gt; 0.7190552, -0.3496320, -0.5502468, 1.5892241, -2.2480905,…
$ InflWdt.S    &lt;dbl&gt; 0.83894602, -0.80610308, 0.42969396, 1.61669129, -1.59078…
$ FrstFlwr.S   &lt;dbl&gt; -1.54639903, 0.34224409, -0.24854531, 2.66688196, -0.1005…
$ SeedBm.S     &lt;dbl&gt; 0.08114206, 0.44458767, -1.58689750, -0.71179816, -0.1112…
$ InflNum.S    &lt;dbl&gt; 0.94431501, 0.85825229, 0.36860437, -1.15238099, -0.45359…
$ AvgDmg1.S    &lt;dbl&gt; 0.66702301, -1.29690435, 0.66031291, -1.32244855, -0.4593…
$ AvgDmg2.S    &lt;dbl&gt; -0.29425351, -0.87159469, 0.13449201, -1.13700594, 1.6870…
$ VegGrowth.S  &lt;dbl&gt; -1.18918210, 0.91239380, -1.37772698, 0.94240864, -1.2096…</code></pre>
</div>
</div>
<p>We will now generate the global model. Remember, this should be a saturated model with all of the fixed effects and their interactions. We are including the presence of hydrogen cyanide (HCN, cyanide in model below), all standardized traits and the trait by HCN interactions as fixed effects in this model. There are no random effects in this model so we can go ahead and use <code>lm()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create saturated model</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>GTSelnModel.HCN <span class="ot">&lt;-</span> <span class="fu">lm</span>(RFSeed <span class="sc">~</span> VegGrowth.S<span class="sc">*</span>cyanide <span class="sc">+</span> BnrLgth.S<span class="sc">*</span>cyanide <span class="sc">+</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                          BnrWdt.S<span class="sc">*</span>cyanide <span class="sc">+</span> FrstFlwr.S<span class="sc">*</span>cyanide <span class="sc">+</span> </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>                          InflNum.S<span class="sc">*</span>cyanide <span class="sc">+</span> FlwrCt.S<span class="sc">*</span>cyanide <span class="sc">+</span> </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                          InflWdt.S<span class="sc">*</span>cyanide <span class="sc">+</span> InflHt.S<span class="sc">*</span>cyanide,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> Thompson_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we will perform our model selection based on AIC<sub>c</sub> (due to low sample sizes). We automate this process using the <code>dredge()</code> function from the <code>MuMIn</code> package. We warned earlier that this dredging approach has been criticized. However, in this case it’s reasonable: we know from work in other systems that all of these traits could conceivably experience selection, and we know that that selection could vary due to plant defenses. In other words, all terms in this model represent biologically real hypotheses. Let’s go ahead and dredge.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>GTSelnModel.HCN <span class="ot">&lt;-</span> <span class="fu">lm</span>(RFSeed <span class="sc">~</span> VegGrowth.S<span class="sc">*</span>cyanide <span class="sc">+</span> BnrLgth.S<span class="sc">*</span>cyanide <span class="sc">+</span> </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                          BnrWdt.S<span class="sc">*</span>cyanide <span class="sc">+</span> FrstFlwr.S<span class="sc">*</span>cyanide <span class="sc">+</span> </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                          InflNum.S<span class="sc">*</span>cyanide <span class="sc">+</span> FlwrCt.S<span class="sc">*</span>cyanide <span class="sc">+</span> </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                          InflWdt.S<span class="sc">*</span>cyanide <span class="sc">+</span> InflHt.S<span class="sc">*</span>cyanide,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> Thompson_data, </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">na.action=</span><span class="st">"na.fail"</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>GTmodel_dredge <span class="ot">&lt;-</span> <span class="fu">dredge</span>(GTSelnModel.HCN,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">beta =</span> F, <span class="co"># or "none" corresponds to unstandardized coefficients</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                         <span class="at">evaluate =</span> T, <span class="co"># evaluate/rank models</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>                         <span class="at">rank =</span> AICc) <span class="co"># rank function</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s have a look at the first few lines returned by <code>dredge()</code>. Let’s also print out how many models were compared.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(GTmodel_dredge)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Global model call: lm(formula = RFSeed ~ VegGrowth.S * cyanide + BnrLgth.S * cyanide + 
    BnrWdt.S * cyanide + FrstFlwr.S * cyanide + InflNum.S * cyanide + 
    FlwrCt.S * cyanide + InflWdt.S * cyanide + InflHt.S * cyanide, 
    data = Thompson_data, na.action = "na.fail")
---
Model selection table 
       (Int)  BnL.S    BnW.S     cyn  FlC.S    FrF.S  InN.S   VgG.S BnL.S:cyn
3920  0.9783 0.2297 -0.09086 0.04292 0.1671          0.4958 0.07497   -0.3245
3664  0.9668 0.2597 -0.10380 0.05271 0.1756          0.5099           -0.3513
2894  0.9895 0.1861          0.02887 0.1721          0.4916 0.09900   -0.1837
69456 0.9809 0.2151 -0.08489 0.04193 0.1624          0.4992 0.10790   -0.3086
3936  0.9825 0.2238 -0.09101 0.04230 0.1687 -0.02619 0.4860 0.08231   -0.3215
2910  0.9943 0.1794          0.02828 0.1739 -0.02989 0.4806 0.10700   -0.1834
      BnW.S:cyn cyn:FlC.S cyn:VgG.S df  logLik  AICc delta weight
3920     0.2273    0.2328           11 -85.102 194.3  0.00  0.254
3664     0.2633    0.2437           10 -86.353 194.4  0.14  0.237
2894               0.2200            9 -87.650 194.7  0.42  0.206
69456    0.2391    0.2521   -0.0917 12 -84.648 195.8  1.49  0.121
3936     0.2238    0.2311           12 -84.880 196.2  1.95  0.096
2910               0.2181           10 -87.370 196.4  2.18  0.086
Models ranked by AICc(x) </code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(GTmodel_dredge)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6817</code></pre>
</div>
</div>
<p>The output tells us the original model and then provides a rather large table with many rows and columns. The rows in this case are different models with different combinations of predictors (<span class="math inline">\(n = 6,817\)</span> models). The columns are the different terms from our model, which <code>dredge()</code> has abbreviated. The numbers in the cells are the estimates (i.e.&nbsp;beta coefficients) for each term that is present in the model; blank cells mean that term was not included in the model. The last 5 columns are important: they give us the degrees of freedom for the model (a function of the number of terms in the model), the log-likelihood of the model, the AIC score, the delta AIC, and the AIC weights. The <span class="math inline">\(\Delta AIC\)</span> is the difference between the AIC score of a model and the AIC score of the top model. The weight can be thought of as the probability that the model is the best model given the candidate set included in the model selection procedure.</p>
<p>We can retrieve the top model using the <code>get.models()</code> function and specifying that we want to top model using the <code>subset</code> argument. We need to further subset this output since it returns a list.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>top_model <span class="ot">&lt;-</span> <span class="fu">get.models</span>(GTmodel_dredge, <span class="at">subset =</span> <span class="dv">1</span>)[[<span class="dv">1</span>]]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(top_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = RFSeed ~ BnrLgth.S + BnrWdt.S + cyanide + FlwrCt.S + 
    InflNum.S + VegGrowth.S + BnrLgth.S:cyanide + BnrWdt.S:cyanide + 
    cyanide:FlwrCt.S + 1, data = Thompson_data, na.action = "na.fail")

Residuals:
     Min       1Q   Median       3Q      Max 
-1.20717 -0.24783 -0.02084  0.26346  1.25135 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        0.97834    0.05049  19.376  &lt; 2e-16 ***
BnrLgth.S          0.22967    0.05807   3.955 0.000125 ***
BnrWdt.S          -0.09086    0.05758  -1.578 0.116972    
cyanide            0.04292    0.08416   0.510 0.610918    
FlwrCt.S           0.16709    0.05256   3.179 0.001845 ** 
InflNum.S          0.49578    0.04865  10.191  &lt; 2e-16 ***
VegGrowth.S        0.07497    0.04898   1.531 0.128237    
BnrLgth.S:cyanide -0.32449    0.11197  -2.898 0.004409 ** 
BnrWdt.S:cyanide   0.22730    0.10567   2.151 0.033313 *  
cyanide:FlwrCt.S   0.23284    0.09003   2.586 0.010806 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.4612 on 130 degrees of freedom
Multiple R-squared:  0.6198,    Adjusted R-squared:  0.5935 
F-statistic: 23.55 on 9 and 130 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>But how much evidence do we actually have that this is the <em>best</em> model? We have over 6,000 models, so it’s unlikely that only one model explains the data. From the <code>dredge</code> output we can see there is little difference in the AIC and weights of the first few models.</p>
<p>Is there really much of a difference between two models who’s AIC differ by only 0.14 points? How do we decide which model(s) to interpret? Statisticians have thought about this problem and it turns out that models with delta AIC (or other criterion) less than 2 are considered to be just as good as the top model and thus we shouldn’t just discount them. In fact, the top 5 models all have AIC<sub>c</sub> scores within 2 units of the top model.</p>
<p>We could use likelihood ratio test(s) to try to test if more complex models are better descriptions of the data. Alternatively, we could use the weights: if a model has weight greater or equal to 95% then it is likely to be the top model. We can generate a “credibility” set consisting of all models whose cumulative sum of AIC weights is 0.95. In any case, the point is that we have no good reason to exclude models other than the top one when the next models after it are likely to be just as good.</p>
<p>To get around this, we will perform what’s called <em>model averaging</em>. This allows us to average the parameter estimates across multiple models that are performing equally well, and avoids the issue of model uncertainty. Let’s do this below by averaging all models with a delta <span class="math inline">\(\text{AIC}_c \leqslant 2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">model.avg</span>(GTmodel_dredge, <span class="at">subset =</span> delta <span class="sc">&lt;=</span> <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
model.avg(object = GTmodel_dredge, subset = delta &lt;= 2)

Component model call: 
lm(formula = RFSeed ~ &lt;5 unique rhs&gt;, data = Thompson_data, na.action = 
     na.fail)

Component models: 
                      df logLik   AICc delta weight
1+2+3+4+6+7+8+9+10    11 -85.10 194.27  0.00   0.28
1+2+3+4+6+8+9+10      10 -86.35 194.41  0.14   0.26
1+3+4+6+7+8+10         9 -87.65 194.68  0.42   0.23
1+2+3+4+6+7+8+9+10+11 12 -84.65 195.75  1.49   0.13
1+2+3+4+5+6+7+8+9+10  12 -84.88 196.22  1.95   0.10

Term codes: 
          BnrLgth.S            BnrWdt.S             cyanide            FlwrCt.S 
                  1                   2                   3                   4 
         FrstFlwr.S           InflNum.S         VegGrowth.S   BnrLgth.S:cyanide 
                  5                   6                   7                   8 
   BnrWdt.S:cyanide    cyanide:FlwrCt.S cyanide:VegGrowth.S 
                  9                  10                  11 

Model-averaged coefficients:  
(full average) 
                     Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)          0.978654   0.051169    0.051637  18.953  &lt; 2e-16 ***
BnrLgth.S            0.225054   0.062200    0.062681   3.590  0.00033 ***
BnrWdt.S            -0.072942   0.064461    0.064835   1.125  0.26058    
cyanide              0.042088   0.084783    0.085570   0.492  0.62282    
FlwrCt.S             0.169975   0.052873    0.053364   3.185  0.00145 ** 
InflNum.S            0.497923   0.049505    0.049957   9.967  &lt; 2e-16 ***
VegGrowth.S          0.066116   0.060037    0.060342   1.096  0.27321    
BnrLgth.S:cyanide   -0.297258   0.124060    0.124926   2.379  0.01734 *  
BnrWdt.S:cyanide     0.186530   0.137538    0.138125   1.350  0.17687    
cyanide:FlwrCt.S     0.235112   0.091214    0.092057   2.554  0.01065 *  
cyanide:VegGrowth.S -0.012129   0.047872    0.048135   0.252  0.80106    
FrstFlwr.S          -0.002749   0.015496    0.015604   0.176  0.86018    
 
(conditional average) 
                    Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)          0.97865    0.05117     0.05164  18.953  &lt; 2e-16 ***
BnrLgth.S            0.22505    0.06220     0.06268   3.590  0.00033 ***
BnrWdt.S            -0.09420    0.05800     0.05853   1.609  0.10753    
cyanide              0.04209    0.08478     0.08557   0.492  0.62282    
FlwrCt.S             0.16997    0.05287     0.05336   3.185  0.00145 ** 
InflNum.S            0.49792    0.04951     0.04996   9.967  &lt; 2e-16 ***
VegGrowth.S          0.08921    0.05295     0.05341   1.670  0.09487 .  
BnrLgth.S:cyanide   -0.29726    0.12406     0.12493   2.379  0.01734 *  
BnrWdt.S:cyanide     0.24090    0.10646     0.10743   2.242  0.02494 *  
cyanide:FlwrCt.S     0.23511    0.09121     0.09206   2.554  0.01065 *  
cyanide:VegGrowth.S -0.09170    0.10015     0.10110   0.907  0.36438    
FrstFlwr.S          -0.02619    0.04092     0.04131   0.634  0.52601    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The first part of the output breaks down which terms are part of which models and provides descriptive statistics for these models. Parameter estimates from the model averaging are also returned. Note there are two sets of estimates: the <em>full coefficients</em> set terms to 0 if they are not included in the model while averaging, whereas the <em>conditional coefficients</em> ignores the predictors entirely. The full coefficients are thus more conservative and it is best practice to interpret these.</p>
<p>To get a sense of what’s going on, a visual might be helpful. (But there are 6000 regressions to deal with! However will we plot them all??) Although the code is admittedly somewhat clunky<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, following chunk plots how predicted fitness (RFSeed) changes as a function of one of standardized trait (BnrLgth.S) value for the top 100 models (in gray) and using the full coefficients estimated after averaging the top five models, i.e., those with <span class="math inline">\(\Delta \text{AIC}_c &lt; 2\)</span> (in black). As expected, the averaged model lives somewhere between the top models. Given the slope of the averaged model, it seems the top fitting models are ones which predict a very strong relationship between fitness and the focal trait.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="do">### can ignore this code! focus on the plot.</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>BnrLgth.S_predictions <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(Thompson_data<span class="sc">$</span>BnrLgth.S),</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">max</span>(Thompson_data<span class="sc">$</span>BnrLgth.S), </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>                               <span class="at">length=</span><span class="dv">100</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>predct_values <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">BnrLgth.S =</span> BnrLgth.S_predictions,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">VegGrowth.S =</span> <span class="dv">0</span>, <span class="at">cyanide =</span> <span class="dv">0</span>, <span class="at">BnrWdt.S =</span> <span class="dv">0</span>, <span class="at">FrstFlwr.S =</span> <span class="dv">0</span>, </span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">InflNum.S =</span> <span class="dv">0</span>, <span class="at">FlwrCt.S =</span> <span class="dv">0</span>, <span class="at">InflWdt.S =</span> <span class="dv">0</span>, <span class="at">InflHt.S =</span> <span class="dv">0</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># predicted values...only varying BnrLgth.S, all other covariates set = 0 for plotting purposes</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">get.models</span>(GTmodel_dredge, <span class="at">subset =</span> i)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cbind</span>(<span class="at">RFSeed_predicted =</span> <span class="fu">predict</span>(model[[<span class="dv">1</span>]], <span class="at">newdata =</span> predct_values), </span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">BnrLgth.S =</span> BnrLgth.S_predictions,</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">index =</span> i) <span class="ot">-&gt;</span> predictions[[i]]</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="co"># only top 100 models</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>predictions_all <span class="ot">&lt;-</span> <span class="fu">do.call</span>(rbind, predictions)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>predictions_ave <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">BnrLgth.S =</span> BnrLgth.S_predictions,</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>                              <span class="at">RFSeed_predicted =</span> <span class="fl">0.9786538</span> <span class="sc">+</span> <span class="fl">0.225054</span><span class="sc">*</span>BnrLgth.S_predictions)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(predictions_all) <span class="sc">%&gt;%</span> </span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> BnrLgth.S, <span class="at">y =</span> RFSeed_predicted, <span class="at">group =</span> <span class="fu">as.factor</span>(index)),</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>            <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"lightgray"</span>) <span class="sc">+</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> predictions_ave, <span class="at">inherit.aes =</span> F,</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> BnrLgth.S, <span class="at">y =</span> RFSeed_predicted), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="lec10-model-selection_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># note: all other trait values are =0 for the purpose of visualization</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="summaryand-some-words-of-caution" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="summaryand-some-words-of-caution"><span class="header-section-number">12.9</span> Summary…and some words of caution</h2>
<ul>
<li>As we have seen, many problems can be formulated in terms of choosing between candidate models or deciding if a given model is an appropriate description of the data. Model selection is important and active area of statistics, and is complementary to the statistics we have so far discussed in the course.</li>
<li>The tools to preform model selection will depend on the application. It is often difficult (or impossible) to fit linear models to high dimensional data, so tools like ridge and LASSO regression are very useful in that they 1) get the job done and 2) can be used to preform feature selection.</li>
<li>Model selection depends on the set set of models considered. You can’t identify a model as being the “best” fit to the data if you exclude it from the analysis.</li>
<li>Statistical significance and biological significance are different things!</li>
<li>Stepwise selection is problematic. Don’t do it. It gives rise to biased regression coefficients, <span class="math inline">\(p\)</span> values, etc. and provides little insight into how the world works.</li>
<li>DO *clap* NOT *clap* USE *clap* <code>dredge</code> *clap* TO *clap* <span class="math inline">\(p\)</span> *clap* HACK *clap*.</li>
</ul>
</section>
<section id="references-and-additional-reading" class="level2" data-number="12.10">
<h2 data-number="12.10" class="anchored" data-anchor-id="references-and-additional-reading"><span class="header-section-number">12.10</span> References and additional reading</h2>
<ol type="1">
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0169534703003458">Johnson &amp; Omland 2004. Model selection in ecology and evolution. <em>Trends in Ecology and Evolution</em>.</a></li>
<li>Burnham &amp; Anderson 2002. <em>Model Selection and Multimodel Inference</em> (2nd ed.).</li>
<li>Zuur et al.&nbsp;2009. <em>Mixed Effects Models and Extensions in Ecology with R</em>.</li>
</ol>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that models that include interaction terms will automatically also include the interacting terms as independent predictors. In other words, you cannot have a model that contain <em>only</em> the interaction term but not the independent effects.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>These AIC<sub>c</sub> score are <em>close</em>! It barely made our predetermined cut off of 2 units. This is a very good example of why it is important to decide on a “recipe” for model selection before we do anything. Let’s pretend we are very attached to the random slope. We see that the AIC<sub>c</sub> scores are really close! We might think to ourselves “you know what, maybe 2 units is too stringent, let’s set the cut off at 3 instead” and then proceed to happily not-reject the intercept-slope model because it’s indistinguishable from the intercept-only model. Of course, there is nothing stopping anybody from just swapping out the recipe under the table half way through without telling anyone and just pretending it was like that all along.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Whatever works! :P<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./lec09-mixed-effects-models.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Linear mixed models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./lec11-multivariate-stats.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multivariate statistics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>