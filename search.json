[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "",
    "text": "Syllabus",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#land-acknowledgement",
    "href": "index.html#land-acknowledgement",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Land Acknowledgement",
    "text": "Land Acknowledgement\nAlthough our students come from many locations around the world, we wish to recognize the land on which the University of Toronto was built. This land has historically been and still is the home of the Huron-Wendat, the Seneca, and the Mississaugas of the Credit River.\nThere is a First Nations House for Indigenous Student Services on campus. Please refer to their web page for more resources and information about honouring our land and their services for students.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#diversity-and-inclusion-statement",
    "href": "index.html#diversity-and-inclusion-statement",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Diversity and inclusion statement",
    "text": "Diversity and inclusion statement\nAs students, you all have something unique and special to offer to science. It is our intent that students from all backgrounds and perspectives be well served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that students bring to this class be recognized as a resource, strength, and benefit.\nDiversity can refer to multiple ways that we identify ourselves, including but not limited to race, national origin, language, cultural heritage, physical ability, neurodiversity, age, sexual orientation, gender identity, religion, and socio-economic class. Each of these varied, and often intersecting, identities, along with many others not mentioned here, shape the perspectives we bring to this class, to this department, and to the greater EEB community. We will work to promote diversity, equity, and inclusion not only because diversity fuels excellence and innovation, but because we want to pursue justice.\nWe expect that everybody in this class will respect each other, and demonstrate diligence in understanding how other people’s perspectives, behaviors, and worldviews may be different from their own. Racist, sexist, colonialist, homophobic, transphobic, and other abusive and discriminatory behavior and language will not be tolerated in this class and will result in disciplinary action, such as removal from class session or revocation of group working privileges. Please consult the University of Toronto Code of Student Conduct for details on unacceptable conduct and possible sanctions.\nPlease let us know if something said or done in this class, by either a member of the teaching team or other students, is particularly troubling or causes discomfort or offense. While our intention may not be to cause discomfort or offense, the impact of what happens throughout the course is not to be ignored and is something that we consider to be very important and deserving of attention. If and when this occurs, there are several ways to alleviate some of the discomfort or hurt you may experience:\n\nDiscuss the situation privately with a member of the teaching team. We are always open to listening to students’ experiences, and want to work with students to find acceptable ways to process and address the issue.\nNotify us of the issue through another source such as a trusted faculty member or a peer. If for any reason you do not feel comfortable discussing the issue directly with us, we encourage you to seek out another, more comfortable avenue to address the issue.\nContact the Anti-Racism and Cultural Diversity Office to report an incident and receive complaint resolution support, which may include consultations and referrals.\n\nWe acknowledge our imperfections while we also fully commit to the work, inside and outside of our classrooms, of building and sustaining a community that increasingly embraces these core values. Your suggestions and feedback are encouraged and appreciated. Please let us know ways to improve the effectiveness of the course for you personally or for other students or student groups.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#wellness-statement",
    "href": "index.html#wellness-statement",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Wellness statement",
    "text": "Wellness statement\nWe on the teaching team value your health and wellness. In order to succeed in this class, in university, and beyond, you must balance your work with rest, exercise, and attention to your mental and physical health. Working until exhaustion is NOT a badge of honor. If you are finding it difficult to balance your health and well-being with your work in this class, please do not hesitate to let us know. We are happy to help connect you with resources and services on campus and also to make accommodations to our course plan as needed. Our inboxes are always open, and we are also available for virtual chats by appointment. You have our support, and we believe in you.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Course Overview",
    "text": "Course Overview\nThis course covers statistical and data analysis, reproducible quantitative methods, and scientific computing in R to answer questions in ecology and evolutionary biology. Statistical and data analysis, modeling, and computing are essential skills for all biologists. This course is designed to meet a growing demand for reproducible, openly accessible, analytically thorough, and well-documented science. Students will learn to analyze and visualize data, develop mathematical models, and document their research using the R programming language. No programming experience is required.\nPrerequisites: BIO220H1 and one of EEB225H1, STA288H1, or STA220H1",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#time",
    "href": "index.html#time",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Time",
    "text": "Time\nTuesdays 2:10 - 4:00 PM and Thursdays 12:10 - 2:00 PM EST.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#class-locations",
    "href": "index.html#class-locations",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Class Locations",
    "text": "Class Locations\nAll classes will be on the St. George campus. On Tuesdays, we will be in 371 Bloor, Room 36. On Thursdays, we will be in Sidney Smith Hall, Room 561.\n\n\n\nOffice hours (in EST)\n\n\n\n\n\n\nMete\nMon 1-2pm\nESC3044\n\n\nZoë\nWed 2-3pm\nESC3044\n\n\nJessie\nTu 4-5pm\n371 Bloor, Room 36\n\n\nGavia\nTh 2-3pm\nESC3044",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#contact-protocol",
    "href": "index.html#contact-protocol",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Contact protocol",
    "text": "Contact protocol\nIf you have assignment-related questions, please email Gavia AND Jessie. If you have course-related or lecture-related questions, please email Mete AND Zoë. Include “EEB313” in the subject line. If you do not receive a reply within 48 hours (excluding weekends), please send us a reminder.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#absence-policy",
    "href": "index.html#absence-policy",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Absence policy",
    "text": "Absence policy\nIf you are feeling unwell, please do not come to class. Instead, take the time to recover fully. Please let us know if you are feeling sick - you will not be penalized for missing a lecture, and we will do our best to ensure that you are up-to-date with class materials when you return.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#accessibility-needs",
    "href": "index.html#accessibility-needs",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Accessibility needs",
    "text": "Accessibility needs\nIf you require accommodations for a disability, or have any accessibility concerns about the course or course materials, please notify your course instructors (Mete and Zoë), or contact Accessibility Services, as soon as possible regarding accommodations.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#course-learning-outcomes",
    "href": "index.html#course-learning-outcomes",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Course learning outcomes",
    "text": "Course learning outcomes\n\nDevelop proficiency in the programming language R.\nUse R to apply appropriate statistical tools to analyze and interpret data.\nDevelop familiarity with mathematical models used in EEB.\nDevelop familiarity with the command line and Git.\nLearn and use techniques and best practices for reproducible, high-quality science.\nLearn how to work as part of a research team to produce a scientific product.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#lecture-schedule",
    "href": "index.html#lecture-schedule",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Lecture schedule",
    "text": "Lecture schedule\n\n\n\nWeek\nDate\nTopic\nInstructor\n\n\n\n\n1\nSep 3\nIntro to course\nEveryone\n\n\n1\nSep 5\nBase R: assignment, vectors, functions, strings, loops, etc.\nZoë\n\n\n2\nSep 10\nIntro to command line and GitHub\nMete\n\n\n2\nSep 12\nData wrangling!\nZoë\n\n\n3\nSep 17\nData visualization in ggplot\nZoë\n\n\n4\nSep 19\nExploratory data analysis\nZoë\n\n\n4\nSep 24\nReview using Farrell & Davies (2019) dataset\n\n\n\n4\nSep 26\nProject work\n\n\n\n5\nOct 01\nIntroduction to statistical inference I\nMete\n\n\n5\nOct 03\nIntroduction to statistical inference II\nMete\n\n\n6\nOct 08\nLinear models I\nMete\n\n\n6\nOct 10\nLinear models II\nMete\n\n\n7\nOct 15\nModel selection\nJessie\n\n\n7\nOct 17\nMultivariate statistics\nGavia\n\n\n8\nOct 22\nMathematical models in ecology and evolution I\nMete\n\n\n8\nOct 24\nMathematical models in ecology and evolution II\nMete\n\n\n9\nOct 29\nReading break\n-\n\n\n9\nOct 31\nReading break\n-\n\n\n10\nNov 05\nProject work\n\n\n\n10\nNov 07\nProject work\n\n\n\n11\nNov 12\nProject work\n\n\n\n11\nNov 14\nProject work\n\n\n\n12\nNov 19\nProject work\n\n\n\n12\nNov 21\nProject work\n\n\n\n13\nNov 26\nProject work\n\n\n\n13\nNov 28\nProject work\n\n\n\n14\nDec 03\nGroup presentations\nEveryone",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#assessment-schedule",
    "href": "index.html#assessment-schedule",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Assessment schedule",
    "text": "Assessment schedule\n\n\n\n\n\n\n\n\n\n\nAssignment\nType\nSubmitted on\nDue date\nMarks\n\n\n\n\nIndividual interest description\nIndividual\nQuercus\nSep 12\n1\n\n\nBasic R, command line, & Git\nIndividual\nQuercus\nSep 19\n8\n\n\nData wrangling\nIndividual\nQuercus\nSep 26\n8\n\n\nData visualization and exploration\nIndividual\nQuercus\nOct 03\n8\n\n\nIntro inference and LMs\nIndividual\nQuercus\nOct 10\n8\n\n\nProject proposal\nGroup\nGitHub\nOct 17\n3\n\n\nLMs, model selection, and multivariate\nIndividual\nQuercus\nOct 24\n8\n\n\nChallenge assignment\nIndividual\nQuercus\nNov 15\n20\n\n\nMid-project update\nGroup\nGitHub\nNov 21\n6\n\n\nPresentation\nGroup\nIn-class\nDec 03\n10\n\n\nFinal report\nGroup\nGitHub\nDec 10\n20\n\n\n\nThere are 100 marks in total. Your final course mark will be the sum of your assignment scores, which will be translated to a letter grade according to the official grading scale of the Faculty of Arts and Science.\nAssignments will be distributed and submitted in the R Markdown format via Quercus. Assignments will be handed out on Thursdays after class and are due at 8:00 PM on the following Thursday.\nThe Challenge Assignment is equivalent to a take home exam. The format will be the same as the other assignments, but this assignment is designed challenge you to go a little beyond what was taught in class. It will be distributed on 9:00 AM on Nov 11, and it will be due 11:59 PM on Nov 15. Students are welcome to work in a group on this assignment, but each student must submit their own original work. No extensions will be granted on this assignment except under the same extra-ordinary circumstances akin to those under which an exam might be deferred. We only expect you to do your best!\nPer our stance on supporting student’s mental health, we are happy to accommodate a 72-hour extension for one of the assignments, no questions asked. Otherwise, except under extenuating circumstances, there will be a penalty of 5% per day (including weekends) for all late submissions. If you foresee needing an extension, please email Zoë AND Mete as soon as possible. This policy does not apply to the Challenge Assignment, Presentation, or Final Report.\nAll submissions to Quercus/GitHub must be submitted as PDFs (i.e., knitted).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#improving-your-writing-skills",
    "href": "index.html#improving-your-writing-skills",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Improving your writing skills",
    "text": "Improving your writing skills\nEffective communication is crucial in science. The University of Toronto provides services to help you improve your writing, from general advices on effective writing to writing centers and writing courses. The Faculty of Arts & Science also offers an English Language Learning (ELL) program, which provides free individualized instruction in English skills. Take advantage of these!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#academic-integrity",
    "href": "index.html#academic-integrity",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "Academic integrity",
    "text": "Academic integrity\nYou should be aware of the University of Toronto Code of Behaviour on Academic Matters. Also see How Not to Plagiarize. Notably, it is NOT appropriate to use large sections from internet sources, and inserting a few words here and there does not make it an original piece of writing. Be careful in using internet sources – most online material are not reviewed and there are many errors out there. Make sure you read material from many sources (published, peer-reviewed, trusted internet sources) and that you write an original text using this information. Always cite your sources. In case of doubt about plagiarism, talk to your instructors and TAs. Please make sure that what you submit for the final project does not overlap with what you submit for other classes, such as the 4th-year research project.\n\nOn the use of generative AI\nWe recognize that students use generative artificial intelligence tools such as ChatGPT. If you use such tools in this course, we ask that you let us know. Given the limitations of these tools, and the fact we will be available to support your learning without the use of AI, we would recommend that you be very cautious when using generative AI. On any submissions where, e.g., ChatGPT, is used please indicate in the answer to the question how the tool was used.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "index.html#fas-student-engagement-programs",
    "href": "index.html#fas-student-engagement-programs",
    "title": "EEB313: Quantitative Methods in R for Biology",
    "section": "FAS student engagement programs",
    "text": "FAS student engagement programs\nThere are a few programs on campus aimed at increasing student engagement with their coursework and keeping them socially connected. Recognized Study Groups are voluntary, peer-led study groups of up to 8 students enrolled in the same course. Meet to Complete are online drop-in study sessions for A&S undergrads. These are worth checking out if you are interested in participating in a study group.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "about-us.html",
    "href": "about-us.html",
    "title": "2024 teaching team",
    "section": "",
    "text": "Course instructors\nMete is a 3rd year PhD student in the Dept. Ecology and Evolutionary Biology at UTSG, and is co-advised by Matt Osmond & Nicole Mideo. He uses mathematical models to address questions in evolutionary genetics and ecology. He is currently developing theory to understand patterns, causes, and consequences of recombination rate variation. Mete was an undergraduate math & statistics student at the University of Idaho. There, he worked on the ecology of gene drive interventions against vectored diseases, understanding how continuous spatial structure can affect species coexistence, and forecasting the dynamics of Chinook salmon in the Willamette River system. He loves R - and teaching this course! Outside of science, Mete enjoys listening to podcasts, cooking, and cycling between Toronto neighborhoods in search of coffee.\nZoë is a PhD student in the Wright and Barrett labs at UTSG. She studies the genome of a weedy plant to better understand how transposable elements affect sex chromosome evolution. She taught herself how to use R during her honours thesis and fell in love because it was much kinder than Lisp or C++ and, most importantly, because aesthetics. Zoë makes plots from aggressively large genomic data sets and spends a lot of time literally bash-ing her data into a file small enough for her computer to load into RStudio. For Zoë, the best way to work in R is while patting her puppies.",
    "crumbs": [
      "2024 teaching team"
    ]
  },
  {
    "objectID": "about-us.html#course-instructors",
    "href": "about-us.html#course-instructors",
    "title": "2024 teaching team",
    "section": "",
    "text": "Mete Yuksel (mete.yuksel@mail.utoronto.ca)\n\n\n\n\n\n\nZoe Humphries (zoe.humphries@mail.utoronto.ca)",
    "crumbs": [
      "2024 teaching team"
    ]
  },
  {
    "objectID": "about-us.html#teaching-assistants",
    "href": "about-us.html#teaching-assistants",
    "title": "2024 teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\nGavia Lertzman-Lepofsky (gavia.lertzmanlepofsky@mail.utoronto.ca)\n\n\nGavia is a PhD candidate in the Mahler lab on the StG campus. She works with the tropical Anolis lizards to understand how macroevolution shapes local patterns of community diversity and structure. When she’s not wandering around Caribbean islands catching lizards or spraying them with paint, she is happily ensconced on her couch working in R or exploring the many bakeries and bookstores of Toronto.\n\n\n\nJessie Wang (jae.wang@mail.utoronto.ca)\n\n\nJessie is a PhD student in the Frederickson lab at UTSG. She studies plant-microbe interactions using high- throughput experimentation in duckweeds. She fell in love with R during her time as an undergraduate and took EEB313 in 2020, simultaneously sharpening her coding skills while conducting research alone in the lab. Jessie loves to spend too much money on fancy coffee as she types away, making sure her code is well-annotated and her figures look beautiful. Outside of work, she enjoys caring for her many houseplants and aquariums, finding new delicious eats, and admiring other people’s pets.",
    "crumbs": [
      "2024 teaching team"
    ]
  },
  {
    "objectID": "downloadingR.html",
    "href": "downloadingR.html",
    "title": "Installing R & Ubuntu",
    "section": "",
    "text": "Introduction\nThis course makes use of R and RStudio, as well as the command line. The goal of these notes is to help you install R and Rstudio and, if you use a Windows machine, to install Ubuntu. If you have any issues, let’s resolve them in advance so that you can make the most of our time together! The goal here is to ensure that your computer is set up for the rest of the course. If you can’t complete these steps, please email Mete and Zoë as soon as possible.",
    "crumbs": [
      "Installing R & Ubuntu"
    ]
  },
  {
    "objectID": "downloadingR.html#installing-r-rstudio",
    "href": "downloadingR.html#installing-r-rstudio",
    "title": "Installing R & Ubuntu",
    "section": "Installing R & RStudio",
    "text": "Installing R & RStudio\n\nDownload R, a free software environment for statistical computing and graphics from CRAN, the Comprehensive R Archive Network. We recommend you install a precompiled binary distribution for your operating system – use the links up at the top of the CRAN page!\n\nNote: MacBook users with an Apple Silicon chip (e.g., M1 or M2) should install the “arm64” version of R, while MacBook users with an Intel chip should install the regular (64-bit) version of R. You can check your laptop’s hardware specifications by clicking the Apple icon (top left corner) \\&gt; About This Mac.\n\nInstall RStudio, a graphical user interface (GUI) for R. Click the link under “2: Install RStudio”. RStudio comes with a text editor, so there is no immediate need to install a stand-alone editor.\n\nIf R is already installed, ensure that the R version is 4.0 or higher. You can do this by opening RStudio, where you should see a multi-section window like below. Locate the quadrant named “Console”, and put your cursor at the start of the prompt indicated by the &gt; symbol. Type sessionInfo() - make sure that only the I at the start of Info is capitalized and you are including the round brackets. Press enter to run this command and R should return an output to you. The first line shows what version of R is installed. Ensure that the R version installed is at least 4.0.",
    "crumbs": [
      "Installing R & Ubuntu"
    ]
  },
  {
    "objectID": "downloadingR.html#installing-r-packages",
    "href": "downloadingR.html#installing-r-packages",
    "title": "Installing R & Ubuntu",
    "section": "Installing R packages",
    "text": "Installing R packages\n\nTinyTex\nThere is one package we have to install first before we can create PDF reports, which will be necessary for assignments and the project. Copy and paste into the console (where the \\&gt; symbol is) the two lines of code below to install a package called tinytex.\n\ninstall.packages(\"tinytex\") \ntinytex::install_tinytex()\n\n\n\nTidyverse\n\nCopy and paste the below code into your console.\n\n\ninstall.packages(c(\"tidyverse\", \"data.table\"), dependencies = TRUE)\n\nDuring installation, if you ever get the below message, click “No”.\n\nIf you get the message “Do you want to install from sources the packages which need compilation? (Yes/no/cancel)” in the Console, type “Yes” and press enter.\n\nCheck that the tinytex and tidyverse packages have been installed correctly. To do this, go to the bottom right pane and click the tab for “Packages”. If you can search for and find the below packages, then they have been installed! They do not need to be checked off. Alternatively, go to the Console and type library(tidyverse) to verify that the package is installed. An error along the lines “there is no package called tidyverse” will be returned if the package is not installed.",
    "crumbs": [
      "Installing R & Ubuntu"
    ]
  },
  {
    "objectID": "downloadingR.html#installing-ubuntu",
    "href": "downloadingR.html#installing-ubuntu",
    "title": "Installing R & Ubuntu",
    "section": "Installing Ubuntu",
    "text": "Installing Ubuntu\nIf you are a Windows user, you will need to install Ubuntu before the command line and GitHub lecture. (If you are a Mac user, it is safe to stop here.) The steps to install Unbuntu are as follows. Do not attempt to follow these instructions while your computer is plugged into an electrical outlet.\n\nSearch for “Turn Windows features on or off” in the Windows search bar and ensure that “Windows Subsystem for Linux” is turned on. This will force your machine to restart.\nDownload Ubuntu from this link.\nOpen the app once installed. The app will say it is installing and, once finished, will prompt you to make a username and password. (The password won’t show up, but the keystrokes are being recognized. You will be asked to confirm the password, too.)\n\nImportantly, you can open Ubuntu via Command Prompt by typing ubuntu. Here is a picture illustrating how to do this:\n\nAfter following these steps, you can check everything has been installed correctly by going to File Explorer and verifying that there is a Linux tab – scroll all the way down and look for a penguin!",
    "crumbs": [
      "Installing R & Ubuntu"
    ]
  },
  {
    "objectID": "lectures/lec00-r_and_rstudio.html",
    "href": "lectures/lec00-r_and_rstudio.html",
    "title": "Introduction to the course",
    "section": "",
    "text": "Introduction to R\nR is a computing environment that combines numerical analysis tools for linear algebra; functions for classical and modern statistical analysis; and functions for graphics and data visualization. It is based on the programming language S, developed by John Chambers in the 1970s.\nThere are two ways to start R:\nWe will use the graphical user interface RStudio throughout this course. Although the GUI makes certain things easier, it is not necessary to use it when running an R script. For example, running the following code in R returns the sum of the numbers 1 and 2.\n1+2\n\n[1] 3\nRunning the code with a # at the beginning of the line results in the line being read as a comment. This means that the calculation which is specified in the line is not processed and the output not returned. Comments are a useful way to keep track of what line(s) of code do, multiple versions of the same code, etc.",
    "crumbs": [
      "Lectures",
      "Introduction to the course"
    ]
  },
  {
    "objectID": "lectures/lec00-r_and_rstudio.html#introduction-to-r",
    "href": "lectures/lec00-r_and_rstudio.html#introduction-to-r",
    "title": "Introduction to the course",
    "section": "",
    "text": "Run R on the command line. On a Mac, you would do this in the Terminal application. On a Windows machine, you would do this using, e.g., Ubuntu. We will cover the command line next week.\nClick the R icon on your desktop, assuming the software has already been installed.",
    "crumbs": [
      "Lectures",
      "Introduction to the course"
    ]
  },
  {
    "objectID": "lectures/lec00-r_and_rstudio.html#rstudio-and-the-r-notebook",
    "href": "lectures/lec00-r_and_rstudio.html#rstudio-and-the-r-notebook",
    "title": "Introduction to the course",
    "section": "RStudio and the R Notebook",
    "text": "RStudio and the R Notebook\nRStudio includes the R console, but also many other convenient functionalities, which makes it easier to get started and to work with R. When you launch RStudio, you will see four panels. Starting at the top left and going clockwise, these panels are:\n\nThe text editor panel. This is where we can write scripts, i.e. putting several commands of code together and saving them as a text document so that they are accessible for later and so that we can execute them all at once by running the script instead of typing them in one by one.\nThe environment panel, which shows us all the files and objects we currently loaded into R.\nThe files-plots-help panel. This panel shows the files in the current directory (the folder we are working out of), any plots we make later, and also documentation for various packages and functions. Here, the documentation is formatted in a way that is easier to read and also provides links to the related sections.\nThe console is another space we can input code, only now the code is executed immediately and doesn’t get saved at the end.\n\nTo change the appearance of your RStudio, navigate to Tools &gt; Global Options &gt; Appearance. You can change the font and size, and the editor theme. The default is “Textmate”, but if you like dark mode, a good option is “Tomorrow Night Bright”. You can also change how your panels are organized.\nIn the RStudio interface, we will be writing code in a format called the R Notebook. As the name entails, this interface works like a notebook for code, as it allows us to save notes about what the code is doing, the code itself, and any output we get, such as plots and tables, all together in the same document.\nWhen we are in the Notebook, the text we write is normal plain text, just as if we would be writing it in a text document. If we want to execute some R code, we need to insert a code chunk.\nYou insert a code chunk by either clicking the “Insert” button or pressing Ctrl/Command + Alt + i simultaneously. You could also type out the surrounding backticks, but this would take longer. To run a code chunk, you press the green arrow, or Ctrl/Command + Shift + Enter.\n\n1+2\n\n[1] 3\n\n\nAs you can see, the output appears right under the code block.\nThis is a great way to perform explore your data, since you can do your analysis and write comments and conclusions right under it all in the same document. A powerful feature of this workflow is that there is no extra time needed for code documentation and note-taking, since you’re doing your analyses and taking notes at the same time. This makes it great for both taking notes at lectures and to have as a reference when you return to your code in the future.",
    "crumbs": [
      "Lectures",
      "Introduction to the course"
    ]
  },
  {
    "objectID": "lectures/lec00-r_and_rstudio.html#r-markdown",
    "href": "lectures/lec00-r_and_rstudio.html#r-markdown",
    "title": "Introduction to the course",
    "section": "R Markdown",
    "text": "R Markdown\nThe text format we are using in the R Notebook is called R Markdown. This format allows us to combine R code with the Markdown text format, which enables the use of certain characters to specify headings, bullet points, quotations and even citations. A simple example of how to write in Markdown is to use a single asterisk or underscore to emphasize text (*emphasis*) and two asterisks or underscores to strongly emphasize text (**strong emphasis**). When we convert our R Markdown text to other file formats, these will show up as italics and bold typeface, respectively. If you have used WhatsApp, you might already be familiar with this style of writing. In case you haven’t seen it before, you have just learned something about WhatsApp in your quantitative methods class…\nTo learn more about R Markdown, check out this reference.\n\nSaving data and generating reports\nTo save our notes, code, and graphs, all we have to do is to save the R Notebook file, and the we can open it in RStudio next time again. However, if we want someone else to look at this, we can’t always just send them the R Notebook file, because they might not have RStudio installed. Another great feature of R Notebooks is that it is really easy to export them to HTML, Microsoft Word, or PDF documents with figures and professional typesetting. There are actually many academic papers that are written entirely in this format and it is great for assignments and reports. (You might even use it to communicate with your collaborators!) Since R Notebook files convert to HTML, it is also easy to publish simple and good-looking websites in it, in which code chunks are embedded nicely within the text.\nLet’s try to create a document in R.\nFirst, let’s set up the YAML block. This is found at the top of your document, and it is where you specify the title of your document, what kind of output you want, etc.\n\n---\ntitle: \"Your title here\"\nauthor: \"Your name here\"\ndate: \"Insert date\"\noutput:\n  pdf_document: default\n---\n\nNext, let’s type code to perform the calculation we did above:\n\n1+2\n\n[1] 3\n\n\nTo create the output document, we say that we “knit” our R Markdown file into, e.g., a PDF. Simply press the Knit button here and the new document will be created.\nAs you can see in the knitted document, the title showed up as we would expect, and lines with pound sign(s) in front of them were converted into headers. Most importantly, we can see both the code and its output! Plots are generated directly in the report without us having to cut and paste images! If we change something in the code, we don’t have to find the new images and paste it in again, the correct one will appear right in your code.\nWhen you quit, R will ask you if you want to save the workspace (that is, all of the variables you have defined in this session); in general, you should say “no” to avoid clutter and unintentional confusion of results from different sessions. Note: When you say “yes” to saving your workspace, it is saved in a hidden file named .RData. By default, when you open a new R session in the same directory, this workspace is loaded and a message informing you so is printed: [Previously saved workspace restored]. It is often best practice to turn this feature off completely.",
    "crumbs": [
      "Lectures",
      "Introduction to the course"
    ]
  },
  {
    "objectID": "lectures/lec00-r_and_rstudio.html#practice-knitting",
    "href": "lectures/lec00-r_and_rstudio.html#practice-knitting",
    "title": "Introduction to the course",
    "section": "Practice knitting!",
    "text": "Practice knitting!\nFor your first assignment, you will need to write a short description of your interests in EEB and submitted the knitted document on Quercus. This assignment is due September 12. If you are having trouble knitting, which you will have to do throughout the course, come find us and we will help you troubleshoot.",
    "crumbs": [
      "Lectures",
      "Introduction to the course"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html",
    "href": "lectures/lec01-basic-r.html",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "",
    "text": "1.1 Lesson Preamble",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#lesson-preamble",
    "href": "lectures/lec01-basic-r.html#lesson-preamble",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "",
    "text": "1.1.1 Learning Objectives\n\nDefine the following terms as they relate to R: call, function, arguments, options.\nUse comments within code blocks.\nDo simple arithmetic operations in R using values and objects.\nCall functions and use arguments to change their default options.\nDefine our own functions\nInspect the content of vectors and manipulate their content.\nCreate for-loops\nDescribe what a data frame is.\nLoad external data from a .csv file into a data frame in R.\n\n1.1.2 Lecture outline\n\nSetting up your R Notebook (10 min)\nCreating objects/variables in R (10 min)\nUsing and writing functions (15 min)\nVectors and data types (10 min)\nSubsetting vectors (15 min)\nMissing data (10 min)\nLoops and vectorization (10 min)\nData set background (10 min)\nWhat are data frames? (10 min)",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#setting-up-the-r-notebook",
    "href": "lectures/lec01-basic-r.html#setting-up-the-r-notebook",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.2 Setting up the R Notebook",
    "text": "1.2 Setting up the R Notebook\nLet’s remove the template RStudio gives us, and add a title of our own.\n---\ntitle: Introduction to R\n---\nThis header block is called the YAML header. This is where we specify whether we want to convert this file to a HTML or PDF file. This will be discussed in more detail in another class. For now, we just care about including the lecture title here. If you are interested in playing with other YAML options, check out this guide.\nUnder this sentence, we will insert our first code chunk. Remember that you insert a code chunk by either clicking the “Insert” button or pressing Ctrl/Cmd + Alt + i simultaneously. To run a code chunk, you press the green arrow, or Ctrl/Cmd + Shift + Enter.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#creating-objects-in-r",
    "href": "lectures/lec01-basic-r.html#creating-objects-in-r",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.3 Creating objects in R",
    "text": "1.3 Creating objects in R\nAs we saw in our first class, you can get output from R simply by typing math in the console:\n\n3 + 5\n\n[1] 8\n\n12 / 7\n\n[1] 1.714286\n\n\nHowever, to do useful and interesting things, we need to assign values to objects.\n\nx &lt;- 3\nx + 5\n\n[1] 8\n\n\nYou can name an object in R almost anything you want:\n\njoel &lt;- 3\njoel + 5\n\n[1] 8\n\n\n\n1.3.0.1 Challenge\nSo far, we have created two variables, joel and x. What is the sum of these variables?\n\n\n1.3.1 Some tips on naming objects\n\nObjects can be given any name: x, current_temperature, thing, or subject_id.\nYou want your object names to be explicit and not too long.\nObject names cannot start with a number: x2 is valid, but 2x is not.\nR is also case sensitive: joel is different from Joel.\nAvoid using the names of existing functions (e.g. mean, df). You can check whether the name is already in use by using tab completion\nGenerally good to use underscores (_) to separate words in variable and function names\n\nIt is also recommended to use nouns for variable names, and verbs for function names. It’s important to be consistent in the styling of your code (where you put spaces, how you name variables, etc.). Using a consistent coding style1 makes your code clearer to read for your future self and your collaborators. RStudio will format code for you if you highlight a section of code and press Ctrl/Cmd + Shift + a.\n\n\n1.3.2 Preforming calculations\nWhen assigning a value to an object, R does not print anything. You can force R to print the value by using parentheses or by typing the object name:\n\nweight_kg &lt;- 55    # doesn't print anything\n(weight_kg &lt;- 55)  # but putting parentheses around the call prints the value of `weight_kg`\n\n[1] 55\n\nweight_kg          # and so does typing the name of the object\n\n[1] 55\n\n\nThe variable weight_kg is stored in the computer’s memory where R can access it, and we can start doing arithmetic with it efficiently. For instance, we may want to convert this weight into pounds (weight in pounds is 2.2 times the weight in kg):\n\n2.2 * weight_kg\n\n[1] 121\n\n\nWe can also change a variable’s value by assigning it a new one:\n\nweight_kg &lt;- 57.5\n2.2 * weight_kg\n\n[1] 126.5\n\n\nThis means that assigning a value to one variable does not change the values of other variables. For example, let’s store the animal’s weight in pounds in a new variable, weight_lb:\n\nweight_lb &lt;- 2.2 * weight_kg # Actually, 1 kg = 2.204623 lbs\n\nand then change weight_kg to 100.\n\nweight_kg &lt;- 100\n\n\n1.3.2.1 Challenge\nWhat do you think is the current content of the object weight_lb? 126.5 or 220?\n\nweight_lb\n\n\n\n1.3.2.2 Challenge\nWhat are the values after each statement in the following?\n\nmass &lt;- 47.5\nage  &lt;- 122\nmass &lt;- mass * 2.0      # mass?\nage  &lt;- age - 20        # age?\nmass_index &lt;- mass/age  # mass_index?",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#functions-and-their-arguments",
    "href": "lectures/lec01-basic-r.html#functions-and-their-arguments",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.4 Functions and their arguments",
    "text": "1.4 Functions and their arguments\n\n1.4.1 Understanding functions\nFunctions can be thought of as recipes. You give a few ingredients as input to a function, and it will generate an output based on these ingredients. Just as with baking, both the ingredients and the actual recipe will influence what comes out of the recipe in the end: will it be a cake or a loaf of bread? In R, the inputs to a function are not called ingredients, but rather arguments, and the output is called the return value of the function. A function does not technically have to return a value, but often does so. Functions are used to automate more complicated sets of commands and many of them are already predefined in R. A typical example would be the function sqrt(). The input (the argument) must be a number, and the return value (in fact, the output) is the square root of that number. Executing a function (‘running it’) is called calling the function. An example of a function call is:\n\nsqrt(9)\n\n[1] 3\n\n\nWhich is the same as assigning the value to a variable and then passing that variable to the function:\n\na &lt;- 9\nb &lt;- sqrt(a)\nb\n\n[1] 3\n\n\nHere, the value of a is given to the sqrt() function, the sqrt() function calculates the square root, and returns the value which is then assigned to variable b. This function is very simple, because it takes just one argument.\nThe return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset, as we will see later on.\nArguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.\n\n\n1.4.2 Tab-completion\nTo access help about sqrt, we are first going to learn about tab-completion. Type s and press Tab.\n\ns&lt;tab&gt;q\n\nYou can see that R gives you suggestions of what functions and variables are available that start with the letter s, and thanks to RStudio they are formatted in this nice list. There are many suggestions here, so let’s be a bit more specific and append a q, to find what we want. If we press enter or tab again, R will insert the selected option.\nYou can see that R inserts a pair of parentheses together with the name of the function. This is how the function syntax looks for R and many other programming languages, and it means that within these parentheses, we will specify all the arguments (the ingredients) that we want to pass to this function.\nIf we press tab again, R will helpfully display all the available parameters for this function that we can pass an argument to. The word parameter is used to describe the name that the argument can be passed to. More on that later.\n\nsqrt(&lt;tab&gt;\n\nThere are many things in this list, but only one of them is marked in purple. Purple here means that this list item is a parameter we can use for the function, while yellow means that it is a variable that we defined earlier.2\n\n\n1.4.3 Help with defined functions\nTo read the full help about sqrt, we can use the question mark, or type it directly into the help document browser.\n\n?sqrt\n\nAs you can see, sqrt() takes only one argument, x, which needs to be a numerical vector. Don’t worry too much about the fact that it says vector here; we will talk more about that later. Briefly, a numerical vector is one or more numbers. In R, every number is a vector, so you don’t have to do anything special to create a vector. More on vectors later.\nLet’s try a function that can take multiple arguments: round().\n\nround(&lt;tab&gt;)\n?round\n\nIf we try round with a value:\n\nround(3.14159)\n\n[1] 3\n\n\nHere, we’ve called round() with just one argument, 3.14159, and it has returned the value 3. That’s because the default is to round to the nearest whole number, or integer. If we want more digits we can pass an argument to the digits parameter, to specify how many decimals we want to round to.\n\nround(3.14159, digits = 2)\n\n[1] 3.14\n\n\nSo, above we pass the argument 2, to the parameter digits. Knowing this nomenclature is not essential for doing your own data analysis, but it will be very helpful when you are reading through help documents online and in RStudio.\nWe can leave out the word digits since we know it comes as the second parameter, after x.\n\nround(3.14159, 2)\n\n[1] 3.14\n\n\nAs you notice, we have been leaving out x from the beginning. If you provide the names for both the arguments, we can switch their order:\n\nround(digits = 2, x = 3.14159)\n\n[1] 3.14\n\n\nIt’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#writing-functions",
    "href": "lectures/lec01-basic-r.html#writing-functions",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.5 Writing functions",
    "text": "1.5 Writing functions\nIn this class, you will be working a lot with functions, especially those that someone else has already written. When you type sum, c(), or mean(), you are using a function that has been made previously and built into R. To remove some of the magic around these functions, we will go through how to make a basic function of our own. Let’s start with a simple example where we add two numbers together:\n\nadd_two_numbers &lt;- function(num1, num2) {\n    return(num1 + num2)\n}\nadd_two_numbers(4, 5)\n\n[1] 9\n\n\nAs you can see, running this function on two numbers returns their sum. We could also assign to a variable in the function and return the function.\n\nadd_two_numbers &lt;- function(num1, num2) {\n    my_sum &lt;- num1 + num2\n    return(my_sum)\n}\nadd_two_numbers(4, 5)\n\n[1] 9\n\n\n\n1.5.0.1 Challenge\nCan you write a function that calculates the mean of 3 numbers?",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#vectors-and-data-types",
    "href": "lectures/lec01-basic-r.html#vectors-and-data-types",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.6 Vectors and data types",
    "text": "1.6 Vectors and data types\nA vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function, which stands for “concatenate (combine/connect one after another) values into a vector” For example we can create a vector of animal weights and assign it to a new object weight_g:\n\nweight_g &lt;- c(50, 60, 65, 82) # Concatenate/Combine values into a vector\nweight_g\n\n[1] 50 60 65 82\n\n\nYou can also use the built-in command seq, to create a sequence of numbers without typing all of them in manually.\n\nseq(0, 30) # This is the same as just `0:30`\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n[26] 25 26 27 28 29 30\n\nseq(0, 30, 3) # Every third number\n\n [1]  0  3  6  9 12 15 18 21 24 27 30\n\n\nA vector can also contain characters:\n\nanimals &lt;- c('mouse', 'rat', 'dog')\nanimals\n\n[1] \"mouse\" \"rat\"   \"dog\"  \n\n\nThe quotes around “mouse”, “rat”, etc. are essential here and can be either single or double quotes. Without the quotes R will assume there are objects called mouse, rat and dog. As these objects don’t exist in R’s memory, there will be an error message.\nThere are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector:\n\nlength(weight_g)\n\n[1] 4\n\nlength(animals)\n\n[1] 3\n\n\nAn important feature of a vector is that all of the elements are the same type of data. The function class() indicates the class (the type of element) of an object:\n\nclass(weight_g)\n\n[1] \"numeric\"\n\nclass(animals)\n\n[1] \"character\"\n\n\nThe function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects:\n\nstr(weight_g)\n\n num [1:4] 50 60 65 82\n\nstr(animals)\n\n chr [1:3] \"mouse\" \"rat\" \"dog\"\n\n\nYou can use the c() function to add other elements to your vector:\n\nweight_g &lt;- c(weight_g, 90) # add to the end of the vector\nweight_g &lt;- c(30, weight_g) # add to the beginning of the vector\nweight_g\n\n[1] 30 50 60 65 82 90\n\n\nIn the first line, we take the original vector weight_g, add the value 90 to the end of it, and save the result back into weight_g. Then we add the value 30 to the beginning, again saving the result back into weight_g.\nWe can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating.\nAn atomic vector is the simplest R data type and it is a linear vector of a single type, e.g. all numbers. Above, we saw 2 of the 6 main atomic vector types that R uses: \"character\" and \"numeric\" (or \"double\"). These are the basic building blocks that all R objects are built from.\nVectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array). In this class, we will focus on data frames, which is most commonly used one for data analyses.\n\n1.6.0.1 Challenge\nWe’ve seen that atomic vectors can be of type character, numeric (or double), integer, and logical. But what happens if we try to mix these types in a single vector? Find out by using class to test these examples.\n\nnum_char &lt;- c(1, 2, 3, 'a')\nnum_logical &lt;- c(1, 2, 3, TRUE)\nchar_logical &lt;- c('a', 'b', 'c', TRUE)\ntricky &lt;- c(1, 2, 3, '4')\n\nThis happens because vectors can be of only one data type. Instead of throwing an error and saying that you are trying to mix different types in the same vector, R tries to convert (coerce) the content of this vector to find a “common denominator”. A logical can be turn into 1 or 0, and a number can be turned into a string/character representation. It would be difficult to do it the other way around: would 5 be TRUE or FALSE? What number would ‘t’ be?\nIn R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced?\nThis can be important to watch for in data sets that you import.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#subsetting-vectors",
    "href": "lectures/lec01-basic-r.html#subsetting-vectors",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.7 Subsetting vectors",
    "text": "1.7 Subsetting vectors\nIf we want to extract one or several values from a vector, we must provide one or several indices in square brackets. For instance:\n\nanimals &lt;- c(\"mouse\", \"rat\", \"dog\", \"cat\")\nanimals[2]\n\n[1] \"rat\"\n\nanimals[c(3, 2)]\n\n[1] \"dog\" \"rat\"\n\n\nWe can also repeat the indices to create an object with more elements than the original one:\n\nmore_animals &lt;- animals[c(1, 2, 3, 2, 1, 4)]\nmore_animals\n\n[1] \"mouse\" \"rat\"   \"dog\"   \"rat\"   \"mouse\" \"cat\"  \n\n\nR indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that was historically simpler for computers and can allow for more elegant code.\n\n1.7.1 Conditional subsetting\nAnother common way of subsetting is by using a logical vector. TRUE will select the element with the same index, while FALSE will not:\n\nweight_g &lt;- c(21, 34, 39, 54, 55)\nweight_g[c(TRUE, FALSE, TRUE, TRUE, FALSE)]\n\n[1] 21 39 54\n\n\nTypically, these logical vectors are not typed by hand, but are the output of other functions or logical tests. For instance, if you wanted to select only the values above 50:\n\nweight_g &gt; 50    # will return logicals with TRUE for the indices that meet the condition\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n## so we can use this to select only the values above 50\nweight_g[weight_g &gt; 50]\n\n[1] 54 55\n\n\nWe will consider conditions in more detail in the next few lectures.\n\n\n1.7.2 Strings (character vectors)\nJust a small note about character vectors, also called strings. There are built-in packages for subsetting them that we’ll learn about later. They can be particularly relevant for ecological and genomic data because important data can be nested in complicated strings of text (ex: extracting only the observations that occurred in wet habitats from a column of habitat descriptions or only genes with functions related to drought tolerance).\n\nstring1 &lt;- \"This is a string\" # you can include spaces between your quotes\nstring2 &lt;- c(string1, \"so is this\") # concatenate with another string\nstring2[2] # can access the second string via subsetting\n\n[1] \"so is this\"\n\n# Playing a bit with declaring variables\n\"You can include 'quotes' in a string\"\n\n[1] \"You can include 'quotes' in a string\"\n\nstring3 &lt;- 'You can include \"quotes\" in a string'\nstring3\n\n[1] \"You can include \\\"quotes\\\" in a string\"\n\n\"You can include \\\"matching quotes\\\" if you 'escape' them with a backslash (\\\\)\"\n\n[1] \"You can include \\\"matching quotes\\\" if you 'escape' them with a backslash (\\\\)\"",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#missing-data",
    "href": "lectures/lec01-basic-r.html#missing-data",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.8 Missing data",
    "text": "1.8 Missing data\nAs R was designed to analyze datasets, it includes the concept of missing data (which is uncommon in other programming languages). Missing data are represented in vectors as NA.\nWhen doing operations on numbers, most functions will return NA if the data you are working with include missing values. This feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm = TRUE to calculate the result while ignoring the missing values.\n\nheights &lt;- c(2, 4, 4, NA, 6)\nmean(heights)\n\n[1] NA\n\nmax(heights)\n\n[1] NA\n\nmean(heights, na.rm = TRUE)\n\n[1] 4\n\nmax(heights, na.rm = TRUE)\n\n[1] 6\n\n\n\n## Extract those elements which are not missing values.\nheights[!is.na(heights)]\n\n[1] 2 4 4 6\n\n## Returns the object with incomplete cases removed. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nna.omit(heights)\n\n[1] 2 4 4 6\nattr(,\"na.action\")\n[1] 4\nattr(,\"class\")\n[1] \"omit\"\n\n## Extract those elements which are complete cases. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nheights[complete.cases(heights)]\n\n[1] 2 4 4 6\n\n\nRecall that you can use the class() function to find the type of your atomic vector.\n\n1.8.0.1 Challenge\n\nUsing this vector of length measurements, create a new vector with the NAs removed.\n\n\nlengths &lt;- c(10, 24, NA, 18, NA, 20)\n\n\nUse the function median() to calculate the median of the lengths vector.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#loops-and-vectorization",
    "href": "lectures/lec01-basic-r.html#loops-and-vectorization",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.9 Loops and vectorization",
    "text": "1.9 Loops and vectorization\nLoops, specifically for-loops, are essential to programming in general. However, in R, you should avoid them as often as possible because there are more efficient ways of doing things that you should use instead. It is still important that you understand the concept of loops and you might also use them in some of your own functions if there is no vectorized way of going about what you want to do.\nYou can think of a for-loop as: “for each number contained in a list/vector, perform this operation” and the syntax basically says the same thing:\n\nv &lt;- c(2, 4, 6)\nfor (num in v) {\n    print(num)\n}\n\n[1] 2\n[1] 4\n[1] 6\n\n\nInstead of printing out every number to the console, we could also add numbers cumulatively, to calculate the sum of all the numbers in the vector:\n\n# To increment `w` each time, we must first create the variable,\n# which we do by setting `w &lt;- 0`, referred to as initializing.\n# This also ensures that `w` is zero at the start of the loop and\n# doesn't retain the value from last time we ran this code.\nw &lt;- 0\nfor (num in v) {\n    w &lt;- w + num\n}\nw\n\n[1] 12\n\n\nIf we put what we just did inside a function, we have essentially recreated the sum function in R.\n\nmy_sum &lt;- function(input_vector) {\n    vector_sum &lt;- 0\n    for (num in input_vector){\n        vector_sum &lt;- vector_sum + num\n    }\n    return(vector_sum)\n}\n\nmy_sum(v)\n\n[1] 12\n\n\nAlthough this gives us the same output as the built-in function sum, the built-in function has many more optimizations so it is much faster than our function. In R, it is always faster to try to find a way of doing things without writing a loop yourself. When you are reading about R, you might see suggestions that you should try to vectorize your code to make it faster. What people are referring to, is that you should not write for loops in R and instead use the ready-made functions that are much more efficient in working with vectors and essentially performs operations on entire vector at once instead of one number at a time. Conceptually, loops operate on one element at a time while vectorized code operates on all elements of a vector at once.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#dataset-background",
    "href": "lectures/lec01-basic-r.html#dataset-background",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.10 Dataset background",
    "text": "1.10 Dataset background\nToday, we will be working with real data from a longitudinal study of the species abundance in the Chihuahuan desert ecosystem near Portal, Arizona, USA. This study includes observations of plants, ants, and rodents from 1977 - 2002, and has been used in over 100 publications. More information is available in the abstract of this paper from 2009. There are several datasets available related to this study, and we will be working with datasets that have been preprocessed by the Data Carpentry to facilitate teaching. These are made available online as The Portal Project Teaching Database, both at the Data Carpentry website, and on Figshare. Figshare is a great place to publish data, code, figures, and more openly to make them available for other researchers and to communicate findings that are not part of a longer paper.\n\n1.10.1 Presentation of the survey data\nWe are studying the species and weight of animals caught in plots in our study area. The dataset is stored as a comma separated value (CSV) file. Each row holds information for a single animal, and the columns represent:\n\n\n\nColumn\nDescription\n\n\n\n\nrecord_id\nunique id for the observation\n\n\nmonth\nmonth of observation\n\n\nday\nday of observation\n\n\nyear\nyear of observation\n\n\nplot_id\nID of a particular plot\n\n\nspecies_id\n2-letter code\n\n\nsex\nsex of animal (“M”, “F”)\n\n\nhindfoot_length\nlength of the hindfoot in mm\n\n\nweight\nweight of the animal in grams\n\n\ngenus\ngenus of animal\n\n\nspecies\nspecies of animal\n\n\ntaxa\ne.g. rodent, reptile, bird, rabbit\n\n\nplot_type\ntype of plot\n\n\n\nTo read the data into R, we are going to use a function called read_csv. This function is contained in an R-package called readr. R-packages are a bit like browser extensions; they are not essential, but can provide nifty functionality. We will go through R-packages in general and which ones are good for data analyses. One useful option that read_csv includes, is the ability to read a CSV file directly from a URL, without downloading it in a separate step:\n\nsurveys &lt;- readr::read_csv('https://ndownloader.figshare.com/files/2292169')\n\nHowever, it is often a good idea to download the data first, so you have a copy stored locally on your computer in case you want to do some offline analyses, or the online version of the file changes or the file is taken down. You can either download the data manually or from within R:\n\ndownload.file(\"https://ndownloader.figshare.com/files/2292169\",\n              \"data/portal_data.csv\") # Saves to current directory with this name\n\nThe data is read in by specifying its local path.\n\nsurveys &lt;- readr::read_csv('data/portal_data.csv')\n\nRows: 34786 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): species_id, sex, genus, species, taxa, plot_type\ndbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis statement produces some output regarding which data type it found in each column. If we want to check this in more detail, we can print the variable’s value: surveys.\n\nsurveys\n\n# A tibble: 34,786 × 13\n   record_id month   day  year plot_id species_id sex   hindfoot_length weight\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1         1     7    16  1977       2 NL         M                  32     NA\n 2        72     8    19  1977       2 NL         M                  31     NA\n 3       224     9    13  1977       2 NL         &lt;NA&gt;               NA     NA\n 4       266    10    16  1977       2 NL         &lt;NA&gt;               NA     NA\n 5       349    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n 6       363    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n 7       435    12    10  1977       2 NL         &lt;NA&gt;               NA     NA\n 8       506     1     8  1978       2 NL         &lt;NA&gt;               NA     NA\n 9       588     2    18  1978       2 NL         M                  NA    218\n10       661     3    11  1978       2 NL         &lt;NA&gt;               NA     NA\n# ℹ 34,776 more rows\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\n\nThis displays a nice tabular view of the data, which also includes pagination when there are many rows and we can click the arrow to view all the columns. Technically, this object is actually a tibble rather than a data frame, as indicated in the output. The reason for this is that read_csv automatically converts the data into to a tibble when loading it. Since a tibble is just a data frame with some convenient extra functionality, we will use these words interchangeably from now on.\nIf we just want to glance at how the data frame looks, it is sufficient to display only the top (the first 6 lines) using the function head():\n\nhead(surveys)\n\n# A tibble: 6 × 13\n  record_id month   day  year plot_id species_id sex   hindfoot_length weight\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1         1     7    16  1977       2 NL         M                  32     NA\n2        72     8    19  1977       2 NL         M                  31     NA\n3       224     9    13  1977       2 NL         &lt;NA&gt;               NA     NA\n4       266    10    16  1977       2 NL         &lt;NA&gt;               NA     NA\n5       349    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n6       363    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#what-are-data-frames",
    "href": "lectures/lec01-basic-r.html#what-are-data-frames",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.11 What are data frames?",
    "text": "1.11 What are data frames?\nData frames are the de facto data structure for most tabular data, and what we use for statistics and plotting. A data frame can be created by hand, but most commonly they are generated by the function read_csv(); in other words, when importing spreadsheets from your hard drive (or the web).\nA data frame is a representation of data in the format of a table where the columns are vectors that all have the same length. Because the columns are vectors, they all contain the same type of data as we discussed in last class (e.g., characters, integers, factors). We can see this when inspecting the structure of a data frame with the function str():\n\nstr(surveys)\n\nspc_tbl_ [34,786 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : chr [1:34786] \"M\" \"M\" NA NA ...\n $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n $ genus          : chr [1:34786] \"Neotoma\" \"Neotoma\" \"Neotoma\" \"Neotoma\" ...\n $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : chr [1:34786] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nInteger refers to a whole number, such as 1, 2, 3, 4, etc. Numbers with decimals, 1.0, 2.4, 3.333, are referred to as floats. Factors are used to represent categorical data. Factors can be ordered or unordered, and understanding them is necessary for statistical analysis and for plotting. Factors are stored as integers, and have labels (text) associated with these unique integers. While factors look (and often behave) like character vectors, they are actually integers under the hood, and you need to be careful when treating them like strings.\n\n1.11.1 Inspecting data.frame objects\nWe already saw how the functions head() and str() can be useful to check the content and the structure of a data frame. Here is a non-exhaustive list of functions to get a sense of the content/structure of the data. Let’s try them out!\n\nSize:\n\ndim(surveys) - returns a vector with the number of rows in the first element and the number of columns as the second element (the dimensions of the object)\nnrow(surveys) - returns the number of rows\nncol(surveys) - returns the number of columns\n\nContent:\n\nhead(surveys) - shows the first 6 rows\ntail(surveys) - shows the last 6 rows\n\nNames:\n\nnames(surveys) - returns the column names (synonym of colnames() for data.frame objects)\nrownames(surveys) - returns the row names\n\nSummary:\n\nstr(surveys) - structure of the object and information about the class, length, and content of each column\nsummary(surveys) - summary statistics for each column\n\n\nNote: most of these functions are “generic”, they can be used on other types of objects besides data.frame.\n\n1.11.1.1 Challenge\nBased on the output of str(surveys), can you answer the following questions?\n\nWhat is the class of the object surveys?\nHow many rows and how many columns are in this object?\nHow many species have been recorded during these surveys?\n\n\n\n\n1.11.2 Indexing and subsetting data frames\nOur survey data frame has rows and columns (it has 2 dimensions). If we want to extract some specific data from it, we need to specify the “coordinates” we want from it. Row numbers come first, followed by column numbers. When indexing, base R data frames return a different format depending on how we index the data (i.e. either a vector or a data frame), but with enhanced data frames, tibbles, the returned object is almost always a data frame.\n\nsurveys[1, 1]   # first element in the first column of the data frame\n\n# A tibble: 1 × 1\n  record_id\n      &lt;dbl&gt;\n1         1\n\nsurveys[1, 6]   # first element in the 6th column\n\n# A tibble: 1 × 1\n  species_id\n  &lt;chr&gt;     \n1 NL        \n\nsurveys[, 1]    # first column in the data frame\n\n# A tibble: 34,786 × 1\n   record_id\n       &lt;dbl&gt;\n 1         1\n 2        72\n 3       224\n 4       266\n 5       349\n 6       363\n 7       435\n 8       506\n 9       588\n10       661\n# ℹ 34,776 more rows\n\nsurveys[1]      # first column in the data frame\n\n# A tibble: 34,786 × 1\n   record_id\n       &lt;dbl&gt;\n 1         1\n 2        72\n 3       224\n 4       266\n 5       349\n 6       363\n 7       435\n 8       506\n 9       588\n10       661\n# ℹ 34,776 more rows\n\nsurveys[1:3, 7] # first three elements in the 7th column\n\n# A tibble: 3 × 1\n  sex  \n  &lt;chr&gt;\n1 M    \n2 M    \n3 &lt;NA&gt; \n\nsurveys[3, ]    # the 3rd element for all columns\n\n# A tibble: 1 × 13\n  record_id month   day  year plot_id species_id sex   hindfoot_length weight\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1       224     9    13  1977       2 NL         &lt;NA&gt;               NA     NA\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\nsurveys[1:6, ]  # equivalent to head(surveys)\n\n# A tibble: 6 × 13\n  record_id month   day  year plot_id species_id sex   hindfoot_length weight\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1         1     7    16  1977       2 NL         M                  32     NA\n2        72     8    19  1977       2 NL         M                  31     NA\n3       224     9    13  1977       2 NL         &lt;NA&gt;               NA     NA\n4       266    10    16  1977       2 NL         &lt;NA&gt;               NA     NA\n5       349    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n6       363    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\n\n: is a special operator that creates numeric vectors of integers in increasing or decreasing order; test 1:10 and 10:1 for instance. This works similarly to seq, which we looked at earlier in class:\n\n0:10\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nseq(0, 10)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\n# We can test if all elements are the same\n0:10 == seq(0,10)\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\nall(0:10 == seq(0,10))\n\n[1] TRUE\n\n\nYou can also exclude certain parts of a data frame using the “-” sign:\n\nsurveys[,-1]    # All columns, except the first\n\n# A tibble: 34,786 × 12\n   month   day  year plot_id species_id sex   hindfoot_length weight genus  \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  \n 1     7    16  1977       2 NL         M                  32     NA Neotoma\n 2     8    19  1977       2 NL         M                  31     NA Neotoma\n 3     9    13  1977       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 4    10    16  1977       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 5    11    12  1977       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 6    11    12  1977       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 7    12    10  1977       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 8     1     8  1978       2 NL         &lt;NA&gt;               NA     NA Neotoma\n 9     2    18  1978       2 NL         M                  NA    218 Neotoma\n10     3    11  1978       2 NL         &lt;NA&gt;               NA     NA Neotoma\n# ℹ 34,776 more rows\n# ℹ 3 more variables: species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\nsurveys[-c(7:34786),] # Equivalent to head(surveys)\n\n# A tibble: 6 × 13\n  record_id month   day  year plot_id species_id sex   hindfoot_length weight\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1         1     7    16  1977       2 NL         M                  32     NA\n2        72     8    19  1977       2 NL         M                  31     NA\n3       224     9    13  1977       2 NL         &lt;NA&gt;               NA     NA\n4       266    10    16  1977       2 NL         &lt;NA&gt;               NA     NA\n5       349    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n6       363    11    12  1977       2 NL         &lt;NA&gt;               NA     NA\n# ℹ 4 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, taxa &lt;chr&gt;, plot_type &lt;chr&gt;\n\n\nAs well as using numeric values to subset a data.frame (or matrix), columns can be called by name, using one of the four following notations: \n\nsurveys[\"species_id\"]       # Result is a data.frame\n\n# A tibble: 34,786 × 1\n   species_id\n   &lt;chr&gt;     \n 1 NL        \n 2 NL        \n 3 NL        \n 4 NL        \n 5 NL        \n 6 NL        \n 7 NL        \n 8 NL        \n 9 NL        \n10 NL        \n# ℹ 34,776 more rows\n\nsurveys[, \"species_id\"]     # Result is a data.frame\n\n# A tibble: 34,786 × 1\n   species_id\n   &lt;chr&gt;     \n 1 NL        \n 2 NL        \n 3 NL        \n 4 NL        \n 5 NL        \n 6 NL        \n 7 NL        \n 8 NL        \n 9 NL        \n10 NL        \n# ℹ 34,776 more rows\n\n\nFor our purposes, these notations are equivalent. RStudio knows about the columns in your data frame, so you can take advantage of the autocompletion feature to get the full and correct column name.\nAnother syntax that is often used to specify column names is $. In this case, the returned object is actually a vector. We will not go into detail about this, but since it is such common usage, it is good to be aware of this.\n\n# We use `head()` since the output from vectors are not automatically cut off\n# and we don't want to clutter the screen with all the `species_id` values\nhead(surveys$species_id)          # Result is a vector\n\n[1] \"NL\" \"NL\" \"NL\" \"NL\" \"NL\" \"NL\"\n\n\n\n1.11.2.1 Challenge\n\nCreate a data.frame (surveys_200) containing only the observations from row 200 of the surveys dataset.\nNotice how nrow() gave you the number of rows in a data.frame?\n\nUse that number to pull out just that last row in the data frame.\nCompare that with what you see as the last row using tail() to make sure it’s meeting expectations.\nPull out that last row using nrow() instead of the row number.\nCreate a new data frame object (surveys_last) from that last row.\n\nUse nrow() to extract the row that is in the middle of the data frame. Store the content of this row in an object named surveys_middle.\nCombine nrow() with the - notation above to reproduce the behavior of head(surveys) keeping just the first through 6th rows of the surveys dataset.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#exporting-data",
    "href": "lectures/lec01-basic-r.html#exporting-data",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "1.12 Exporting data",
    "text": "1.12 Exporting data\nAs you begin to play with your raw data, you may want to export these new, processed, datasets to share them with your collaborators or for archival. Similar to the read_csv() function used for reading CSV files into R, there is a write_csv() function that generates CSV files from data frames.\nManually create a new folder called “data-processed” in your directory. Alternatively, get R to help you with it.\n\ndir.create(\"Processed data\")\n\nWe are going to prepare a cleaned up version of the data without NAs.\n\n# Note that this omits observations with NA in *any* column.\n# There is no way to control which columns to use.\nsurveys_complete_naomit &lt;- na.omit(surveys)\n\n# Compare the dimensions of the original and the cleaned data frame\ndim(surveys)\n\n[1] 34786    13\n\ndim(surveys_complete_naomit)\n\n[1] 30676    13\n\n\nNow that our dataset is ready, we can save it as a CSV file in our Processed data folder.\n\n# To save to current directory\nwrite_csv(surveys_complete_naomit, \"surveys_complete_naomit.csv\")\n\n# To save to newly created directory\nwrite_csv(surveys_complete_naomit, \n          file.path(\"/Users/abuga/Dropbox/313_course/2022/Lec01 R Basics/Development/Processed data\", \"surveys_complete_naomit.csv\"))\n\nNext lecture, we’re going to discuss collaboration with GitHub and go over an intro to the command line.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec01-basic-r.html#footnotes",
    "href": "lectures/lec01-basic-r.html#footnotes",
    "title": "1  Introduction to R: assignment, vectors, functions, strings, loops",
    "section": "",
    "text": "Refer to the tidy style guide for which style to adhere to.↩︎\nThere are a few other symbols as well, all of which can be viewed at the end of this post about RStudio code completion.↩︎",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R: assignment, vectors, functions, strings, loops</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html",
    "href": "lectures/lec02-command+git.html",
    "title": "2  Command line & Git(Hub)",
    "section": "",
    "text": "2.1 Lesson preamble",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#lesson-preamble",
    "href": "lectures/lec02-command+git.html#lesson-preamble",
    "title": "2  Command line & Git(Hub)",
    "section": "",
    "text": "2.1.1 Lesson objectives\n\nDevelop familiarity with the logic of the command line, including how to\n\nNavigate between directories\nCreate, copy, move, delete and compare files and directories\nSearch, edit, and read content from files\nChange file permissions\nInstall, update and remove packages\nUse NCBI’s BLAST!\n\nLearn how Git(Hub) works and the logic of version control\n\nDevelop proficiency using basic Git commands\nDevelop understanding of the Git workflow and recommended practices\nPractice using Git commands at the command line\n\n\n2.1.2 Lesson outline\n\nIntroduction to the command line and where/why/when we use it (10 mins)\nA tour through different command line tools (25 mins)\nRunning software tools: BLAST (25 mins)\nCollaborating with GitHub using the command line (30 min)\nWorkflows and recommended practices (10 mins)",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#intro-to-the-command-line",
    "href": "lectures/lec02-command+git.html#intro-to-the-command-line",
    "title": "2  Command line & Git(Hub)",
    "section": "2.2 Intro to the command line",
    "text": "2.2 Intro to the command line\n\n2.2.1 Why use the command line?\nIncreasing amounts of data in biology (especially genomic data stored in databases like the UK Biobank and GenBank) are transforming the field. These data have allowed us to ask and answer questions that would otherwise be impossible to address, and have motivated extensive cross-talk between biology, computer science, mathematics, and statistics. To analyze large-scale datasets in a way that is efficient, robust, reproducible, and scale-able, researchers turn to the command line. The command line interface allows researches to pass commands to the shell.\nSome advantages of working are the commend line are:\n\nEfficient parallelization: where it would not be possible to preform certain calculations due to time and memory limitations, the command line allows us to interface with computing clusters which can run many calculations or processes simultaneously. For example, efficient parallelization can allow a user to run many simulations of a model (each run corresponding to a different combination of parameter values) simultaneously. This can cut run times from months to seconds.\nControl over data: the command line allows users to view, parse, transform, and transfer large files (such as genome sequences) efficiently. Such control is simply not possible with a GUI like RStudio.\nAutomation, reproducibility, and computational ease: shell commands automate tasks which would otherwise be 1) computationally expensive, 2) error-prone, and 3) emotionally taxing.1 Shell commands can be scripted, shared, version-controlled, and made to run at certain times. (For example, shell scripts designed to scrape the web for data are often made to run during off-peak hours.) Because the command line makes automating complex tasks possible, software used to analyze large data is often written for use on the command line.\n\nAll that said, shell commands appear quite scary. Indeed, the command line is unforgiving–cryptic error messages abound when incorrect commands are entered. One can do serious damage without understanding the basis of the shell. The goal of this lecture is to provide you all with knowledge of 1) the logic of the command line, 2) important shell commands, 3) how to use NCBI’s BLAST on the command line, and 4) how to use the command line to interface with GitHub. The first half of the lecture will focus on the shell, and the second half on Git.\n\n\n2.2.2 Logic of the command line\nThe command line interface takes commands of the following form:\n\ncommand param1 param2 param3 … paramN\n\nwhere param1, param2, \\(\\dots,\\) and paramN are parameters provided by the user. This is a simplification, but one can get by thinking of commands as having this form, with the command line interpreter providing an interface between what is entered and the machine. Commands can range in what they do (navigation between directories, editing of files and of file permissions, etc.) but will not do what they are intended to if the relevant parameters are not specified, or if files which are called by the command are not accessible.\n\n\n2.2.3 Where are we?\nFor this portion of the lecture, we will move to the terminal on Mete’s machine. The commands that we execute there are given and described below:\n\ncal # returns this month's calender\ndate # returns today's date\npwd # print working directory\nls # returns contents of the working directory\nls -l # returns contents of wd and information about those contents\n\n\nmkdir newdirectory # makes new directory called newdirectory\ncd newdirectory # change directory to newdirectory\ntouch emptytextfile.txt # make new .txt file with name emptytextfile\nless emptytextfile.txt # view emptytextfile.txt\nq # stop viewing emptytextfile.txt\ntouch emptytextfile2.txt\nnano emptytextfile2.txt # edit emptytextfile2.txt\nmv emptytextfile2.txt file_nolongerempty.txt \n# make new file called file_nolongerempty.txt from emptytextfile2.txt\nless file_nolongerempty.txt\ncp file_nolongerempty.txt file_nolongerempty_todelete.txt\n# copy file_nolongerempty.txt and make new file called file_nolongerempty_todelete.txt\nrm file_nolongerempty_todelete.txt # delete file_nolongerempty_todelete.txt\n\n\ncd .. # go back to preview working directory\nmkdir newdirectory2\ncp -r newdirectory2 newdirectory3 # copy directory\nrm -r newdirectory3 # remove directory that was just made\n\n\ndiff -qr newdirectory/ newdirectory2/ \n# assess and return differences between directories specified\n# r recursively searches subdirectories, q reports 'briefly', when files differ\n# -arq is also valid, treats all files as text\n  \ncd newdirectory\ndiff file_nolongerempty.txt emptytextfile.txt \n# assess and return differences between files specified\n# -w ignores white space\n\n\n\n2.2.4 All about file permissions\nTo see what the permissions of a specific file are, one can use the command ls followed by -l (for all files within a directory) or -la for specific files within that directory.\n\nls -la file_nolongerempty.txt\n# multiple instances of r, w, and x reflect different levels of ownership\n# r = can read the file, can ls the directory\n# w = can write the file, can modify the directory's contents\n# x = can execute the file, can cd to the directory\n\nFor example, the rw that appears first in -rw-r--r-- indicates the owner (user) can can read and write to the file but can’t execute it as a program. The r that appears next indicates group members can read the file. drwxr-xr-x indicates group members can view as well as enter the directory.\nThe command cmod for “change mode” allows one to modify file permissions.\n\nchmod a+r file_nolongerempty.txt\n# a stands for all (default, so can be omitted), +r = add read permission\n# g = group, o = other, u = user\n# - = remove access, = sets exact access\nchmod go-rw file_nolongerempty.txt # removes group read and write permissions\n\nchmod also acts on directories but requires -R argument. chmod -R o+x would grant execution permissions for other users to a directory and its subdirectories.\nFor more about the chmod command (e.g., specifying the entire state of a file or directories permissions by providing the command numbers rather than combinations of r,x,w), one can run the command man chmod. The man command displays the manual page for a particular command.\nTo see what a shell command does, we also reccomend you check out https://explainshell.com.\n\n2.2.4.1 Challenge\nWhat steps, in order, would you perform in order to create a file called “test.txt” with the text “Hello World!” in a new folder called “challenge” and make it executable for all users?\n\n\n\n2.2.5 apt, sudo, get, and all that jazz\nAn important but unfortunately tricky part of using the command line is using the utility apt (or one of its cousins) to install, update, remove, or otherwise manage packages on a Linux distribution. More information how apt works and can be used can be found at https://ubuntu.com/server/docs/package-management. Since there are some steps to get apt to work on a Mac, Mete will illustrate how to do package installation using the free and open source package manager Homebrew.\nOne can install Homebrew by running\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# if you're on Linux or Windows (with Ubuntu installed with WSL 2):\napt update\napt upgrade\n\nbrew can be used to install packages the machine does not have. For example, running\n\nbrew install wget\n\ninstalls the package wget, a free package for retrieving files using HTTP, HTTPS, FTP and FTPS. Homebrew does this by running Ruby and Git, which you can see for yourseld by entering the following command:\n\nbrew edit wget\n\nHomebrew also allows users to create their own packages, has very through documentation, and even facilitates the installation of new fonts and non-open source software.\n\nbrew install --cask firefox\n\nA list of packages that are installed can be found by running\n\nbrew list\nbrew deps --tree --installed # illustrates dependencies\n\nA particular piece of software can be found by using brew search:\n\nbrew search google\n\napt-cache search google\n\nbrew install will install software such as the highly useful Basic Local Alignment Search Tool (BLAST):\n\nbrew install blast\n\napt-get install ncbi-blast+\n\nAlong these lines, it is important to mention that one sometimes will run into issues installing packages using brew or apt. To get around this, a very handy (but at times dangerous) command to have ready is sudo. For example, trying to run shutdown, Mete gets an error. But if we run\n\nsudo shutdown\n\none can run … just about anything. sudo stands for superuser do.\n\n\n2.2.6 Running software tools\n\n2.2.6.1 Examples of software tools\nThere’s a lot of software available for biological research, but much of it can only be used from the command line. For example, if you wanted to identify all of the transposable elements (“selfish genes” that make copies of themselves in their host genomes) in a genome, you’d want to run something like EDTA but it does not offer a graphical interface. If you had a sequence that you knew was associated with herbicide resistance, you could use NCBI’s BLAST (Basic Local Alignment Search Tool) to compare your nucleotide or protein sequence against a large database to find regions of similarity in order to determine the potential functional role of the region or if the region is shared among similar species. The has an online graphical interface but is also available to use via the command line. The command line provides some additional functionality, such as the time-saving option of performing searches in parallel.\n\n\n2.2.6.2 Step 1: Understand the software\nYour first step to running something is always going to be reading documentation. You need to understand what the software tool is actually doing and whether that methods it uses is appropriate for your data.\nThe inputs and outputs of a programme are an important starting place. BLAST’s required inputs are -query, a “query sequence” (what you’re looking for), and -db, a “database” (where you’re hoping to find a match). Ideally, you’ve read the paper associated with the software’s creation, you’ve understood all of the arguments that can be passed to the software, and, most importantly, you understand the software’s weaknesses and strengths with regards to your particular type of data.\nThis is the most important step for analysing your data. Getting the software running can be tricky and often more time-consuming than this step, but understanding what’s happening to your data is the most important thing you’re going to do.\nOne way to interact with help documentation is to use -h or -help. Many software tools will display their documentation after such an argument.\n\nbash --help\n\n\n\n2.2.6.3 Installing and running the software\nPackage managers like conda are really useful for more complex software tools that have dependencies. Luckily, tools like BLAST can be simply installed with apt-get and/or brew (as outlined earlier).\n\nbrew install blast\n# earlier code for reference\n\napt-get install ncbi-blast+\n\nIn the below code chunk, we use curl to download a mouse amino acid sequences that have been compressed (notice the file extension!) into our current working directory, and check it downloaded with ls.\n\ncurl -o mouse.protein.faa.gz -L https://osf.io/v6j9x/download\n\nls\n\nFilenames that end in .gz have been compressed with gzip (similar in theory to compressing with zip). We can de-compress the files to be able to view them.\n\ngunzip mouse.protein.faa.gz\n\nhead -n 6 mouse.protein.faa # head works the same in R as the command line\nless mouse.protein.faa # less will show the whole file. You can quit with `q`.\n\n# Let's take the first two sequences and save them to a different file\nhead -n 11 mouse.protein.faa &gt; mm.first.faa\n\n# You can check this worked with `less mm.first.faa`\n\nWe can search this mouse sequence against a protein data set with BLAST. First, we need to make a protein sequence database for searching with makeblastdb.\n\nmakeblastdb -in mouse.protein.faa -dbtype prot\n\nThen we can call BLAST to do a protein search:\n\n# Note that the outfile specified references the query and db names\nblastp -query mm.first.faa -db mouse.protein.faa -out mm.first.mouse.txt\n\n# Check the output with head or less\nless mm.first.mouse.txt\n\nYou can use spacebar to move down a page. q exits less.\n\n\n2.2.6.4 Challenge\nCreate a new query file from the first 498 lines of the file mouse.protein.faa, name it mm.second.faa, and use that to search mouse.protein.faa with blastp. Did BLAST take longer?",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#reproducible-science-and-collaboration-with-github",
    "href": "lectures/lec02-command+git.html#reproducible-science-and-collaboration-with-github",
    "title": "2  Command line & Git(Hub)",
    "section": "2.3 Reproducible science and collaboration with Git(Hub)",
    "text": "2.3 Reproducible science and collaboration with Git(Hub)\n\n2.3.1 Introduction to version control using Git\nGit is a version control system that tracks changes in files. Although it is primarily used for software development, Git can be used to track changes in any files, and is an indispensable tool for collaborative projects. Using Git, we effectively create different versions of our files and track who has made what changes. The complete history of the changes for a particular project and their metadata make up a repository.\nTo sync the repository across different computers and to collaborate with others, Git is often used via GitHub, a web-based service that hosts Git repositories. In the spirit of “working open” and ensuring scientific reproducibility, it has also become increasingly common for scientists to upload scripts and related files to GitHub for others to use.\n\n\n2.3.2 Intro to GitHub\nGitHub allows for easy use of Git for collaborative purposes using a primarily point-and-click interface, in addition to providing a web-based hosting service for Git repositories (or “repos”). If you have not already made a GitHub account, do so now here.\nA new repository can be made by clicking on the + in the top right of the page and selecting “New repository”. For now, however, navigate to your provided group repo. All members of the group have been given admin access to a pre-made repository in the 2023-GroupX projects repo. All groups have been provided with existing repositories, but a new repository can be made by clicking on the + in the top right of the page and selecting “New repository”. For now, however, navigate to your provided group repo.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#version-control-with-git",
    "href": "lectures/lec02-command+git.html#version-control-with-git",
    "title": "2  Command line & Git(Hub)",
    "section": "2.4 Version Control with Git",
    "text": "2.4 Version Control with Git\n\n2.4.1 Setup and Installation\nGit is primarily used on the command line. The implementation of the command line that we’ll be using is known as a “bash interpreter”, or “shell”. While bash interpreters are natively available on Mac and Linux operating systems, Windows users may have to externally install a bash shell.\nTo install Git on a Mac, you will have to install Xcode, which can be downloaded from the Mac App Store. Be warned: Xcode is a very large download (approximately 6 GB)! Install Xcode and Git should be ready for use. (Note: most students will have already installed Xcode already for some R packages we used earlier in the course. If you’re not sure whether this is the case, run the git --version command described below)\nTo install Git (and Bash) on Windows, download Git for Windows from its website. At the time of writing, 2.19.1 is the most recent version. Download the exe file to get started. Git for Windows provides a program called Git Bash, which provides a bash interpreter that can also run Git commands.\nTo install Git for Linux, use the preferred package manager for your distribution and follow the instructions listed here.\nTo test whether Git has successfully been installed, open a bash interpreter, type:\n\ngit --version\n\nand hit Enter. If the interpreter returns a version number, Git has been installed.\n\n\n2.4.2 Getting started with Git\nFirst, we have to tell Git who we are. This is especially important when collaborating with Git and keeping track of who did what! Keep in mind that this only has to be done the first time we’re using Git.\nThis is done with the git config command. When using Git, all commands begin with git, followed by more specific subcommands.\n\ngit config --global user.name \"My Name\"\ngit config --global user.email \"myemail@example.com\"\n\nFinally, the following command can be used to review Git configurations:\n\ngit config --list\n\n\n\n2.4.3 Cloning local from main\nAfter configuring our name and email, we are ready for version control!\nFirst, we need to initialize our local repository, so we need to tell Git where to store our files on our computer. At the same time, we can also connect the two repositories: the local one on your computer, and the remote one on GitHub. We do both by making the GitHub repository a remote for the local repository.\nFirst, head to your group’s repo on GitHub, and click on the green “Clone or download” button on the right side of the page. This yields a link to your fork. Copy this link to your clipboard.\nOn the command line, run\n\ngit clone [repo link]\n\nwith the link in place of [repo link]. This process, known as cloning, will create a new folder in your current working directory that contains the contents of your GitHub folder. This also initializes your local repo.\nEnter this new folder with cd and type git status to make sure the repo has been cloned properly. git status should output that the branch is even with origin/main, indicating that it is currently the same as the current state of your fork.\n\n\n2.4.4 Adding and commiting files\nFor your projects, you will be making edits to your .Rmd file in RStudio, or you will be writing your report in text editors. For today, let’s use the file we created earlier and commit it.\nThe “untracked files” message means that there’s a file in the directory that Git isn’t keeping track of. We can tell Git to track a file using git add:\n\ngit add draft-yn.txt\n\nGit now knows that it’s supposed to keep track of mars.txt, but it hasn’t recorded these changes as a commit yet. To get it to do that, we need to run one more command:\n\ngit commit -m \"intro about my project\"\n\nWhen we run git commit, Git takes everything we have told it to save by using git add and stores a copy permanently inside the special .git directory. This permanent copy is called a commit (or revision) and its short identifier is a series of letters and numbers. Each commit has a unique identifier.\nWe use the -m flag to write a message that describes our edits specifically.\n\n\n2.4.5 Pushing changes\nNow, let’s push our changes from the local repo to the main repo.\nWe can push our changes:\n\ngit push origin main\n\nThe first time you run the push subcommand, you may get a prompt asking you to enter your GitHub username and password. If you are entering your password and nothing pops up, don’t worry! Your keystrokes are being recognized, although there is no visual cue for it.\nNow, running git status shows us that our local repo is up-to- date with origin/main.\nIf we navigate to GitHub, we now see that we have our updates in the main repo, and there is a comment “intro about my project” associated with the commit.\nGit commit history is a directed acyclic graph (or DAG), which means that every single commit always has at least one “parent” commit (the previous commit(s) in the history), and any individual commit can have multiple “children”. This history can be traced back through the “lineage” or “ancestry”.\n\n\n2.4.6 Pulling changes\nWhen other group members add to the shared repo, you have to make sure those edits have been incorporated into your repo before making new changes of your own. This ensures that there aren’t any conflicts within files, wherein your edits clash with someone else’s if one of you is working with an earlier version of the file.\nTo remain up to date, navigate to the local copy of your repo.\nFirst, you have to fetch the new changes that are in the shared origin repo.\n\ngit fetch origin\n\nOnce the edits have been downloaded from the origin, merge them into your local main repo:\n\ngit merge origin/main\n\nNote that the git pull command combines two other commands, git fetch and git merge.\n\ngit pull\n\nThis will download any changes your group members may have made and update your local versions of your fork accordingly.\nYour local copy is now even with the shared repo!\nBefore starting any edits of your own, it’s usually a good idea to start off by checking to see whether anything’s been added to the main repo and, if needed, pulling those changes\n\n\n2.4.7 Summary\nBasic Git commands:\n\ngit init (or git clone)\ngit status\ngit add\ngit commit\ngit push\ngit log\ngit checkout\ngit help\n\nThe “GitHub flow” (so far):\n\nMake sure your local is up to date using git pull\nMake your edits\nAdd your edits with git add\nCommit your edits with an informative commit message\nPush your edits\nRepeat\n\n\n2.4.7.1 GitHub Issues\nFinally, each repo on GitHub also has an Issues tab at the top of the page. Here, you and your group can create posts regarding the content of the repo that highlight issues with code or serve as to-do lists to manage outstanding tasks with.\nAlthough issues aren’t needed for any of the steps we discussed above, it can be useful to create a roadmap of your project with them and assign group members to specific tasks if need be.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#extra-material-best-practices-for-collaboration",
    "href": "lectures/lec02-command+git.html#extra-material-best-practices-for-collaboration",
    "title": "2  Command line & Git(Hub)",
    "section": "2.5 EXTRA MATERIAL: best practices for collaboration",
    "text": "2.5 EXTRA MATERIAL: best practices for collaboration\nUsually, there are several other steps involved during collaboration. At this point, we are able to push our edits from our local machine straight to the final version on the GitHub repo. This can be dangerous if no one else is checking over your code, especially if every team member has direct access to change the contents of the main repo, and all of your project files. These additional steps include using forks and branches.\n\n2.5.1 Creating a Fork\nThe repos that have already been created can be thought of as “main repos”, which will contain the “primary” version of the repo at any given point in time. However, instead of directly uploading and editing files right within this main repo itself, usually collaborators will be begin by forking the repo. When a given user forks a repo, GitHub creates a user-specific copy of the repo and all its files in a remote location.\nHaving a forked copy means that the developer who performs the fork will have complete control over the newly copied codebase. Developers who contributed to the Git repository that was forked will have no knowledge of the newly forked repo. Previous contributors will have no means with which they can contribute to or synchronize with the Git fork unless the developer who performed the fork operation provides access to them.\nSome famous examples of Git forks include:\n\nFire OS for Kindle Fire, which is a fork of Android\nLibreOffice, which is a fork of OpenOffice\nUbuntu, which is a fork of Debian\nMariaDB, from MySQL\n\nYou’ll notice that on the top left of this repo page, the repo’s name will be “[your username] / 2023-GroupX”, as opposed to “EEB313 / 2023-GroupX”. Furthermore, GitHub will indicate that this is a fork right underneath said repo name (“forked from eeb313-[year]/ [repo name]”).\n\n\n2.5.2 Setting up your remotes\nNow we connect the three repositories: the local repo on your computer, the forked repo on GitHub, and the main group remote repo on GitHub. We do this by making the GitHub repository a remote for the local repository.\nTo get your fork up to date with the main repo, you next have to add a remote linking to the main repo. Head to your group’s repo and once again click on “Clone or download” to grab its link. Then, using the main repo link, run:\n\ngit remote add upstream [repo link]\n\nThen, we have to update our forked repo. Earlier, since we didn’t have a forked repo, we only had a link between our local computer version of the folder and the shared version. When we cloned the shared version, we created that remote link. Now, we have changed that shared repo as the upstream remote, and we have a fork that acts as an intermediate step. Let’s change our fork to become the main remote.\nRun:\n\ngit remote -v\n\nto get a list of existing remotes. This should return four links, two of which are labelled origin and two of which are labelled upstream. At this point, they should be the same link. We need to update our main remote by removing it and adding our fork link.\nTo remove our origin remote, run:\n\ngit remote rm origin\n\nThen, let’s add our fork:\n\ngit remote add origin [repo link]\n\nNow, when you run :\n\ngit remote -v\n\nyou should find two links for origin and two links for upstream. These two links are used to fetch from upstream, and one to push from main to upstream. The links for origin are your main forked repo on your own GitHub, while the links for upstream are the EEB313-2023-GroupX repo.\n\n\n2.5.3 Syncing your fork\nNext, you have to fetch the new changes that are in the shared repo.\n\ngit fetch upstream\n\nOnce the edits have been downloaded from upstream, merge them into your local repo:\n\ngit merge upstream/main\n\nYour local copy is now even with the main repo! Finally, push these changes to the GitHub version of your fork (origin) from your main local repo.\n\ngit push origin main\n\nNow the GitHub version of the fork is all synced up, ready for your next batch of edits, and eventually another pull request!\n\n\n2.5.4 Making edits\nEvery time you make edits to your local files, first make sure you are first syncing any changes from upstream to your local to your origin (fork).\nThen, go ahead and make your edits! After you are done your batch of editing, you can add and commit those changes, still using git add and git commit.\nThese commits do not go to the upstream EEB313 repo, but instead end up in your forked repo. In order to contribute your changes from your fork to upstream, you will need to make a Pull Request (PR).\n\n\n2.5.5 Pull requests\nAfter a commit has been made, head to your fork. GitHub will have noticed that there are new edits that you can contribute. Click “Contribute” and “Open Pull Request”. A PR is GitHub’s way of neatly packaging one or more commits that have been made into a single request, and then you can merge said commits into upstream. In our case, a PR is essentially you saying: “Here are all the edits I’ve made. Have a look, and add them to main if you think they’re ready to go.”\nFollowing a pull request pending, GitHub takes you to the “Pull Requests” tab of the repo and prompts you to write about your pull request (i.e., describe the changes you’re attempting to merge). Here, you can (and should) explain the changes you’ve made for your collaborators, so that they know what to look for and review. Be specific and detailed to save your group members’ time – it’s a good idea to start off your pull request message with an overall summary (“adding dplyr code to clean dataset”) followed by a point-form list of what changes have been made, if necessary.\nOnce the pull request has been made, GitHub will list both your message and your commit messages below. Clicking on any of these commits opens up a new page highlighting the changes made in that specific commit. You also have the option of merging the pull request yourself – but don’t do this! When collaborating, always have someone else review and merge your pull request.\nIf all does not look good, your team members can add messages below, and tag others using the @ symbol, similarly to most social networks. If more changes are needed before the pull request is ready to merge, any new commits you make to the main branch on your fork will automatically be added on to the pull request. This way, you can incorporate any changes or fixes suggested by your team members simply by continuing to work in your fork until your changes are ready to merge. For line-specific edits, if a file is opened up (i.e., by clicking on one of the commits), clicking on the + button that appears when hovering over a line number will allow you or a group member to add a comment specifically attached to that line. This can be useful when pointing out typos, for instance, among other things.\n\n\n2.5.6 Creating a branch\nA branch is used to isolate development work without affecting other branches in the repository. Each repository has one default branch, and can have multiple other branches. Branches allow you to develop features, fix bugs, or safely experiment with new ideas in a contained area of your repository.\nThe main branch should be thought of as the actual current state of your project – branches are meant, by design, to be temporary, and exist only to facilitate edits and experimental work while avoiding any risk of breaking the original codebase. Branches can keep experimental work separate; for example, you can create a separate branch from your main branch so any trials or bugs only exist in your branch.\nBranches are simply a named pointer to a commit in the DAG, which automatically move forward as commits are made. Divergent commits (two commits with the same parent) could be considered “virtual” branches. Since they are simply pointers, branches in Git are very lightweight.\nYou always create a branch from an existing branch, typically, the default branch of your repository. You can then work on this new branch in isolation from changes that other people are making to the repository. A branch you create to build a feature is commonly referred to as a feature branch or topic branch.\nTo create a new branch, run:\n\ngit branch &lt;branch-name&gt;\n\nFor example:\n\ngit branch new-feature\n\nThe repository history remains unchanged. Then, we need to record all new commits to that branch.\n\ngit checkout new-feature\n\nNote that you can combine branch creation and checkout by using only one command:\n\ngit checkout -b new-feature\n\nYou should see the confirmation: Switched to a new branch \"new-feature\"\nMake your edits, and commit them to your branch using git add and git commit. When you are ready to merge your new feature to your local main branch, head back to your main branch:\n\ngit checkout main\n\nAnd merge your new features from the new-feature branch:\n\ngit merge new-feature\n\nNow you can delete your branch, since it has been successfully merged:\n\ngit branch -d new-feature\n\nThis is a common workflow for short-lived topic branches that are used more as an isolated development than an organizational tool for longer-running features.\nNote that this is all happening locally. You now push your changes from your local main to upstream or origin. Don’t forget to create a pull request from your fork to the upstream EEB313 repo if you are using forks!\nHowever, you are also able to create a new branch and push that local branch to upstream or origin. To do this, make sure you are in your new branch:\n\ngit checkout new-feature\n\nThen, git add and git commit as you normally would. This time, instead of merging your new branch to your local main, git push to push them to your forked repo or upstream.\nNow, running git status shows us that our new-feature branch on our local repo is up-to- date with origin/main.\nIf we navigate to GitHub, we now see that we have a new branch in our forked repo (and remember that there should a comment associated with the commit)/\nNow, you can submit a pull request for the rest of your team to check on the repo. Once they review the changes, they can merge the PR, and the final version will show up on the upstream repo!\nOnce a pull request has been merged into the main repo, the new-feature branch (or whatever you have named your branch) isn’t needed anymore. Because of this, GitHub will immediately prompt you to delete the this branch as soon as the merge has been completed right in the PR.\nTo list the branches that are currently being used, use this for local branches:\n\ngit branch\ngit branch --list\n\nThe git branch command lets you create, list, rename, and delete branches. It doesn’t let you switch between branches or put a forked history back together again. For this reason, git branch is tightly integrated with the git checkout and git merge commands.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#tldr-refer-back-to-this",
    "href": "lectures/lec02-command+git.html#tldr-refer-back-to-this",
    "title": "2  Command line & Git(Hub)",
    "section": "2.6 TL;DR (refer back to this!)",
    "text": "2.6 TL;DR (refer back to this!)\nThe general collaborative workflow is as follows:\n\nFirst, create a branch of the main repo.\nMake edits in the branch. These could involve adding/deleting lines of code or even adding/removing entire files. Keep in mind that the branch is separate from the main codebase, so don’t worry too much about deleting things or making large changes.\nOnce you have made your changes in this branch, submit what’s known as a pull request (PR) from this edited branch to main. A PR neatly packages all the edits that have been made in your branch for review by other members of your group.\nOnce your changes have been approved, merge the PR. It’s good practice to have group members merge your PRs instead of doing it yourself.\n\nAlthough this process may seem a bit laborious, using this method (also known as the “GitHub flow”) minimizes chances of error and ensures that all code is reviewed by at least one other person. Understanding how and why this process works is key to collaborative work in software development and the like, and is used by all sorts of open source projects on GitHub (including dplyr itself!)\n\n2.6.1 Git Terminology\n\nrepository (short form: repo): a storage area for a project containing all the files for the project and the history of all the changes made to those files\nlocal copy: the version of file stored on your own computer\nremote copy: the version of a file stored outside of your own computer, for example stored on an external server, perhaps at GitHub. Remotes are referenced by nicknames, e.g., origin or upstream.\nbranch: a named series of commits. The default branch that you download is usually called gh-pages or main. Creating a new branch makes a parallel version of a repository where changes can be made that affect the new branch only and not the original (base) version of the repository. New branches are often used to test changes or new ideas, which can later be merged with the base branch. Moving from one branch to another is called checking out a new branch.\nfork (GitHub-specific term): to copy a repository from another user and store it under your own GitHub account. Can also refer to the copied repo itself.\ngh-pages (GitHub-specific term): stands for “GitHub Pages”. This is often the default branch in repositories. Branches called gh-pages can be published as webpages hosted by GitHub.\norigin: the main remote repository you want to download files from or compare local changes you have made to. When you’ve forked a repository, your origin is your new copy of the repository in your account.\nupstream: the original repository you made your fork from. Both origin and upstream are remote repositories.\ncommit: to save changes in your working directory to your local repository\npush: send committed changes you have made on your local computer to a remote repository. For a change to show up on GitHub, the committed changes must be pushed from your computer to the remote repository.\npull: download changes from a remote repository to your local version of the same repository. This is useful when other people have made changes to a shared project, and you want to download (pull) the changes from the shared remote repository to your own computer.\npull request (GitHub-specific term, abbreviated as “PR”): send proposed changes from a specific version of a repository back to the main version of a repository to be considered for incorporation by the people maintaining the repository (the maintainers). You are requesting that the maintainers pull your changes into their repository.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#additional-resources",
    "href": "lectures/lec02-command+git.html#additional-resources",
    "title": "2  Command line & Git(Hub)",
    "section": "2.7 Additional resources:",
    "text": "2.7 Additional resources:\n\nA visual demonstration of the GitHub flow.\nA useful Git command cheat sheet.\nGuide to a good Git Workflow\nThis textbook",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec02-command+git.html#footnotes",
    "href": "lectures/lec02-command+git.html#footnotes",
    "title": "2  Command line & Git(Hub)",
    "section": "",
    "text": "Trust us on this!↩︎",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Command line & Git(Hub)</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html",
    "href": "lectures/lec03-data-wrangling.html",
    "title": "3  Data wrangling!",
    "section": "",
    "text": "3.1 Lesson preamble",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#lesson-preamble",
    "href": "lectures/lec03-data-wrangling.html#lesson-preamble",
    "title": "3  Data wrangling!",
    "section": "",
    "text": "3.1.1 Learning objectives\n\nUnderstand the purpose of the dplyr package.\nLearn to use data wrangling commands select, filter, %&gt;%, and mutate from the dplyr package.\nUnderstand the split-apply-combine concept for data analysis.\nUse summarize, group_by, and tally to split a data frame into groups of observations, apply a summary statistics for each group, and then combine the results.\nLearn to switch between long and wide format\n\n3.1.2 Lesson outline\n\nR packages for data analyses (10 min)\nData wrangling in dplyr (40 min)\nSplit-apply-combine techniques in dplyr (25 min)\nUsing group_by and tally to summarize categorical data (20 mins)\nReshaping data (15 mins)",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#r-packages-for-data-analyses",
    "href": "lectures/lec03-data-wrangling.html#r-packages-for-data-analyses",
    "title": "3  Data wrangling!",
    "section": "3.2 R packages for data analyses",
    "text": "3.2 R packages for data analyses\nR packages are basically bundles of functions that perform related tasks. There are many some that will be come with a base install of R since they are considered critical for using R, such as c(), mean(), +, -, etc.\nThere is an official repository for R-packages beyond the base packages called CRAN (Comprehensive R Archive Network). CRAN has thousands of packages, and all these cannot be installed by default, because then base R installation would be huge and most people would only be using a fraction of everything installed on their machine. It would be like if you downloaded the Firefox or Chrome browser and you would get all extensions and add-ons installed by default, or as if your phone came with every app ever made for it already installed when you bought it: quite impractical.\nWe can install new packages using the function install.packages(). You only need to do this once, so we’ll pass eval=FALSE to knitr at the top of our code chunk to make sure that the chunk won’t be evaluated when we knit the document. You can find other possible options to pass that can be helpful for formatting your output document.\nWhile we’re looking at the {} section of our code chunk, we might note that it starts with “r”. This specifies that this chunk is written in R and you could tell RStudio to to instead interpret the code in the chunk as a different language like bash (command line) or python. You can also specify names for the chunks. The knitr options are probably the most useful part of this section, though!\n\ninstall.packages('tidyverse')\n\ntidyverse1 is a large collection of packages with similar functions, similar to the way Microsoft Word is part of Microsoft Office. tidyverse, as its name may suggest, contains many packages that makes data cleaning and exploring more intuitive and effective. It is basically an entire philosophy on how to handle data and has a massive following.\nThe two tidyverse packages we will be using the most frequently in this course is dplyr and ggplot2. dplyr is great for data wrangling (Lecture 2) and ggplot2 makes killer plots (Lecture 3).\nTo use functions in the dplyr package, type dplyr:: and then the function name.\n\ndplyr::glimpse(cars) # `glimpse` is similar to `str`\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\n# cars is a built-in data set\n\nSince we will be using this package a lot, it would be a little annoying to have to type dplyr:: every time. We can bypass this step by loading the package into our current environment. Think of this is “opening” the package for your work session.\n\n# We could also do `library(dplyr)`, but we need the rest of the\n# tidyverse packages later, so we might as well import the entire collection.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\n\nThis needs to be done once for every new R session, and so it is common practice to keep a list of all the packages used at the top of your script or notebook for convenience and load all of it at start up.\nThat’s a lot of red though! What are these warning signs and checks?\nAll the warning signs indicate are the version of R that they were built under. They can frequently be ignored unless your version of R is so old that the packages can no longer be run on R! Note that packages are frequently updated, and functions may become deprecated.\nNext, the warning shows you all the packages that were successfully installed.\nFinally, there are some conflicts! All this means is that there are multiple functions with the same name that may do different things. R prioritizes functions from certain packages over others. So, in this case, the filter() function from dplyr will take precedent over the filter() function from the stats package. If you want to use the latter, use double colons :: to indicate that you are calling a function from a certain package:",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#data-wrangling-with-dplyr",
    "href": "lectures/lec03-data-wrangling.html#data-wrangling-with-dplyr",
    "title": "3  Data wrangling!",
    "section": "3.3 Data wrangling with dplyr",
    "text": "3.3 Data wrangling with dplyr\nWrangling here is used in the sense of maneuvering, managing, controlling, and turning your data upside down and inside out to look at it from different angles in order to understand it. The package dplyr provides easy tools for the most common data manipulation tasks. It is built to work directly with data frames, with many common tasks optimized by being written in a compiled language (C++), this means that many operations run much faster than similar tools in R. An additional feature is the ability to work directly with data stored in an external database, such as SQL-databases. The ability to work with databases is great because you are able to work with much bigger datasets (100s of GB) than your computer could normally handle. We will not talk in detail about this in class, but there are great resources online to learn more (e.g. this lecture from Data Carpentry).\n\n3.3.1 Selecting columns and filtering rows\nWe’re going to learn some of the most common dplyr functions: select(), filter(), mutate(), group_by(), and summarise(). To select columns of a data frame, use select(). The first argument to this function is the data frame (surveys), and the subsequent arguments are the columns to keep. Note that we don’t need quotation marks around the column names here like with did with base R. You do still need quotation marks around strings, though!\n\nselect(surveys, plot_id, species_id, weight, year) %&gt;% head()\n\n  plot_id species_id weight year\n1       2         NL     NA 1977\n2       2         NL     NA 1977\n3       2         NL     NA 1977\n4       2         NL     NA 1977\n5       2         NL     NA 1977\n6       2         NL     NA 1977\n\n# head explained below, allows us to see first couple of rows of the data frame\n\nTo choose rows based on a specific criteria, use filter():\n\nfilter(surveys, year == 1995) %&gt;% head()\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1     22314     6   7 1995       2         NL   M              34     NA\n2     22728     9  23 1995       2         NL   F              32    165\n3     22899    10  28 1995       2         NL   F              32    171\n4     23032    12   2 1995       2         NL   F              33     NA\n5     22003     1  11 1995       2         DM   M              37     41\n6     22042     2   4 1995       2         DM   F              36     45\n      genus  species   taxa plot_type\n1   Neotoma albigula Rodent   Control\n2   Neotoma albigula Rodent   Control\n3   Neotoma albigula Rodent   Control\n4   Neotoma albigula Rodent   Control\n5 Dipodomys merriami Rodent   Control\n6 Dipodomys merriami Rodent   Control\n\n\n\n3.3.1.1 An aside on conditionals\nNote that to check for equality, R requires two equal signs (==). This is to prevent confusion with object assignment, since otherwise year = 1995 might be interpreted as ‘set the year parameter to 1995’, which is not what filter does!\nBasic conditionals in R are broadly similar to how they’re already expressed mathematically:\n\n2 &lt; 3\n\n[1] TRUE\n\n5 &gt; 9\n\n[1] FALSE\n\n\nHowever, there are a few idiosyncrasies to be mindful of for other conditionals:\n\n2 != 3 # not equal\n\n[1] TRUE\n\n2 &lt;= 3 # less than or equal to\n\n[1] TRUE\n\n5 &gt;= 9 # greater than or equal to\n\n[1] FALSE\n\n\nFinally, the %in% operator is used to check for membership:\n\n2 %in% c(2, 3, 4) # check whether 2 in c(2, 3, 4)\n\n[1] TRUE\n\n\nAll of the above conditionals are compatible with filter, with the key difference being that filter expects column names as part of conditional statements instead of individual numbers.\n\n\n\n3.3.2 Chaining functions together using pipes\nBut what if you wanted to select and filter at the same time? There are three ways to do this: use intermediate steps, nested functions, or pipes. With intermediate steps, you essentially create a temporary data frame and use that as input to the next function. This can clutter up your workspace with lots of objects:\n\ntemp_df &lt;- select(surveys, plot_id, species_id, weight, year)\nfilter(temp_df, year == 1995) %&gt;% head()\n\n  plot_id species_id weight year\n1       2         NL     NA 1995\n2       2         NL    165 1995\n3       2         NL    171 1995\n4       2         NL     NA 1995\n5       2         DM     41 1995\n6       2         DM     45 1995\n\n\nYou can also nest functions (i.e. one function inside of another). This is handy, but can be difficult to read if too many functions are nested as things are evaluated from the inside out. Readability can be mildly improved by enabling “rainbow parentheses” (open settings &gt; Code &gt; Display and check rainbow parentheses), but it’s still basically impossible to document and effectively convey your work with this method.\n\nfilter(select(surveys, plot_id, species_id, weight, year), year == 1995) %&gt;% head()\n\n  plot_id species_id weight year\n1       2         NL     NA 1995\n2       2         NL    165 1995\n3       2         NL    171 1995\n4       2         NL     NA 1995\n5       2         DM     41 1995\n6       2         DM     45 1995\n\n\nThe last option, pipes, are a fairly recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. Pipes in R look like %&gt;% and are made available via the magrittr package that also is included in the tidyverse. If you use RStudio, you can type the pipe with Ctrl/Cmd + Shift + M.\n\nsurveys %&gt;% \n    select(., plot_id, species_id, weight, year) %&gt;% \n    filter(., year == 1995) %&gt;% head()\n\n  plot_id species_id weight year\n1       2         NL     NA 1995\n2       2         NL    165 1995\n3       2         NL    171 1995\n4       2         NL     NA 1995\n5       2         DM     41 1995\n6       2         DM     45 1995\n\n\nThe . refers to the object that is passed from the previous line. In this example, the data frame surveys is passed to the . in the select() statement. Then, the modified data frame which is the result of the select() operation, is passed to the . in the filter() statement. Put more simply: whatever was the result from the line above the current line, will be used in the current line.\nSince it gets a bit tedious to write out all the dots, dplyr allows for them to be omitted. By default, the pipe will pass its input to the first argument of the right hand side function; in dplyr, the first argument is always a data frame. The chunk below gives the same output as the one above:\n\nsurveys %&gt;% \n    select(plot_id, species_id, weight, year) %&gt;% \n    filter(year == 1995) %&gt;% \n  head()\n\n  plot_id species_id weight year\n1       2         NL     NA 1995\n2       2         NL    165 1995\n3       2         NL    171 1995\n4       2         NL     NA 1995\n5       2         DM     41 1995\n6       2         DM     45 1995\n\n\nAnother example:\n\nsurveys %&gt;%\n  filter(weight &lt; 5) %&gt;%\n  select(species_id, sex, weight) %&gt;% head()\n\n  species_id sex weight\n1         PF   F      4\n2         PF   F      4\n3         PF   M      4\n4         RM   F      4\n5         RM   M      4\n6         PF          4\n\n\nIn the above code, we use the pipe to send the surveys dataset first through filter() to keep rows where weight is less than 5, then through select() to keep only the species_id, sex, and weight columns. Since %&gt;% takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include it as an argument to the filter() and select() functions anymore.\nIf this runs off your screen and you just want to see the first few rows, you can use a pipe to view the head() of the data. (Pipes work with non-dplyr functions, too, as long as either the dplyr or magrittr package is loaded).\n\nsurveys %&gt;%\n  filter(weight &lt; 5) %&gt;%\n  select(species_id, sex, weight) %&gt;% \n  head()\n\n  species_id sex weight\n1         PF   F      4\n2         PF   F      4\n3         PF   M      4\n4         RM   F      4\n5         RM   M      4\n6         PF          4\n\n\nIf we wanted to create a new object with this smaller version of the data, we could do so by assigning it a new name:\n\nsurveys_sml &lt;- surveys %&gt;%\n  filter(weight &lt; 5) %&gt;%\n  select(species_id, sex, weight)\n\nsurveys_sml\n\n   species_id sex weight\n1          PF   F      4\n2          PF   F      4\n3          PF   M      4\n4          RM   F      4\n5          RM   M      4\n6          PF          4\n7          PP   M      4\n8          RM   M      4\n9          RM   M      4\n10         RM   M      4\n11         PF   M      4\n12         PF   F      4\n13         RM   M      4\n14         RM   M      4\n15         RM   F      4\n16         RM   M      4\n17         RM   M      4\n\n\nNote that the final data frame is the leftmost part of this expression.\nA single expression can also be used to filter for several criteria, either matching all criteria (&) or any criteria (|):\n\nsurveys %&gt;% \n    filter(taxa == 'Rodent' & sex == 'F') %&gt;% \n    select(sex, taxa) %&gt;% head()\n\n  sex   taxa\n1   F Rodent\n2   F Rodent\n3   F Rodent\n4   F Rodent\n5   F Rodent\n6   F Rodent\n\n\n\nsurveys %&gt;% \n    filter(species == 'clarki' | species == 'leucophrys') %&gt;% \n    select(species, taxa) %&gt;% head()\n\n     species    taxa\n1 leucophrys    Bird\n2     clarki Reptile\n3 leucophrys    Bird\n\n\n\n3.3.2.1 Challenge\nUsing pipes, subset the survey data to include individuals collected before 1995 and retain only the columns year, sex, and weight.\n\n\n\n3.3.3 Creating new columns with mutate\nFrequently, you’ll want to create new columns based on the values in existing columns. For instance, you might want to do unit conversions, or find the ratio of values in two columns. For this we’ll use mutate().\nTo create a new column of weight in kg:\n\nsurveys %&gt;%\n    mutate(weight_kg = weight / 1000) %&gt;% head()\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1         1     7  16 1977       2         NL   M              32     NA\n2        72     8  19 1977       2         NL   M              31     NA\n3       224     9  13 1977       2         NL                  NA     NA\n4       266    10  16 1977       2         NL                  NA     NA\n5       349    11  12 1977       2         NL                  NA     NA\n6       363    11  12 1977       2         NL                  NA     NA\n    genus  species   taxa plot_type weight_kg\n1 Neotoma albigula Rodent   Control        NA\n2 Neotoma albigula Rodent   Control        NA\n3 Neotoma albigula Rodent   Control        NA\n4 Neotoma albigula Rodent   Control        NA\n5 Neotoma albigula Rodent   Control        NA\n6 Neotoma albigula Rodent   Control        NA\n\n\nYou can also create a second new column based on the first new column within the same call of mutate():\n\nsurveys %&gt;%\n    mutate(weight_kg = weight / 1000,\n           weight_kg2 = weight_kg * 2) %&gt;% head()\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1         1     7  16 1977       2         NL   M              32     NA\n2        72     8  19 1977       2         NL   M              31     NA\n3       224     9  13 1977       2         NL                  NA     NA\n4       266    10  16 1977       2         NL                  NA     NA\n5       349    11  12 1977       2         NL                  NA     NA\n6       363    11  12 1977       2         NL                  NA     NA\n    genus  species   taxa plot_type weight_kg weight_kg2\n1 Neotoma albigula Rodent   Control        NA         NA\n2 Neotoma albigula Rodent   Control        NA         NA\n3 Neotoma albigula Rodent   Control        NA         NA\n4 Neotoma albigula Rodent   Control        NA         NA\n5 Neotoma albigula Rodent   Control        NA         NA\n6 Neotoma albigula Rodent   Control        NA         NA\n\n\nThe first few rows of the output are full of NAs, so if we wanted to remove those we could insert a filter() in the chain:\n\nsurveys %&gt;%\n    filter(!is.na(weight)) %&gt;%\n    mutate(weight_kg = weight / 1000) %&gt;% head()\n\n  record_id month day year plot_id species_id sex hindfoot_length weight\n1       588     2  18 1978       2         NL   M              NA    218\n2       845     5   6 1978       2         NL   M              32    204\n3       990     6   9 1978       2         NL   M              NA    200\n4      1164     8   5 1978       2         NL   M              34    199\n5      1261     9   4 1978       2         NL   M              32    197\n6      1453    11   5 1978       2         NL   M              NA    218\n    genus  species   taxa plot_type weight_kg\n1 Neotoma albigula Rodent   Control     0.218\n2 Neotoma albigula Rodent   Control     0.204\n3 Neotoma albigula Rodent   Control     0.200\n4 Neotoma albigula Rodent   Control     0.199\n5 Neotoma albigula Rodent   Control     0.197\n6 Neotoma albigula Rodent   Control     0.218\n\n\nis.na() is a function that determines whether something is an NA. The ! symbol negates the result, so we’re asking for everything that is not an NA.\n\n3.3.3.1 Challenge\nCreate a new data frame from the surveys data that meets the following criteria: contains only the species_id column and a new column called hindfoot_half containing values that are half the hindfoot_length values. In this hindfoot_half column, there are no NAs and all values are less than 30.\nHint: think about how the commands should be ordered to produce this data frame!",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#split-apply-combine-techniques-in-dplyr",
    "href": "lectures/lec03-data-wrangling.html#split-apply-combine-techniques-in-dplyr",
    "title": "3  Data wrangling!",
    "section": "3.4 Split-apply-combine techniques in dplyr",
    "text": "3.4 Split-apply-combine techniques in dplyr\nMany data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results.\ndplyr facilitates this workflow through the use of group_by() to split data and summarize(), which collapses each group into a single-row summary of that group. The arguments to group_by() are the column names that contain the categorical variables for which you want to calculate the summary statistics. Let’s view the mean weight by sex.\n\nsurveys %&gt;%\n    group_by(sex) %&gt;%\n    summarize(mean_weight = mean(weight))\n\n# A tibble: 3 × 2\n  sex   mean_weight\n  &lt;chr&gt;       &lt;dbl&gt;\n1 \"\"             NA\n2 \"F\"            NA\n3 \"M\"            NA\n\n\nThe mean weights become NA since there are individual observations that are NA. Let’s remove those observations.\n\nsurveys %&gt;%\n    filter(!is.na(weight)) %&gt;%\n    group_by(sex) %&gt;%\n    summarize(mean_weight = mean(weight))\n\n# A tibble: 3 × 2\n  sex   mean_weight\n  &lt;chr&gt;       &lt;dbl&gt;\n1 \"\"           64.7\n2 \"F\"          42.2\n3 \"M\"          43.0\n\n\nThere is one row here that is neither male nor female, these are observations where the animal escaped before the sex could not be determined. Let’s remove those as well.\n\nsurveys %&gt;%\n    filter(!is.na(weight) & !is.na(sex)) %&gt;%\n    group_by(sex) %&gt;%\n    summarize(mean_weight = mean(weight))\n\n# A tibble: 3 × 2\n  sex   mean_weight\n  &lt;chr&gt;       &lt;dbl&gt;\n1 \"\"           64.7\n2 \"F\"          42.2\n3 \"M\"          43.0\n\n\nYou can also group by multiple columns:\n\nsurveys %&gt;%\n    filter(!is.na(weight) & !is.na(sex)) %&gt;%\n    group_by(genus, sex) %&gt;%\n    summarize(mean_weight = mean(weight))\n\n`summarise()` has grouped output by 'genus'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 28 × 3\n# Groups:   genus [10]\n   genus       sex   mean_weight\n   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;\n 1 Baiomys     \"F\"          9.16\n 2 Baiomys     \"M\"          7.36\n 3 Chaetodipus \"\"          19.8 \n 4 Chaetodipus \"F\"         23.8 \n 5 Chaetodipus \"M\"         24.7 \n 6 Dipodomys   \"\"          81.4 \n 7 Dipodomys   \"F\"         55.2 \n 8 Dipodomys   \"M\"         56.2 \n 9 Neotoma     \"\"         168.  \n10 Neotoma     \"F\"        154.  \n# ℹ 18 more rows\n\n\nSince we will use the same filtered and grouped data frame in multiple code chunks below, we could assign this subset of the data to a new variable and use this variable in the subsequent code chunks instead of typing out the functions each time.\n\nfiltered_surveys &lt;- surveys %&gt;%\n    filter(!is.na(weight) & !is.na(sex)) %&gt;%\n    group_by(genus, sex)\n\nIf you want to display more data, you can use the print() function at the end of your chain with the argument n specifying the number of rows to display.\n\nfiltered_surveys %&gt;%\n    summarize(mean_weight = mean(weight)) %&gt;%\n    print(n = 15) # Will change the knitted output, not the notebook\n\n`summarise()` has grouped output by 'genus'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 28 × 3\n# Groups:   genus [10]\n   genus       sex   mean_weight\n   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;\n 1 Baiomys     \"F\"          9.16\n 2 Baiomys     \"M\"          7.36\n 3 Chaetodipus \"\"          19.8 \n 4 Chaetodipus \"F\"         23.8 \n 5 Chaetodipus \"M\"         24.7 \n 6 Dipodomys   \"\"          81.4 \n 7 Dipodomys   \"F\"         55.2 \n 8 Dipodomys   \"M\"         56.2 \n 9 Neotoma     \"\"         168.  \n10 Neotoma     \"F\"        154.  \n11 Neotoma     \"M\"        166.  \n12 Onychomys   \"\"          23.4 \n13 Onychomys   \"F\"         26.8 \n14 Onychomys   \"M\"         26.2 \n15 Perognathus \"\"           6   \n# ℹ 13 more rows\n\n\nOnce the data are grouped, you can also summarize multiple variables at the same time. For instance, we could add a column indicating the minimum weight for each species for each sex:\n\nfiltered_surveys %&gt;%\n    summarize(mean_weight = mean(weight),\n              min_weight = min(weight))\n\n`summarise()` has grouped output by 'genus'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 28 × 4\n# Groups:   genus [10]\n   genus       sex   mean_weight min_weight\n   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;      &lt;int&gt;\n 1 Baiomys     \"F\"          9.16          6\n 2 Baiomys     \"M\"          7.36          6\n 3 Chaetodipus \"\"          19.8          10\n 4 Chaetodipus \"F\"         23.8           5\n 5 Chaetodipus \"M\"         24.7           4\n 6 Dipodomys   \"\"          81.4          24\n 7 Dipodomys   \"F\"         55.2          10\n 8 Dipodomys   \"M\"         56.2          12\n 9 Neotoma     \"\"         168.           83\n10 Neotoma     \"F\"        154.           32\n# ℹ 18 more rows\n\n\n\n3.4.0.1 Challenge\n\nUse group_by() and summarize() to find the mean, min, and max hindfoot length for each species.\nWhat was the heaviest animal measured in each year? Return the columns year, genus, species, and weight.\n\n\n\n3.4.1 Using tally to summarize categorical data\nWhen working with data, it is also common to want to know the number of observations found for each factor or combination of factors. For this, dplyr provides tally(). For example, if we want to group by taxa and find the number of observations for each taxa, we would do:\n\nsurveys %&gt;%\n    group_by(taxa) %&gt;%\n    tally()\n\n# A tibble: 4 × 2\n  taxa        n\n  &lt;chr&gt;   &lt;int&gt;\n1 Bird      450\n2 Rabbit     75\n3 Reptile    14\n4 Rodent  34247\n\n\nWe can also use tally() when grouping on multiple variables:\n\nsurveys %&gt;%\n    group_by(taxa, sex) %&gt;%\n    tally()\n\n# A tibble: 6 × 3\n# Groups:   taxa [4]\n  taxa    sex       n\n  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n1 Bird    \"\"      450\n2 Rabbit  \"\"       75\n3 Reptile \"\"       14\n4 Rodent  \"\"     1209\n5 Rodent  \"F\"   15690\n6 Rodent  \"M\"   17348\n\n\nHere, tally() is the action applied to the groups created by group_by() and counts the total number of records for each category.\nIf there are many groups, tally() is not that useful on its own. For example, when we want to view the five most abundant species among the observations:\n\nsurveys %&gt;%\n    group_by(species) %&gt;%\n    tally()\n\n# A tibble: 40 × 2\n   species             n\n   &lt;chr&gt;           &lt;int&gt;\n 1 albigula         1252\n 2 audubonii          75\n 3 baileyi          2891\n 4 bilineata         303\n 5 brunneicapillus    50\n 6 chlorurus          39\n 7 clarki              1\n 8 eremicus         1299\n 9 flavus           1597\n10 fulvescens         75\n# ℹ 30 more rows\n\n\nSince there are 40 rows in this output, we would like to order the table to display the most abundant species first. In dplyr, we say that we want to arrange() the data.\n\nsurveys %&gt;%\n    group_by(species) %&gt;%\n    tally() %&gt;%\n    arrange(n)\n\n# A tibble: 40 × 2\n   species          n\n   &lt;chr&gt;        &lt;int&gt;\n 1 clarki           1\n 2 scutalatus       1\n 3 tereticaudus     1\n 4 tigris           1\n 5 uniparens        1\n 6 viridis          1\n 7 leucophrys       2\n 8 savannarum       2\n 9 fuscus           5\n10 undulatus        5\n# ℹ 30 more rows\n\n\nStill not that useful. Since we are interested in the most abundant species, we want to display those with the highest count first, in other words, we want to arrange the column n in descending order:\n\nsurveys %&gt;%\n    group_by(species) %&gt;%\n    tally() %&gt;%\n    arrange(desc(n)) %&gt;%\n    head(5)\n\n# A tibble: 5 × 2\n  species          n\n  &lt;chr&gt;        &lt;int&gt;\n1 merriami     10596\n2 penicillatus  3123\n3 ordii         3027\n4 baileyi       2891\n5 megalotis     2609\n\n\nIf we want to include more attributes about these species, we can include these in the call to group_by():\n\nsurveys %&gt;%\n    group_by(species, taxa, genus) %&gt;%\n    tally() %&gt;%\n    arrange(desc(n)) %&gt;%\n    head(5)\n\n# A tibble: 5 × 4\n# Groups:   species, taxa [5]\n  species      taxa   genus               n\n  &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;           &lt;int&gt;\n1 merriami     Rodent Dipodomys       10596\n2 penicillatus Rodent Chaetodipus      3123\n3 ordii        Rodent Dipodomys        3027\n4 baileyi      Rodent Chaetodipus      2891\n5 megalotis    Rodent Reithrodontomys  2609\n\n\nBe careful not to include anything that would split the group into subgroups, such as sex, year etc.\n\n3.4.1.1 Challenge\n\nHow many individuals were caught in each plot_type surveyed?\nYou saw above how to count the number of individuals of each sex using a combination of group_by() and tally(). How could you get the same result using group_by() and summarize()? Hint: see ?n.",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#reshaping-with-pivot_wider-and-pivot_longer",
    "href": "lectures/lec03-data-wrangling.html#reshaping-with-pivot_wider-and-pivot_longer",
    "title": "3  Data wrangling!",
    "section": "3.5 Reshaping with pivot_wider and pivot_longer",
    "text": "3.5 Reshaping with pivot_wider and pivot_longer\n\n3.5.1 Defining wide vs long data\nThe survey data presented here is almost in what we call a long format – every observation of every individual is its own row. This is an ideal format for data with a rich set of information per observation. It makes it difficult, however, to look at the relationships between measurements across plots/trials. For example, what is the relationship between mean weights of different genera across all plots?\nTo answer that question, we want each plot to have its own row, with each measurements in its own column. This is called a wide data format. For the surveys data as we have it right now, this is going to be one heck of a wide data frame! However, if we were to summarize data within plots and species, we can reduce the dataset and begin to look for some relationships we’d want to examine. We need to create a new table where each row is the values for a particular variable associated with each plot. In practical terms, this means the values in genus would become the names of column variables and the cells would contain the values of the mean weight observed on each plot by genus.\nWe can use the functions called pivot_wider() and pivot_longer() (these are newer replacements for spread() and gather(), which were the older functions). These can feel tricky to think through, but do not feel alone in this! Many others have squinted at their data, unsure exactly how to reshape it, so there are many guides and cheatsheets available to help!\n\n\n3.5.2 Summary of long vs wide formats\nLong format:\n\nevery column is a variable\n\nfirst column(s) repeat\n\nevery row is an observation\n\nWide format:\n\neach row is a measured thing\neach column is an independent observation\n\nfirst column does not repeat\n\n\n\n\n3.5.3 Long to Wide with pivot_wider\nLet’s start by using dplyr to create a data frame with the mean body weight of each genus by plot.\n\nsurveys_gw &lt;- surveys %&gt;%\n    filter(!is.na(weight)) %&gt;%\n    group_by(genus, plot_id) %&gt;%\n    summarize(mean_weight = mean(weight))\n\n`summarise()` has grouped output by 'genus'. You can override using the\n`.groups` argument.\n\nsurveys_gw %&gt;% head()\n\n# A tibble: 6 × 3\n# Groups:   genus [1]\n  genus   plot_id mean_weight\n  &lt;chr&gt;     &lt;int&gt;       &lt;dbl&gt;\n1 Baiomys       1        7   \n2 Baiomys       2        6   \n3 Baiomys       3        8.61\n4 Baiomys       5        7.75\n5 Baiomys      18        9.5 \n6 Baiomys      19        9.53\n\n\nNow, to make this long data wide, we use pivot_wider() from tidyr to spread out the different taxa into columns. pivot_wider() takes 3 arguments: the data , the names_from column variable that will eventually become the column names, and the values_from column variable that will fill in the values. We’ll use a pipe so we don’t need to explicitly supply the data argument.\n\nsurveys_gw_wide &lt;- surveys_gw %&gt;% \n  pivot_wider(names_from = genus, values_from = mean_weight)\n\nhead(surveys_gw_wide)\n\n# A tibble: 6 × 11\n  plot_id Baiomys Chaetodipus Dipodomys Neotoma Onychomys Perognathus Peromyscus\n    &lt;int&gt;   &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1       1    7           22.2      60.2    156.      27.7        9.62       22.2\n2       2    6           25.1      55.7    169.      26.9        6.95       22.3\n3       3    8.61        24.6      52.0    158.      26.0        7.51       21.4\n4       5    7.75        18.0      51.1    190.      27.0        8.66       21.2\n5      18    9.5         26.8      61.4    149.      26.6        8.62       21.4\n6      19    9.53        26.4      43.3    120       23.8        8.09       20.8\n# ℹ 3 more variables: Reithrodontomys &lt;dbl&gt;, Sigmodon &lt;dbl&gt;, Spermophilus &lt;dbl&gt;\n\n\nNow we can go back to our original question: what is the relationship between mean weights of different genera across all plots? We can easily see the weights for each genus in each plot! Notice that some genera have NA values. That’s because some genera were not recorded in that plot.\nYou may have used spread()in the past, which also takes three arguments: the data, the key column (or column with identifying information), and the values column (the one with the numbers/values).\n\nsurveys_gw_wide0 &lt;- surveys_gw %&gt;%\n  spread(key = genus, value = mean_weight) \n\nhead(surveys_gw_wide0)\n\n# A tibble: 6 × 11\n  plot_id Baiomys Chaetodipus Dipodomys Neotoma Onychomys Perognathus Peromyscus\n    &lt;int&gt;   &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1       1    7           22.2      60.2    156.      27.7        9.62       22.2\n2       2    6           25.1      55.7    169.      26.9        6.95       22.3\n3       3    8.61        24.6      52.0    158.      26.0        7.51       21.4\n4       4   NA           23.0      57.5    164.      28.1        7.82       22.6\n5       5    7.75        18.0      51.1    190.      27.0        8.66       21.2\n6       6   NA           24.9      58.6    180.      25.9        7.81       21.8\n# ℹ 3 more variables: Reithrodontomys &lt;dbl&gt;, Sigmodon &lt;dbl&gt;, Spermophilus &lt;dbl&gt;\n\n\n\n\n3.5.4 Wide to long with gather and pivot_longer\nWhat if we had the opposite problem, and wanted to go from a wide to long format? For that, we can use pivot_longer() to gather a set of columns into one key-value pair. To go backwards from surveys_gw_wide, we should exclude plot_id.\npivot_longer() takes 4 arguments: the data, the names_to column variable that comes from the column names, the values_to column with the values, and cols which specifies which columns we want to keep or drop. Again, we will pipe from the dataset so we don’t have to specify the data argument:\n\nsurveys_gw_long2 &lt;- surveys_gw_wide %&gt;% \n  pivot_longer(names_to = \"genus\", values_to = \"mean_weight\", cols = -plot_id)\n\nsurveys_gw_long2\n\n# A tibble: 240 × 3\n   plot_id genus           mean_weight\n     &lt;int&gt; &lt;chr&gt;                 &lt;dbl&gt;\n 1       1 Baiomys                7   \n 2       1 Chaetodipus           22.2 \n 3       1 Dipodomys             60.2 \n 4       1 Neotoma              156.  \n 5       1 Onychomys             27.7 \n 6       1 Perognathus            9.62\n 7       1 Peromyscus            22.2 \n 8       1 Reithrodontomys       11.4 \n 9       1 Sigmodon              NA   \n10       1 Spermophilus          NA   \n# ℹ 230 more rows\n\n\nIf the columns are directly adjacent as they are here, we don’t even need to list the all out: we can just use the : operator, as before.\n\nsurveys_gw_wide %&gt;% \n  pivot_longer(names_to = \"genus\", values_to = \"mean_weight\", cols = Baiomys:Sigmodon)\n\n# A tibble: 216 × 4\n   plot_id Spermophilus genus           mean_weight\n     &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n 1       1           NA Baiomys                7   \n 2       1           NA Chaetodipus           22.2 \n 3       1           NA Dipodomys             60.2 \n 4       1           NA Neotoma              156.  \n 5       1           NA Onychomys             27.7 \n 6       1           NA Perognathus            9.62\n 7       1           NA Peromyscus            22.2 \n 8       1           NA Reithrodontomys       11.4 \n 9       1           NA Sigmodon              NA   \n10       2           NA Baiomys                6   \n# ℹ 206 more rows\n\n\nNote that now the NA genera are included in the long format.\nIn the past, you may have used gather(). We give it the arguments of a new key and value column name, and then specify which columns we either want or do not want gathered up. So, togo backwards from surveys_gw_wide, and exclude plot_id from the gathering, we would do the following:\n\nsurveys_gw_long1 &lt;- surveys_gw_wide0 %&gt;%\n  gather(genus, mean_weight, -plot_id) \n\nhead(surveys_gw_long1)\n\n# A tibble: 6 × 3\n  plot_id genus   mean_weight\n    &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n1       1 Baiomys        7   \n2       2 Baiomys        6   \n3       3 Baiomys        8.61\n4       4 Baiomys       NA   \n5       5 Baiomys        7.75\n6       6 Baiomys       NA   \n\n\n\n3.5.4.1 Challenge\nStarting with the surveys_gw_wide dataset, how would you display a new dataset that gathers the mean weight of all the genera (excluding NAs) except for the genus Perognathus?",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "lectures/lec03-data-wrangling.html#footnotes",
    "href": "lectures/lec03-data-wrangling.html#footnotes",
    "title": "3  Data wrangling!",
    "section": "",
    "text": "This course is focused on tidyverse functions, because that seems to be the trend these days. Although all of our teaching material is written in tidy lingo, it is mostly for the sake of consistency. In all honesty, tidy is pretty great, but some functions are more intuitive in base, so most people code in a mix of the two. If you learned base R elsewhere and prefer to use those functions instead, by all means, go ahead. The correct code is code that does what you want it to do.↩︎",
    "crumbs": [
      "Lectures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling!</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-00.html",
    "href": "assignments/assignment-00.html",
    "title": "Assignment00: individual interest description",
    "section": "",
    "text": "Download the .Rmd file  here.\nTo submit this assignment, upload the full document on Quercus, including the original questions, your code, and the output. Submit your assignment as a knitted .pdf.\n\nGet set up at home (or on a lab computer after hours)\n\nIf you have not already done so, install R and RStudio (already installed on the lab computers).\nOpen a new R Notebook and read the instructions about how to use the R Markdown syntax.\nOpen this assignment file in RStudio or copy its content into an empty R Notebook.\nInsert a code chunk below, above Question 2. Set eval=FALSE\nIn the code chunk, use install.packages(\"&lt;package_name&gt;\") to install tidyverse and rmarkdown. Remember to run the code chunk to execute the commands.\nLoad the two libraries you just installed into your environment with library(&lt;package_name&gt;) (no surrounding quotation marks). Add this to the same code chunk you created previously and execute it again.\n\nDon’t worry that the install.packages() commands have already been executed once, R is smart and checks if you already have those installed.\n\nRun sessionInfo() to list all the loaded packages.\n\nYou should see the following packages under “other attached packages”: rmarkdown, dplyr, purrr, readr, tidyr, tibble, ggplot, and tidyverse.\n\nSince this is your first assignment, we have already completed most of this question below. You still need to run the code chunk on your computer to confirm that the packages installed and to get the sessionInfo() output for your computer. You might receive warnings that functions from other packages are masked when you load tidyverse, but this is fine.\n\n\n\nIn 4-5 sentences, what are some of the topics/questions in ecology and evolutionary biology that you are interested in for the group project?",
    "crumbs": [
      "Assignments",
      "Assignment00: individual interest description"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html",
    "href": "assignments/assignment-01.html",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "",
    "text": "1. Variable assignment (1 mark)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#variable-assignment-1-mark",
    "href": "assignments/assignment-01.html#variable-assignment-1-mark",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "",
    "text": "Assign the value 5 to the variable/object a. Display a. (0.25 marks)\n\n\nAssign the result of 10/3 to the variable b. Display b. (0.25 marks)\n\n\nWrite a function that adds two numbers and returns their sum. Use it to assign the sum of a and b to result. Display result. (In practice, there is already a more sophisticated built-in function for this: result &lt;- sum(a, b)) (0.25 marks)\n\n\nWrite a function that multiplies two numbers and returns their product. Use it to assign the product of a and b to product. Display product. (In practice, there is already a more sophisticated built-in function for this: product &lt;- prod(a, b)) (0.25 marks)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#vectors-2.5-marks",
    "href": "assignments/assignment-01.html#vectors-2.5-marks",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "2. Vectors (2.5 marks)",
    "text": "2. Vectors (2.5 marks)\n\nCreate a vector v with all integers 0-30, and a vector w with every third integer in the same range. (0.25 marks)\n\n\nWhat is the difference in lengths of the vectors v and w? (0.25 marks)\n\n\nCreate a new vector, v_square, with the square of elements at indices 3, 6, 7, 10, 15, 22, 23, 24, and 30 from the variable v. Hint: Use indexing rather than a for loop. (0.25 marks)\n\n\nCalculate the mean and median of the first five values from v_square. (0.25 marks)\n\n\nCreate a boolean vector v_bool, indicating which vector v elements are bigger than 20. How many values are over 20? Hint: In R, TRUE = 1, and FALSE = 0, so you can use simple arithmetic to find this out. (0.5 marks)\n\n\nWrite a function that calculates the median of the last two elements of any numeric vector. Test this function with the v and v_square vectors. (1 marks)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#data-frames-1.5-marks",
    "href": "assignments/assignment-01.html#data-frames-1.5-marks",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "3. Data frames (1.5 marks)",
    "text": "3. Data frames (1.5 marks)\n\nThere are many built-in data frames in R, which you can find more details about online. What are the column names of the built-in dataframe beaver1? How many observations (rows) and variables (columns) are there? (0.5 marks)\n\n\nDisplay both the first 6 and last 6 rows of this data frame. Show how to do so with both indexing as well as specialized functions. (0.5 marks)\n\n\n# With indexing\n\n\n# With functions\n\n\nWhat is the min, mean, and max body temperature for beavers inside and outside of the retreat? Hint: You can use ? on the beaver1 data set to get more information about it. Remember that each column in a data frame is a vector and you can use the same functions. (0.5 marks)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#command-line-1-mark",
    "href": "assignments/assignment-01.html#command-line-1-mark",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "4. Command line (1 mark)",
    "text": "4. Command line (1 mark)\nWhat commands would you run to create a directory named “mydir”, check mydir’s permissions, add write permissions for users, copy mydir to “mydir2” , and then remove mydir? Hint: try running each step in your terminal to check if the output is what you expect (1 mark)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#understanding-command-line-software-1-mark",
    "href": "assignments/assignment-01.html#understanding-command-line-software-1-mark",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "5. Understanding command line software (1 mark)",
    "text": "5. Understanding command line software (1 mark)\nOpen the documentation for Earl Grey, a software programme that identifies transposable elements in genomes. There may be a lot of unfamilliar terms on this web page, but we’ll just be skimming this page to practice identifying the kind of information command line software might require and how to provide that.\n\nWhat three arguments (files/information) are required input for this software? (0.3 marks)\nWhat would you type into the command line to provide Earl Grey with those minimum command options? You don’t need to make up example text for this, just ensure you have the three - arguments written out. Hint: search for “minimum command options” on the GitHub page and use the next line (0.3 marks)\nBased on the visual overview of the software (or the “Example Outputs” section) on the GitHub page, what does this software output? (0.2 marks)\nWhat optional parameter (i.e. the - argument) does Earl Grey offer to display help information? Is this kind of help parameter common? Hint: you can search for “help documentation” in your lecture notes (0.2 marks)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "assignments/assignment-01.html#github-1-mark",
    "href": "assignments/assignment-01.html#github-1-mark",
    "title": "Assignment 01: base R, command line, & Git(Hub)",
    "section": "6. GitHub (1 mark)",
    "text": "6. GitHub (1 mark)\n\nMake a Github account. You can do this at github.com. What is your GitHub username? (1 mark)",
    "crumbs": [
      "Assignments",
      "Assignment 01: base R, command line, & Git(Hub)"
    ]
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Project description",
    "section": "",
    "text": "Option 1: Hypothesis-driven project\nGroups will formulate their own hypotheses based on their interests within ecology and evolution. Groups will test predictions borne out of their hypotheses with reproducible and quantitative analysis techniques (e.g., ANOVA). If your group has an idea for statistical analyses that are beyond the scope of the course, please let us know. We are happy to support any groups who want to learn new tools, but expect that these groups are ready to learn how these tools work on their own; we hope to equip you with enough understanding to learn new things independently. Finally, the work must be original – while we may be repurposing data, we will not be simply redoing analyses. Keep in mind also that any work you do as part of this course may not be submitted for credit in another course (such as a fourth-year research project) and vice versa. While you may not submit your work for this course for credit in another course, you are welcome to publish or present your work in an academic setting. (In fact, if you do so, please let us know!)\nA note about community/citizen science websites: since the data is community-controlled, it may not always be research quality. There may be incorrect species IDs, inaccurate geolocations or time of observations, or discrepancies in protocols. When working with community science data, make sure that the data is cleaned and wrangled so that it is reliable. Quality control is a good first step when working with data, as simple errors can exist in any dataset.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#option-1-hypothesis-driven-project",
    "href": "projects.html#option-1-hypothesis-driven-project",
    "title": "Project description",
    "section": "",
    "text": "What is a hypotheses? What is a prediction?\nA hypothesis is a testable and falsifiable statement that offers a possible explanation of a phenomenon based on background knowledge, preliminary observations, or logic.\nE.g., Primary productivity is an important driver of mammal species richness.\nA prediction is based on a hypothesis. It is meant to describe what will happen in a specific situation, such as during an experiment, if the hypothesis is correct.\nE.g., If primary productivity is an important driver of mammal species richness, then more mammalian species would be found in sites with more plant biomass (proxy for primary productivity) compared with sites with less plant growth.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#option-2-modeling",
    "href": "projects.html#option-2-modeling",
    "title": "Project description",
    "section": "Option 2: Modeling",
    "text": "Option 2: Modeling\nGroups will develop a mathematical model to answer a question in ecology and/or evolution they find interesting. There are many reasons to develop models: they help clarify assumptions, generate predictions, nullify hypotheses, provide mechanistic explanations for observed data, and help us know what kinds of data to look for. New models almost always build on existing and well-studied ones (e.g., the Lotka-Volterra model). The fact models are simplifying representations of the real world is by design! The goal of building a model is to identify the key features that make a process interesting, represent the process mathematically (and, in doing so, clarify what assumptions are being made!), characterize the behaviour of the model, and from this characterization draw conclusions about how the process being modelled works. Characterization of a model can involve mathematical analysis, simulation, and confrontation with data.\nThe key steps in this project are to 1) identify an interesting question in ecology or evolution, 2) develop (and likely revise) a model to address that question, 3) characterize the behaviour of the model, and 4) draw biological conclusions from the model and its characterization.\nIf you are interested in modeling, let Mete and Zoë know as soon possible!",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#option-3-simulation-study",
    "href": "projects.html#option-3-simulation-study",
    "title": "Project description",
    "section": "Option 3: Simulation study",
    "text": "Option 3: Simulation study\nSimilar to Option 1, groups that do a simulation study will formulate hypotheses and use reproducible and quantitative analysis techniques to test predictions borne out of those hypotheses. The difference is that students will simulate their own data, instead of using an existing dataset. One reason to do a simulation study is to see what kind of data would be needed to test a hypothesis in the field, e.g., how much data would be needed to find a significant association between response and predictor variables.\nIf you are interested in doing a simulation study, let Mete and Zoë know as soon possible!",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#individual-interest-description",
    "href": "projects.html#individual-interest-description",
    "title": "Project description",
    "section": "Individual interest description",
    "text": "Individual interest description\nDue Sept 12th, worth 1% of final grade\nTo make sure you pair up with group mates who share common interests, we ask that you write a short (4-5 sentences) description of your interests in ecology and evolution. Please do so in RStudio by creating an .Rmd file and knitting it into a pdf.\nHere are some discussion questions to help you:\n\nWhat is a scientific paper or popular science article you read (or a podcast you listened to) recently that you found interesting (how microbial communities differ among environments, frequency of herbicide resistance alleles in weed populations, bird species richness in regions that have experienced climatic shifts, understanding the relationship between longevity and traits like body size in mice…)?\nWhat is your favourite EEB course so far? Why did you like it?\nThinking about EEB professors, was there anyone whose work you are particularly interested in?\nBrowse through some recent issues of broad scope EEB journals such as Trends in Ecology and Evolution and Annual Review of Ecology, Evolution, and Systematics. Any articles catching your eyes?\nCheck out this paper. Any of those questions spark your interest?",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#project-proposal",
    "href": "projects.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nDue Oct 17rd, worth 3% of final grade\nGood research takes time! The purpose of the proposal is to get your group started on this process early on so that you will have sufficient time to do your project justice. This will also serve as official documentation of your project development process. Your projects will likely evolve over time, and there can be many reasons for this. For instance, as you explore your data, you might be inspired to ask different questions, or you may need to refine your hypotheses due to limitations in the data.\nInclude the following information in your proposal:\n\nOption 1: your hypotheses and predictions (point form or short paragraph) and data source (short paragraph). Include a citation, a brief description of how the data was collection, and which section of the dataset you plan to use in your analysis (e.g., which columns).\nOption 2: a question you want to answer using a mathematical model (short paragraph describing the problem and the value modeling may add). Be sure to include a description of the variables that you may want to track and the kind of model you envision using.\nOption 3: same as 1, except with a description of how to simulate the data.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#mid-project-update",
    "href": "projects.html#mid-project-update",
    "title": "Project description",
    "section": "Mid-project update",
    "text": "Mid-project update\nDue Nov 21st, worth 6% of final grade\nThe purpose of the mid-project update is to ensure you are on track with your projects. By now, you should have completed your exploratory data analyses, modelling, or simulation. You should have also solidified your hypotheses, predictions, and analyses plan (i.e., the Methods section of your final report!).\nInclude the following information in your mid-project report:\n\nOptions 1 and 3:\n\n\nYour hypotheses and predictions (point form or short paragraph). If these differ from the ones in your proposal, explain clearly the rationale for the change.\nA detailed description of your data (a paragraph), including how the data was collected or simulated, along with any manipulation(s) you performed to get your data ready for the analysis.\nYour analysis plan (a paragraph): describe the statistical test(s) that you will use to test each prediction, including how you will validate the assumptions of each test.\n\n\nOption 2:\n\n\nA detailed description of the question you want to answer, any previous work (modelling and otherwise), the model you have built to answer this question, and your modelling assumptions.\nDetailed descriptions of the model analysis and biological interpretations of the results so far.\nYour analysis plan (a paragraph): describe additional analysis that you will do and any assumptions you would like to relax.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#presentation",
    "href": "projects.html#presentation",
    "title": "Project description",
    "section": "Presentation",
    "text": "Presentation\nDue Dec 3rd, worth 10% of final grade\nThe presentations will be held on the last day of class during regular class hours (Dec 3rd, 2-4 pm). Each presentation will be 10 minutes long, followed by 2 minutes of questions from the audience. If you cannot make it to class, please get in touch with us to make alternative arrangements no later than Nov 28th.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#report",
    "href": "projects.html#report",
    "title": "Project description",
    "section": "Report",
    "text": "Report\nDue Dec 10th, worth 20% of final grade\nThis report will be styled as a journal article, with these sections:\n\nAbstract\nIntroduction\nMethods (including “Data Description” and “Data Analysis” subsections)\nResults\nDiscussion\nReferences\nSupplementary material consisting of data and code required to reproduce analysis\n\nFor your sake (and ours), we are enforcing a two page limit (single spaced, excluding figures, tables, code, references, and appendices). Please use a standard font, size 12, with regular margins. One goal of this assignment is to write clearly and concisely – it is often clarifying to put your analyses in as few words as possible.\nFor the report, you are expected to:\n\nPut your research questions in the context of existing research and literature.\nHave clear and explicit objectives, hypotheses, and/or predictions.\nAdequately describe and properly cite the data source(s) you will analyze. If your project involves modeling, describe other modeling work that is relevant.\nDescribe your analysis in sufficient detail for others to understand.\nDiscuss the interpretation of your results and their implications.\n\nThe data and code associated with your report is expected to be entirely reproducible. Your supplementary files must include the following:\n\nA description of what every column/row in your submitted data file.\nA well-annotated R script or R notebook file. We must be able to run your code once you submit the project. This lesson on best practices for writing R code is a good starting place. Also check out this coding style guide and these simple rules on how to write code that is easy to read.\n\nHermann et al. 2016 is a great example of what we expect your code to look like. Refer to their supplementary materials for examples of how to describe your data set and how to annotate your code.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#individual-interest-description-1",
    "href": "projects.html#individual-interest-description-1",
    "title": "Project description",
    "section": "Individual interest description",
    "text": "Individual interest description\n1 marks total\nThis part of the project will be graded based on completion. That said, it will help determine your group-mates. Make sure to spend some time on it and reflect on what questions in EEB you would like to work on.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#project-proposal-1",
    "href": "projects.html#project-proposal-1",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\n3 marks total\nOption 1: Two marks for your hypotheses and associated predictions, and one mark for a description of your data source(s). Students are expected to demonstrate effort in formulating hypotheses and predictions, and identifying a suitable dataset.\nOption 2: 1.5 marks each for 1) a clear description of the question or problem in ecology or evolution you would like to address using a model, and 2) a description of the kind of model you envision using, including what variables to track.\nOption 3: One mark for your hypotheses and associated predictions, and two marks for describing the appropriate analyses.\nThese components will be graded mostly on completion. The purpose of this assignment is to ensure you start early and are heading towards the right track.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#mid-project-update-1",
    "href": "projects.html#mid-project-update-1",
    "title": "Project description",
    "section": "Mid-project update",
    "text": "Mid-project update\n6 marks total\nOptions 1 and 3: Two marks are given to clearly stating hypotheses and predictions. In the case that these are different from those in the proposal, the rationale for refinement needs to be clearly explained.\nEach of the following criteria are scored out of 2: 2 == excellent, 1.5 == good, 1 == acceptable, but needs improvement.\n\nData description\n\nThe data source(s) are sufficiently described, specifically, where was the obtained and how it was originally collected.\nThe data is sufficient described, including any initial observations from your exploratory data analyses.\nThe suitability of the data is justified.\nAny manipulations done to the data are thoroughly explained and well-justified.\n\nData analysis plan\n\nClearly lay out the statistical test(s) you will use to test each prediction.\nState how you will validating assumptions associated with each statistical test.\n\n\nOption 2: Each of the following criteria are scored out of 3: 3 == excellent, 2 == good, 1 == acceptable, but needs improvement.\n\nDescription of question, previous work, the model, modeling assumptions, and any predictions you have ahead of the analysis\n\nThe question you want to address and previous work in that direction (modeling or otherwise) is described in detail.\nThe relationship between the question/problem and modeling approach is clear and well-justified.\nModeling assumptions and choices (including limitations) are clear and well-motivated.\nPredictions for how the model will behave, what it might have to say about the question/problem, etc. are inclued and well thought out.\n\nAnalysis and analysis plan\n\nThe details of all analysis (mathematical or computational) are explained clearly.\nThe biological interpretations of results so far are clearly presented and their validity/applicability is discussed.\nClearly lay out plans for remaining analysis (e.g., relaxing model assumptions) and justify why they are reasonable.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#the-presentation",
    "href": "projects.html#the-presentation",
    "title": "Project description",
    "section": "The presentation",
    "text": "The presentation\n10 marks total\nEach of the following criteria are scored out of 3: 3 == excellent, 2 == adequate, 1 == needs improvement.\n\nContent – background and methods\n\nThe context for the study, along with hypotheses and predictions, are clearly set up.\nData source(s), manipulations, and statistical tests used are succinctly and adequately described.\nIf modeling, the relationship between the question/problem addressed and modeling approach is well-explained, and previous work (modeling or otherwise) is discussed.\n\nContent – results and conclusions\n\nResults are accurately described and interpreted, with particular attention to how they related to the hypotheses and predictions the group set out to test.\nThe conclusion to the study is succinct and clear.\n\nDelivery\n\nAll students participated in presenting the information.\nAll students spoke clearly and without jargon.\nThe presentation is well organized and ideas flowed naturally from one to the next.\nThe presentation is well rehearsed and is an appropriate length.\nFigures are easy to read (e.g., axis labels are big enough to read and are informative) and are explained thoroughly (e.g., x and y axis and what each data point is).\n\n\nThe final 1 mark will be assigned to the question period, and students will be assessed on whether they are able to answer questions thoughtfully.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#the-report",
    "href": "projects.html#the-report",
    "title": "Project description",
    "section": "The report",
    "text": "The report\n20 marks total\nEach of the following criteria are scored out of 4: 4 == excellent, 3 == good, 2 == acceptable, 1 == needs improvement.\n\nContent and concepts\n\nAuthors demonstrate a full understanding of the existing literature on the topic, and these concepts are critically integrated into their own insights.\nOptions 1 and 3: Hypotheses and predictions are clearly defined, and rational for choosing/simulating this data is justified.\nOption 2: The question, modeling approach, and relevant work are thoughtfully explained; the rationale for using the model (and its assumptions) is justified.\n\nCommunication\n\nWriting is succinct, clear, logical, and free of grammatical and spelling errors.\n\nAnalysis: see below.\nResults\n\nResults are accurately and sufficiently described.\nConclusions are supported by evidence.\nFigures and tables are clearly presented and are informative.\n\nCoding style and reproducibility\n\nData and code are well-organized and well-documented.\nThe analysis is easily reproducible.\nAll team members have pushed to a common GitHub repo.\n\n\nNote: marks for the 3rd criterion (Analysis) depend on if groups did a modeling or data-driven project:\nOptions 1 and 3: Statistical analysis\n\nStatistical tests chosen or modeling choices made are appropriate.\nAssumptions for each statistical test is validated.\nLimitations in the data and analysis are discussed.\n\nOption 2: Analysis of model\n\nCharacterization of the model is appropriate and explained in detail.\nImportantly, biological conclusions explained in detail and in terms of the processes described (or not described) by the model.\nLimitations of modeling assumptions are discussed, and extensions are proposed.\n\nPlease note that we are only going to be marking the two pages of your report. Please do not go over the page limit (with the exception of tables, figures, references, and appendices).",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects.html#issues-working-in-groups",
    "href": "projects.html#issues-working-in-groups",
    "title": "Project description",
    "section": "Issues working in groups",
    "text": "Issues working in groups\nIf you are having trouble working with your group, e.g., because you feel like the work is not being equitably divided, please let us know as soon as possible. We will work with you and your group to identify a solution that works for everyone. Do not wait until the last minute to let us know that your group has been having trouble – at that point, there is little we can do to fix the situation. Moreover, we expect group members to communicate with each other and to try to work out their concerns before we become involved.",
    "crumbs": [
      "Project",
      "Project description"
    ]
  },
  {
    "objectID": "projects_databases.html",
    "href": "projects_databases.html",
    "title": "Some open-access databases",
    "section": "",
    "text": "Below are some resources that would be a good to look at if you are in search of data for the term project, or in search of a question in ecology or evolution:\n\nGenBank: annotated collection of all publicly available DNA/protein sequences. It is possible to download sequences manually, but command line tools can help to automate the process.\nPanTHERIA: database of ecology, life history, and geography of all extant and recently extinct mammal species. Includes body size, lifespan, litter size, and other trait data at the species level.\nThe Open Traits Network has information about trait datasets for other taxa – including spiders, nematodes, amphibians, and birds!\nGene Expression Omnibus: repository of gene expression, methylation, and annotated genomic data which are (like GenBank) most readily accessible using command line tools.\nContinuous Plankton Recorder Survey: data (going back to 1958!) on northern hemisphere plankton species, including the location (latitude, longitude) and date of sampling.\nRed-backed salamander abundance: abundance of red-backed salamanders from 4 sites in the Bruce Peninsula from 2004 to 2017.\nNorth American Bird Breeding Survey: repository containing information regarding the number of birds at multiple sites in North America. Many datasets of varying size that need to be linked together.\nMalaria Atlas Project: publicly available and up-to-date malaria prevalence and distribution data. Vector distribution, bednet coverage, etc. data also available.\nGISAID hosts much of the available sequence data for rapidly-evolving RNA viruses such as influenza, SARS-CoV-2, monkeypox, and RSV as well as relevant meta-data (e.g., host species).\n\nLet Mete and Zoe know if data from any of these resources interests you, or if you would like to discuss where data to answer questions you find interesting might be found…",
    "crumbs": [
      "Project",
      "Some open-access databases"
    ]
  }
]