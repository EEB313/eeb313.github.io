# Linear mixed models

```{r, include=F}
library(tidyverse)
library(broom)
theme_set(theme_bw())
```

## Lesson preamble

> ### Learning objectives
>
> - Understand the structure of linear mixed models.
> - Understand how linear mixed models are fitted via maximum liklihood.
> - Understand the differences between fixed and random effects.
> - Apply random effects models to nested experimental data.
> - Apply mixed models to data of Fitzpatrick et al.
> 
> ### Lesson outline
> - Describe the structure of a linear mixed model, the form of the likelihood function, and how fixed/random effects are estimated. Discuss how variance components can be estimated.
> - Familiarize ourselves with the RIKZ data.
> - Perform standard linear regression on the RIKZ data. Check the assumptions of multiple regression, including the independence of observations.
> - Explore ways to overcome this violation without the use of mixed effects modeling.
> - Apply random intercept, random intercept and slope, and random-effects only models to RIKZ data. Discuss the differences between these models.
> - Explore to how use mixed-effects models for more deeply nested data. 
> - Explore differences between nested and crossed random effects.
> 
> ### Required packages
>
> - `tidyverse`
> - `ggalt`
> - `lme4`
> - `lmerTest`
> - `ggalt`
> - `MuMIn`
> - `sjmisc`

## Why linear mixed models?

Last class we discussed how to apply linear models to data (e.g., linear
regression, ANOVA, etc.) to understand the relationship between predictor (i.e.,
independent) and response (i.e., dependent) variables. As a reminder, the usual assumptions are:

1. Normality of the errors
2. Homogeneity of error variances
3. Independence of observations

Although one can model the distribution of the data differently (e.g., using transformations or GLMMs), serious violations of independence and equality of error variances can pose problems and result in biased parameter estimates and $p$-values. Additionally, ecological and evolutionary data are often very messy, with a lot of noise, unequal sample sizes, and missing data. Thankfully, **linear mixed effects models provide us with an estimation and inference framework which alleviates violations of these assumptions**. Mixed effects models also allow us to better understand the sources of variation in the data; in quantitative genetics, for example, the goal of many analyses is to understand how much variation in a trait is additive, and this involves estimating what is called the _additive genetic variance_ using a mixed effects model. Like linear models of other kinds, mixed effects models can be fit via maximum likelihood.

## Fitting LMMs

A linear mixed effects model is of the form

$$\boldsymbol{y}_i = \boldsymbol{X}_i \boldsymbol{\beta} + \boldsymbol{Z}_i \boldsymbol{b}_i + \boldsymbol{\varepsilon}_i,$$

where $\boldsymbol{y}_i$ is the $n_i \times 1$ response vector for observations in the $i$th group ($i = 1,\dots,M$). $\boldsymbol{X}_i$ is an $n_i \times p$ matrix of fixed effects for the observations in group $i$, and $\boldsymbol{\beta}$ is a $1 \times p$ vector of fixed effects. Similarly, $\boldsymbol{Z}$ is a $n_i \times q$ matrix of $q$ random effects associated to the observations in group $i$, and $\boldsymbol{b}_i$ is a $q \times 1$ vector of random coefficients for group $i$. This is called the Laird-Ware form of the linear mixed model. 

A more compact way to write an LMM is as follows:

$$\boldsymbol{y} = \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{Z} \boldsymbol{b} + \boldsymbol{\varepsilon}.$$

The random effect coefficients $b_{i1},\dots,b_{iq}$ for group $i$ are assumed to be $\text{Normal}(0,\psi_i^2)$. Furthermore, $\text{Cov}(b_i,b_{i'}) = \psi_{ii'}$ so that the random effects need not be independent of each other. In the more compact notation, $\boldsymbol{b} \sim \text{Normal}(0,\boldsymbol{\Psi}).$ Other distributions can be used to model variability in the random effects, but the choice of a Normal distribution has advantages which we will not get into here. In a similar spirit, to make estimation and inference of LMMs tractable, the errors $\boldsymbol{\varepsilon}$ are assumed to be $\text{Normal}(0,\boldsymbol{\Lambda})$, where $\boldsymbol{\Lambda}$ is the matrix of error variances (on the diagonal) and co-variances (on the off-diagonal).

**Importantly, we interested in random effects insofar as they can provide information and help form inferences about the distribution of response measurements at different levels. Because the random effects are unobserved, we must first estimate the fixed effects.** The assumptions we have made about the random effects and error variances imply $\boldsymbol{y}|\boldsymbol{b} \sim \text{Normal}(\boldsymbol{X} \boldsymbol{\beta}, \boldsymbol{\Sigma})$, where $\boldsymbol{\Sigma} = \boldsymbol{Z} \boldsymbol{\Psi} \boldsymbol{Z}' + \boldsymbol{\Lambda}$. _Conditional on the random effects, the data are independent._ The log-likelihood for the data is

$$\frac{1}{2} \ln |\boldsymbol{\Sigma}| - \frac{1}{2} (\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta})'  \boldsymbol{\Sigma}^{-1} (\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}).$$

### Estimating fixed, random effects with $\boldsymbol{\Sigma}$ known

Maximizing the log-likelihood with respect to $\boldsymbol{\beta}$ gives $\boldsymbol{\hat{\beta}_{\text{MLE}}} = (\boldsymbol{X}' \boldsymbol{\Sigma}^{-1}\boldsymbol{X})^{-1} \boldsymbol{X}' \boldsymbol{\Sigma}^{-1} \boldsymbol{y}.$ This, as in standard regression theory, is the best linear unbiased estimator (BLUE) of the fixed effects. In addition to the estimation of fixed effects, prediction^[To emphasize the fact the random effects come from a population (distribution) of such effects, this term is used.] of random effects is often of interest. The best linear unbiased predictor (BLUP) of the random effects is $\boldsymbol{\hat{u}} = \boldsymbol{\Psi}\boldsymbol{Z}'(\boldsymbol{Z} \boldsymbol{\Psi} \boldsymbol{Z}'+\boldsymbol{\Lambda})^{-1}(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\hat{\beta}})$.

\newpage

_Note_: the ML estimator of the random effects is biased, so Restricted ML Estimation (REML) is often used. It’s generally good to use REML when you are interested in the magnitude of the random effects variances, but do not do this when comparing models with different fixed effects.

### Estimation and inference when $\boldsymbol{\Sigma}$ is unknown

In the preceding discussion, we have assumed the variance-covariance matrices $\boldsymbol{\Psi},\boldsymbol{\Lambda}$. This is rarely the case. Sometimes, modelers will specify variance-covariance matrices of a certain form (so that there are not so many parameters the model becomes impossible to fit). Otherwise, it is advisable to use methods that estimate the variance components from the data. In today's lecture, we will have to estimate varience components to get a sense of how much random effects matter and shape variation in the data. The math that goes into correctly estimating varience components is quite complicated, but we'll mention that an algorithm known as expectation-maximization can often be used.

### On the difference between fixed and random effects

One of the most tricky things about mixed effects modeling is deciding what co-variates are "fixed" and which are "random" --- sometimes, a co-variate can be both! The meaning of "fixed" and "random" can, ironically, be variable depending on in what context they are used, and who they are used by. As a rule of thumb, a random effect is one which is drawn from a population of effects and can be used to _combine information from different groups_ to learn about the properties (e.g, the variance) of that distribution.

\vspace{12pt}

For more on this, see

- [this thread on the difference between fixed and random effects](https://stats.stackexchange.com/questions/238005/what-is-the-intuition-on-fixed-and-random-effects-models)
- [this page of linear mixed modeling questions and answers, maintained by Dr. Ben Bolker](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#when-can-i-include-a-predictor-as-both-fixed-and-random)
- [this paper by Bolker et al.](https://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(09)00019-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0169534709000196%3Fshowall%3Dtrue)

## On to data analysis!

### The RIKZ dataset

Throughout the lecture, we will be making use of the RIKZ dataset. The data are as follow: for each of 9 intertidal areas (denoted ‘Beaches’), the researchers sampled five sites (denoted ‘Sites’) and at each site they measured abiotic variables and the diversity of macro-fauna (e.g. aquatic invertebrates). Here, species richness refers to the total number of species found at a given site while NAP (i.e. Normal Amsterdams Peil) refers to the height of the sampling location relative to the mean sea level and represents the amount of food available for birds, etc. The data are described in more detail in Zuur et al. (2009).

```{r message=FALSE, warning=FALSE}
rikz_data <- read_csv("rikz_data.csv")
head(rikz_data)
```

The question we'll try to answer with this data is: _What is the influence of NAP on species richness?_

![Diagrammatic representation of the RIKZ dataset (modified from Zuur _et al._ (2009), Chapter 5)](RIKZ_data.png)

#### Challenge 

Now that you are experts at exploring data, work in groups to answer the following questions and get familiar with this dataset!

1. How many columns of data are there? How many rows of data? Are all the data columns classified correctly?

2. What do the distributions of NAP and Richness look like? Take note of if these distributions are symmetric, and whether or not there are any outliers.
    
3. Make a plot of the relationship between NAP and Richness. How would you describe this relationship? 

```{r}
# question 1
str(rikz_data)
head(rikz_data)

is.factor(rikz_data$Beach)
rikz_data <- rikz_data %>% mutate(Beach = as.factor(Beach))

# we can see that the data contains 45 rows (observations). 
# as expected, observations were taken across 9 beaches, each with 5 sites. 
# we have encoded 'Beach' as a factor...
# this will facilitate plotting and its use as a random effect downstream.
```

```{r}
# question 2
rikz_data %>% select("NAP", "Richness", "Beach") %>% 
  pivot_longer(1:2) %>% ggplot(aes(x = value)) + geom_histogram() + 
  facet_wrap(~name, scales = "free_x")
```

```{r}
# question 3
ggplot(rikz_data, aes(x = NAP, y = Richness)) + geom_point(size = 2) +
    geom_smooth(method = "lm", se = F, color = "gray")
```

### Limitations of simple linear models

Let's go ahead and perform a linear regression to examine the relationship between species richness and NAP, pooling data across all beaches to see if it matches our expectation based on the graph.

```{r Standard linear regression}
model <- lm(Richness~NAP, data=rikz_data)
summary(model)
```

It appears there is a significant relationship between NAP and species richness! Next we assess if the assumptions (equality of variances, normality) of the linear model are met. Thankfully, `plot()` applied to a linear model does all of diagnostic work for us.

```{r}
par(mfrow=c(2,2)) # look at all 4 plots together
plot(model)
```


The **residual plot** suggests that the homogeneity assumption is violated
(increasing variance in the residuals with increasing fitted values). Similarly,
the **QQ plot** suggests non-normality (points falling off of the dotted line). The **scale-location plot** shows us that the assumption of equal variance between groups (homoscedasticity) is violated, since the residuals are not spread equally along predictors, but instead the range of residuals is wider as the x-axis increases. Finally, **residuals vs. leverage** helps to identify influential data points on the model (e.g., outliers, but also non-outlier points that don't follow the trend) -- look for points with a high Cook's distance, outside the dashed line(s) on the top-right or bottom-right. Lucky for us, there are no highly-influential points; in fact, we can barely see the Cook's distance lines.

#### Transformations to the rescue?

Let's try a third root transformation to see if that helps:

```{r}
model_3rd_root_transform <- lm(Richness^(1/3)~NAP, data=rikz_data)
par(mfrow=c(2,2)) # look at all 4 plots together                                 
plot(model_3rd_root_transform)
```

A third-root transformation of the response variable (i.e. Richness) seems to alleviate our three problems. Nonetheless, for the analyses in this section, we will ignore violations of these assumptions and carry out the rest of the analysis with un-transformed data for the purpose of highlighting the fact that these data violate yet a key assumption, _independence of observations_.

### Non-independence of observations

The species richness data come from multiple sites within multiple beaches. While each beach may be independent, sites within a beach are likely to have similar species richness due simply to their proximity within the same beach. In other words, observations among sites within a beach are **not independent**. Another way of saying this is that the data are _nested_. Nesting in this sense is a product of the experimental design (i.e., we chose to sample 5 sites within each beach) and not necessarily of the data itself. Other types of nested data include: sampling the same individual pre- and post-treatment or sampling them multiple times (i.e., repeated measures), or sampling multiple tissues from the same individuals.

### Ways to deal with non-independence in the data

1. One way to account for the non-independence of observations would be to _run a separate analysis for each beach_. In this case, each analysis only has five observations to work with, and we have to run multiple tests. This means we run the risk of obtaining spuriously significant results by chance.

```{r}
models <- NULL

for (i in 1:9){
  data <- rikz_data %>% subset(Beach == i)
  models[[i]] <- cbind(
    summary(lm(Richness~NAP, data = data))$coefficients[,c(1,4)],
    Beach = i)
}

do.call(rbind, models)
```

2. Alternatively, one could account for the fact observations are non-independent by including a term for each beach in the model, and estimate a separate effect for each level. 

In this case, adding terms to account for between-beach differences did not change our interpretation of the association between NAP and species richness (which is still negative and significant). However, the inclusion of additional terms in this way will sometimes change the estimated effect of other terms in the model and alter their interpretation. The question we need to ask ourselves here is: _Do we really care about differences between beaches represented in the data?_ These beaches were a random subset of all beaches that could have been chosen --- their effects on the response are best modeled as random variables.

```{r}
model_beaches <- lm(Richness ~ NAP + Beach, data = rikz_data)
summary(model_beaches)
```

### Random intercept model

To estimate the variance among beaches and account for the non-independence of sites within beaches, we include Beach as a _random effect_ in our model. NAP remains a _fixed effect_. As such, we model a separate $y$-intercept (i.e. Richness at NAP both = 0) for each beach and estimate the variance around this intercept. A small variance means that variances between beaches are small whereas a large variance means the opposite. We can run mixed-effects models using the `lmer` function from the `lme4` R package and obtain parameter estimates using the `lmerTest` package. The question we are now asking is: _What is the influence of NAP on species richness, accounting for the non-independence of sites within each beach?_

```{r Random intercept model, message=FALSE, warning=FALSE}
library(lme4)
library(lmerTest)

# Random intercept model with NAP as fixed effect and Beach as random effect
mixed_model_IntOnly <- lmer(Richness~NAP+(1|Beach), data=rikz_data, REML=FALSE)
summary(mixed_model_IntOnly)
```

The `(1|Beach)` is the random effect term, where the `1` denotes this is a
random-intercept model and the term on the right of the `|` is a nominal
variable (or factor) to be used as the random effect. `lmer` returns log-likelihood values for the model, as well as information theoretic criteria (AIC, which stands for Akaike information criterion) used to evaluate the goodness-of-fit of the model and preform model selection.

`lmer` also returns an estimated variance for the random effects. For this data, the variance associated with the effect of beach is `7.507`. By dividing the variance of beach by the total variance, we see that differences between beaches account for `(7.507/(7.507+9.111))*100=45%` of the _residual variance_ (i.e., variance left over after accounting for the fixed effects) in the model. Note the _total variance explained by random effects_ (i.e., the sum of the variance components from all the random effects, including the residuals). This allows us to calculate the importance of each random effect relative to each another (as measured by how much of the residual variance it explains), which is crucial to note when there is more than one random effect.

We can visualize the fitted values for this model as follows:

```{r Random intercept fitted values}
rikz_data <- rikz_data %>% mutate(fit_InterceptOnly=predict(mixed_model_IntOnly))
# uses model to predict Richness at NAP

ggplot(rikz_data, aes(x=NAP, y=Richness, colour=Beach)) +
  
  # fixed effect regression line (read values off of model output above)
  geom_abline(aes(intercept=6.5844, slope=-2.5757), linewidth=2) +
  
  # fitted values (i.e., regression lines) for each beach
  geom_line(aes(y=fit_InterceptOnly), linewidth=1) +
  geom_point(size=3)
```

The thick black line corresponds to the fitted values associated with the
fixed-effect component of the model. The thin coloured
lines correspond to the fitted values estimated for each beach. As you can see,
they all have separate intercepts, as expected. As the estimated variance of the
random effect increases, these lines would become more spread out around the thick
black line. If the variance was $=0$, all the coloured lines would coincide with
the thick black line.

### Random intercept-slope model

The model above allows the intercept for each beach to vary around the
population-level intercept. This means that each beach may differ in species richness, but how that respond to NAP remains the same across beaches. However, what if beaches don't only vary in their mean richness, but the richness on each beach also varies in its response to NAP? 

In a standard regression, this would amount to including NAP, Beach and
interaction effects in the model. Of course, including such fixed-effects here
would consume way too many degrees of freedom and we already decided we don't
really care about differences between beaches _per se_. Thankfully, we can still allow beaches to vary in the response to NAP using a random intercept-slope model.

We can fit the random intercept-slope model to these data using the code below.

```{r Random intercept-slope model}
mixed_model_IntSlope <- lmer(Richness~NAP+(1+NAP|Beach), data=rikz_data, REML=FALSE)
summary(mixed_model_IntSlope)
```

The above model now allows both the intercept and slope of the relationship
between Richness and NAP to vary across beaches. The only difference here is the
additional variance component in the random effects, which estimates the
variance in slopes across beaches. It also includes a `Corr` term, which
estimates the correlation between the intercept and slope variances. A correlation of -1, for example, would imply that beaches with larger intercepts also have more steeply negative slopes, as can be seen in the figure below.

```{r Random intercept-slope fitted values}
rikz_data$fit_IntSlope <- predict(mixed_model_IntSlope)

ggplot(rikz_data, aes(x=NAP, y=Richness, colour=Beach)) +
    geom_abline(aes(intercept=6.582, slope=-2.829), linewidth=2) +
    geom_line(aes(y=fit_IntSlope), linewidth=1) +
    geom_point(size=3)
```

### Random effects only model

Note that it is not always necessary to specify fixed effects, in the same way
that it is not always necessary to specify random effects. For example, we could
run the following model which would allow us to solely estimate the variation in species richness between beaches. Here, `1` is used as a placeholder to indicate no fixed effects are fitted.

```{r Random effects only model}
mixed_model_NoFix <- lmer(Richness~1+(1|Beach), data=rikz_data, REML=TRUE)
### note we are using REML because we are not interested in the fixed effects
### varience component estimation is more accurate with REML
summary(mixed_model_NoFix)
```

```{r Random effects fitted values}
rikz_data$fit_NoFix <- predict(mixed_model_NoFix)

ggplot(rikz_data, aes(x=NAP, y=Richness, colour=Beach)) +
    geom_abline(aes(intercept=6.582, slope=-2.829), linewidth=2) +
    geom_line(aes(y=fit_NoFix), linewidth=1) +
    geom_point(size=3)
```

### Inspecting model fit

In previous lectures we emphasized how regression models seek the "best fit model" (that is: the one that maximizes the liklihood of the observed data under some parametric model, e.g., normal errors, for the generative process). But we need to be careful that the "best fit" might not be a "good fit" after all! To inspect model fit, we look to the _coefficient of determination_, or $R^2$, which represents the percentage of variance in your data that is explained by your model. In simple linear models, the $R^2$ value is rather straightforward and included in the `summary` output. In a mixed model, this is slightly more complicated, as we now have to think about about variance explained by the fixed effects as well as random effects. Here, we introduce an extension to the concept of $R^2$:

  * Conditional $R^2$ ($R_c^2$): Variance explained by both fixed and random effects
  * Marginal $R^2$ ($R_m^2$): Variance explained by fixed effects only

And of course `R` has handy functions to help us calculate these:

```{r warning=FALSE}
library(MuMIn)

r.squaredGLMM(mixed_model_IntOnly)
r.squaredGLMM(mixed_model_IntSlope)
```

We see that $R_c^2$ is a lot larger than $R_m^2$ in both cases, meaning that most of the variance in our data is actually captured by our random effects (i.e., due to differences between beaches) -- good thing we included them! In general, $R_m^2$ of $\sim 10%$ is considered a good day in field ecology. Since NAP explained $\sim 30\%$ of the variance in species richness in both cases, we can conclude that the models are performing well!

Now that we have specified these models and see that they both perform reasonably well, how do we know which to choose? After all, they all provide slightly different estimates for the effects of NAP and P-values. 

Our model structure should be informed by our hypothesis of "reality", and this provides one way to choose between models. But in cases where we are unsure, or trying to compete different hypotheses (e.g., trying to figure out whether the species richness and NAP relationship differ by beach), then just knowing that both models fit well isn't good enough anymore --- we need a way to determine which model is a better fit to the data, controlling for the number of parameters fitted. We will come back to this question in the next lecture when discussing model selection.

## Deeply nested and crossed effects

Have a look back at the original diagram showing the layout of the RIKZ data and
the dataset itself. Every site within each beach is associated with only one
observation for each of the variables (e.g. species richness). As such, we used
mixed-effects modeling to account for the variance among these five observations
within each of the five beaches. But what about if each of those sites
additionally included multiple samples (e.g. measurements of morphological
traits of multiple individuals of a species), as in the diagram below?. We would
the need to account for the variance both within sites and within beaches.

![Diagrammatic representation of what the RIKZ data would look like if it were more deeply nested (i.e., if each site had multiple samples taken)](RIKZ_data_DeepNest.png)

Thankfully, `lmer` allows us to do this quite easily. To account for variation within sites _and_ within beaches, we would need to modify our existing random effect term. We would write this as `(1|Beach/Site)`, which means "Site nested within beach". This expands to — and can also be written as `(1|Beach) + (1|Beach:Site)`. Thus, we are modeling a separate intercept for every beach and for every site within every beach. 

It is worth emphasizing that the 'Site 1' from 'Beach 1' is **not** the same as 'Site 1' from 'Beach 2' and this was true of the original data as well. These sites are distinct; despite carrying the same label, they are occurring on distinct beaches and are thus not the same site. **This is what makes the data nested.**
 
An alternative design to this would be _crossed effects_, in which any site
could be observed on any beach (sometimes, this is called "multiple membership"). If all sites were observed on all beaches, this would be a **fully crossed effect** whereas if some sites were observed on only some beaches, this would be a **partially crossed effect**. If every site occurred on every beach, then we would code this as `(1|Beach) + (1|Site)`. Crossed effects are shown in the diagram below. This may sound confusing; the easiest way to think about it is that if the data are not nested, they are crossed. 

![Diagrammatic representation of what the RIKZ dataset would look like if it were fully crossed (i.e., if every site occurred on every beach)](RIKZ_data_Crossed.png)

### Example

We will illustrate deeply nested and crossed random effects in a single model using data from a greenhouse experiment conducted at UTM. The researchers were interested in understanding whether soil microbes collected within populations of invasive species can help a second generation of invasive plants perform better. This is called plant-soil feedbacks (PSF), in which plants influence the soil that they grow in, which in turn benefits future generations of the same species. The researchers were especially interested to see if PSF can occur even soils collected from the edge of the species' range, at which the invader is still in the process of spreading.

To do this, soil was collected from 14 sites in a subarctic region. These 14 sites were found in 3 main location: the town, the airport, and the regional studies centre, which was about 20 km away. At each site, soil was collected from within an existing population of invasive *Linaria vulgaris* (common toadflax) and about 2 meters away outside of the population. Then, soil was left live to preserve microbes, or sterilized. This produced four treatments:

1. Live invaded soil (microbes from invaded soils present)
2. Sterile invaded soil
3. Live uninvaded soil (microbes from uninvaded soils present)
4. Sterile uninvaded soil

The authors collected *L. vulgaris* seeds from two sources, germinated them and measured their initial height before transplant into soil treatments. In the greenhouse, *L. vulgaris* was randomly assigned to a soil treatment and individually planted, with soil coming from one of 14 sites, found in one of 3 locations. Plants were grown in soil treatments for 6 weeks, and harvested plant material at the end of the experiment to weigh, and biomass (g) was recorded for each plant ($n = 224$).

*Is this nested or crossed? Or both?* Soil was collected only from one site, and each site was only part of one location (sites nested within location). Given that sites could contain soil that is more similar to soil within a location (site effect), and the same is true for location (location effect), this non-independence needs to be accounted for. However, seeds from both seed sources (1 and 2) were planted in soils from all sites, and seeds from one source may be more similar to each other than seeds from the second source.

The code below provides a useful way of examining the data to assess whether terms are nested or crossed and then fits a mixed-effects model to the biomass data. Note that this data is currently in the process of manuscript submission - to protect privacy, some data have been redacted and modified[^soil].

The question we are interested in here is: 

_Does invasion status, sterilization, or the interaction influence growth of_ L. vulgaris _plants?_

Load in the data with this code:

```{r message = F}
biomass <- read_csv("biomass.csv", col_names = TRUE)
```

Let's quickly clean up and inspect this data.

```{r}
biomass <- biomass %>% 
  mutate(invaded_status = as.factor(invaded_status),
         sterile_status = as.factor(sterile_status),
         site_number = as.numeric(site_number)) %>% 
    filter(!is.na(biomass))

glimpse(biomass)
head(biomass)
```

Now let's have a look at how sites break down across the locations. We can do this using `dplyr` or cross-tabulation.

```{r}
biomass %>% 
  group_by(site_number, location) %>%
  tally() %>%
  spread(site_number, n)

# cross tabulation
xtabs(~ site_number + location, biomass)
```

As you can see above, each site occurs in only one location. This is an indication that the data are nested (i.e., site is nested within location). 

Now, let's look at how seeds from the two different sources were planted into soil from sites:

```{r}
biomass %>% 
  group_by(site_number, source) %>%
  tally() %>%
  spread(source, n)

xtabs(~ site_number + source, biomass)
```

In this case, we see that seeds from both sources occur on every site equally. In other words, seed source and site are fully crossed.

Remember also that we collected initial height data, as seeds will vary in their growth ability. Let's now look at variation in initial height across the sites.

```{r}
biomass %>% 
  group_by(site_number, location) %>%
  ggplot(aes(x = site_number, y = initial_height, colour = location)) +
  geom_point(position = "jitter") +
  stat_summary(fun = "mean", colour = "black") # add mean
```

Continuous variables should not be treated as a random effect. This is because it makes no sense to ask what the variance is across a continuous variable. Instead, what you are doing is forcing a continuous variable to be used as a categorical effect, and estimating a random intercept for each value of the continuous variable. So, if we were to make `initial_height` as a random effect, we would be estimating an intercept and/or slope for each level of `initial_height`, which is not informative. Continuous variables are often modeled as fixed effects if we believe they are important to the model due to the methods or data collection. In this case, initial heights of plants did vary, from 1.6 cm to 0.2 cm, so we are choosing to include it in our model.

Let's go ahead and fit our model. Note that this is a random intercept model, not a random slope-intercept model (i.e., the slope is the same throughout sites).

```{r model}
biomass_model <- lmer(biomass ~ invaded_status * sterile_status +
                        initial_height + # initial height as a fixed effect
                        (1|source) + # seed source fully crossed
                        (1|location/site_number), # site nested within location
                      data = biomass)
summary(biomass_model)
```

Notice we are now estimating 3 random-effect variance components. First, we are
estimating the variance among seed sources, which explains the most residual
variance among the random effects ($=0.0001893$). We also estimate the variance between locations ($=0.0001071$) and sites ($=0.0001069$). Note that our random effects explained very little of the residual variance; for example, seed source only explained 2.2% of the variance after accounting for fixed effects.

From the fixed effects, we see that the initial height of plants was a strong predictor of the final plant biomass. Additionally, the soil sterilization treatment (`sterile_status`) and the invasion history (`invasion_status`) had a significant effect on final biomass of the plant. In fact, the effect of invasion depended on the sterilization treatment (`invaded_status:sterile_status` interaction). While we will not go into the details of these results here[^PSF], this example serves to illustrate how nested and crossed random effects are encoded.

### Checking nested versus crossed data

You can use the `sjmisc` package to check whether groups are nested, fully crossed, or cross-classified (partially crossed). The recommendation is that you inspect your data first, and make sure you understand the nested and/or crossed design, and then check using the following functions:

```{r message = F, warning = F}
library(sjmisc)
```

```{r}
is_nested(biomass$site_number, biomass$location) # returns "TRUE" if nested

is_crossed(biomass$source, biomass$location) # returns "TRUE" if fully crossed

is_cross_classified(biomass$source, biomass$location) # returns "TRUE" if partially crossed
```

It is very important to understand the experimental, study, or survey design, because this and this alone determines the random effects that should be included.

## Additional readings

1. Zuur, A. *et al.* 2009. Mixed effects models and extensions in ecology with
R. *Springer*
2. Douglas Bates, Martin Mächler, Ben Bolker, and Steve Walker. 2015. [Fitting linear mixed-effects models using lme4](https://www.jstatsoft.org/article/view/v067i01).
*Journal of Statistical Software* 67: 1-48.
3. Fitzpatrick, C. R., Mustafa, Z., and Viliunas, J. Soil microbes alter plant
fitness under competition and drought. *Journal of Evolutionary Biology* 32:
438-450.
4. [This Stack Exchange post reagrding crossed vs. nested random effects](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)
5. [This blog post on the use of fixed vs. random effects](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)
6. [This article on the use of LMMs in quantitative genetics](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.1365-2656.2009.01639.x)

[^soil]: Vicki is happy to talk more about this research if you are interested!

[^PSF]: Plant-soil feedbacks can be complicated!