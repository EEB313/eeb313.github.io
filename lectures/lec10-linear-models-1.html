<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EEB313: Quantitative Methods in R for Biology - 10&nbsp; Linear models I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../lectures/lec11-linear-models-2.html" rel="next">
<link href="../lectures/lec09-intro-inference-2.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../lectures/lec01-r_and_rstudio.html">Lectures</a></li><li class="breadcrumb-item"><a href="../lectures/lec10-linear-models-1.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear models I</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">EEB313: Quantitative Methods in R for Biology</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/EEB313/eeb313.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about-us.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2024 teaching team</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../downloadingR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Installing R &amp; Ubuntu</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec01-r_and_rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to the course</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec02-basic-r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to R: assignment, vectors, functions, strings, loops</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec03-command_git.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Command line &amp; Git(Hub)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec04-data-wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data wrangling!</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec05-data-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data visualization with ggplot2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec06-exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Exploratory data analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec07-self-directed-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Review using Farrell and Davies (2019) dataset</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec08-intro-inference-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to inference I</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec09-intro-inference-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to inference II</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec10-linear-models-1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear models I</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lec11-linear-models-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Linear models II

## Lesson preamble

&gt; ### Learning objectives
&gt;
&gt; - Learn how dependent data can be modeled, and the sitations in which one may encounter such data.
&gt; - Understand the structure, assumptions, and implementation of GLMs.
&gt; - Understand the structure, assumptions, and implementation of LLMs.
&gt; - Learn how to use simulation to inform what data that should be collected, and how.
&gt; 
&gt; ### Lesson outline
&gt; -   Generalized linear models
&gt;     - Structure and assumptions, including interpretation of the effects
&gt;     - Implement logistic regression using dataset of Farrell and Davies (2019)
&gt;     - Other types of GLMs (Poisson, negative binomial, etc.)
&gt; -   Power analysis!
&gt; -   Dealing with dependent data
&gt;     - Splitting the data into groups...
&gt;     - Controlling for phylogeny
&gt;     - Linear mixed models: structure and assumptions
&gt;       - Difference between fixed, random effects; examples
&gt;       - Implement mixed models using sexual size dimorphism data

```{r, message=F, warning=F}
library(tidyverse)
library(broom)
library(lme4)
```

## Generalized linear models: theory and examples

So far we have seen how linear models can be used to describe relationships between a response variable and predictors when the data is normally distributed or can be transformed so that this assumption is not violated. What if we were, say, interested in a *binary* response (e.g., infection status of a host with a particular parasite) and how it changes with a continuous predictor (e.g., age of the host)? In this case, one can use a special kind of linear model called *logistic regression* to estimate the additive effect of predictor(s) on the binary response. Logistic regression is a special kind of **generalized linear model**.

### GLMs: structure and assumptions

Generalized linear models describe how the mean of a response variable changes as a function of the predictors when important assumptions of the linear modeling framework (normality, constant error variance, etc.) are violated. In particular, **GLMs allow us to work with data that are not normal, whose range is restricted, or whose variance depends on the mean.** The latter might be important if, say, larger values of the response were also more variable.

A GLM models the transformed mean of a response variable $Y_i$ as a linear combination of the predictors $x_1,\dots,x_p$. The goal of using a GLM is often to estimate how the predictors (e.g., sex and previous exposure to the disease) affect the response (e.g., infection status). sThe transformation of the response is done using a "link" function $g(\cdot)$ that is specific to the distribution which used to model the data. Written out, a GLM is of the form

$$g(\mu_i) = \beta_0 + \beta_1 x_{1i} + \cdots \beta_p x_{pi}.$$

The link functions for the Normal, Gamma, Exponential, Poisson, and Multinomial distributions are known. In general, GLMs apply when the data are modeled using a member of the [exponential family](https://en.wikipedia.org/wiki/Exponential_family). The distributions will have a mean parameter $\mu$ and, sometimes, a parameter $\tau$ which characterizes the dispersion around the mean. _GLMs are fitted using by maximizing the likelihood function that results from assuming the data arise from a distribution in the exponential family (with a mean and dispersion that depend on the predictors), using using numerical optimization methods._

### Interpretation of the effects

Notice that, in a GLM, because the mean of the response been transformed in a particular way, the coefficients must be interpreted carefully. In particular, $\beta_{j}$ is how a per-unit change in $x_{j}$ increases or decreases the _transformed_ mean $g(\mu_i)$.

### Example: logistic regression

In a previous class, we estimated the probability of death given infection for the wild boar when infected with viruses in the family _Coronaviridae_. In your current homework, you have been tasked with extending that model to all host and parasite family combinations. Excitingly, the dataset which have used includes information about the mean evolutionary isolation of all hosts that are infected with a parasite from all other hosts which are known to be infected.

Farrell and Davies tested if the mean evolutionary isolation affected the probability of death. They used a complex model to control for sampling bias and other confounding aspects of the data. We will ignore those complexities and see if, using a GLM, we can recapitulate their findings. To get started, load the `disease_distance.csv` dataset.

```{r}
disease_distance &lt;- read_csv("data/disease_distance.csv")

disease_distance %&gt;% 
  mutate(AnyDeaths = case_when(Deaths &gt; 0 ~ 1,
                               Deaths == 0 ~ 0)) -&gt; DataBern

DataBern |&gt;
  ggplot(aes(x = EvoIso, y = AnyDeaths)) + 
  geom_point()
```

These are binary data. We CANNOT use a linear model, as this assumes the data are Normal. In fact, these data are distributed according to a Bernoulli($p$) distribution. This is a member of the exponential family and the type of generalized linear model when the data are distributed in this way (i.e., are binary) is called **logistic regression**.

The mean of Bernoulli($p$) data is just $p$, and the link function for $p$ is

$$ \text{logit}(p) = \log\frac{p}{1-p}.$$

$\text{logit}(p)$ is called the *log-odds*, which can be thought of as a likelihood the response takes on the value one. In logistic regression, the log-odds ratio is modeled as a linear combination in the predictors:

$$ \text{logit}(p_i) =  \beta_0 + \beta_1 x_{1i} + \cdots + \beta_p x_{pi}.$$

Notice that increasing $x_j$ by one unit results in change $\beta_j$ to the link-transformed response.This is how the effect sizes are interpreted for GLMs such as this one.


```{r}
model &lt;- glm(AnyDeaths ~ EvoIso, 
             family = "binomial", 
             data = DataBern)
summary(model)
```

#### Challenge

How do we interpret the regression coefficient above?

#### Challenge

What are the log-odds of death if the evolutionary isolation of hosts is $EI = 200$? How much does this quantity change if the evolutionary isolation were to increase by 20 million years?

#### Visualizing the fitted model

```{r}
DataBern |&gt;
  ggplot(aes(x = EvoIso, y = AnyDeaths)) + 
  geom_point() +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial")
              )

### base R implementation

EvoIso &lt;- seq(0, 200, 0.1)
predicted_prob &lt;- predict(model, list(EvoIso = EvoIso), type = "response")

plot(DataBern$EvoIso, DataBern$AnyDeaths)
lines(EvoIso, predicted_prob)
```

### Other GLMs

Here are some common types of response variables and their corresponding distributions:

-   **Count data**: the **Poisson** distribution
-   **Over-dispersed count data** (when the count data is more spread out than "expected"): the **negative binomial** distribution
-   **Binary data** (two discrete categories): the **binomial** distribution
-   Counts of occurrences of $K$ different types: the **multinomial** distribution
-   **Times** between $r$ events: the **gamma** distribution, which is equivilent to the exponential when $r=1$

You will have the opportunity to implement such models in your homework and on the challenge assignment!

## Power analysis

When designing experiments or how best to collect data, it is best to think about the model you will fit and the kind of experiment you need to design in order to have sufficient power to detect an effect of interest. For example, if we thought that age affected the likelihood that a host dies of a disease, then we would likely fit a logistic regression-type model. By _simulating_ data from such a model, we can determine

- the minimum sample size required to reliably estimate an effect of a certain size
- the minimum sample size required to detect an effect of a certain size at a fixed significance level
- the minimum effect size that can be detected at a fixed significance level and sample size

### Example

Below is an example of a simulation in which binary disease data (death/no death; 0/1) are simulated hosts of various ages, assuming the the log-odds of disease is a linear function of age. (Notice that we assume that host lifetimes are exponentially distributed with rate parameter $\lambda = 1/10$ years. This means that hosts, in this simulation, live for an average of 10 years.) We then fit a logistic regression to this data to determine the effect of age on disease risk.

```{r}
data_generator &lt;- function(sample_size = 100, effect = 0.1){
  age &lt;- rexp(n = sample_size, rate = 1/10)
  linear_predictor &lt;- effect*age
  prob &lt;- 1/(1+exp(-linear_predictor))
  
  disease_status &lt;- c()
  
  for (i in 1:length(prob)){
  disease_status[i] &lt;- rbinom(n = 1, size = 1, prob = prob[i])
  }
  
  return(data.frame(age = age, disease_status = disease_status))
}

data &lt;- data_generator()

data %&gt;% pivot_longer(! age) %&gt;% 
  ggplot(aes(x = age, y = value)) + geom_point() + 
  geom_smooth(method = "glm", method.args = list(family = "binomial")
              ) + labs(y = "prob. of disease (i.e., disease status =1)")

model &lt;- glm(disease_status~scale(age), family = binomial, data = data)
summary(model)
```

Next, we will write a function that performs a **power analysis**. We will use this function determine the sample size that is required so that simulating the age-disease data repeatedly we identify a significant effect of age on disease status (i.e., reject the null hypothesis) at level $\alpha = 0.01$ *at least $95\%$ of the time*.

```{r}
power_analysis_function &lt;- function(sample_size){
  
  sims &lt;- 1000
  pvalues &lt;- c()
  for (i in 1:sims){
  data &lt;- data_generator(sample_size)
  model &lt;- glm(disease_status~scale(age), family = binomial, data = data)
  pvalues[i] &lt;- summary(model)$coefficients[2,4]
  }
  
  power_estimate &lt;- length(which(pvalues &lt; 0.01))/length(pvalues)
  
  return(power_estimate)
}

sample_sizes &lt;- seq(150,200,10); power_estimates &lt;- c()

for (i in 1:length(sample_sizes)){
  power_estimates[i] &lt;- power_analysis_function(sample_size = sample_sizes[i])
}

knitr::kable(cbind(n = sample_sizes, power = power_estimates))
```

## Dealing with dependent data!

To illustrate how mixed models work and what kinds of questions we can answer using them, we will use the sexual size dimorphism data which we analyzed last class. Recall that we did NOT find a significant effect of sex on the average body size. There was no effect of the interaction between Order and sex on body size. Indeed, this matches what you saw in the homework questions where you had to visualize the data --- most of the variation in body size was _between_ orders.

In the models we built, we ignored a pretty important fact about the data: species have a common history (i.e., phylogeny). Thus, observations are not independent! This can make drawing inferences from comparative data difficult. **We will address how to deal with the non-independence of data (due to a common history of species, replication in blocks, etc.) using three approaches.**

But, first, let's download the data we will use in this section!

```{r}
SSDdata &lt;- read_csv("data/SSDinMammals.csv")
```

```{r}
mammal_length &lt;- SSDdata %&gt;%
  select(c("Order", "Scientific_Name", "lengthM", "lengthF")) %&gt;%
  pivot_longer(c(lengthM, lengthF), names_to = "sex", values_to = "length",
               names_pattern = "length(.)")

mammal_mass &lt;- SSDdata %&gt;%
  select(c("Order", "Scientific_Name", "massM", "massF")) %&gt;%
  pivot_longer(c(massM, massF), names_to = "sex", values_to = "mass",
               names_pattern = "mass(.)")

mass_nodup &lt;- mammal_mass %&gt;% 
  group_by(Scientific_Name, sex) %&gt;%
  distinct(Scientific_Name, sex, .keep_all = TRUE)

length_nodup &lt;- mammal_length %&gt;% 
  group_by(Scientific_Name, sex) %&gt;%
  distinct(Scientific_Name, sex, .keep_all = TRUE)

mammal_long &lt;- full_join(mass_nodup, length_nodup, 
                         by = join_by("Scientific_Name", "sex", "Order")) |&gt;
  drop_na()

glimpse(mammal_long)
```

### Group-by-group analyses

**One first way we can handle dependent data is to split observations into groups such that, within each group, observations are independent (or approximately so).** This is what we did last class when we fit order-specific regression coefficients of sex on body size. We saw that ALL order-specific effects had confidence intervals which overlapped zero!

```{r, warning=F, message=F}
# run linear model of size on sex for EACH Order

Order_specific_models &lt;- 
  mammal_long |&gt; 
  group_by(Order) |&gt;
  do(model = tidy(lm(log(mass) ~ sex, data = .), conf.int = T))
  
# get coefficients for each Order

Order_specific_models |&gt;
  unnest() |&gt;
  select(Order, estimate)

# visualize effects, CIs, and p values

Order_specific_models |&gt;
  unnest() |&gt;
  subset(term == "sexM") |&gt;
  group_by(Order) |&gt;
  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2)
```

No effect of sex on body size, for any of the orders!

#### Challenge

How would you adjust the previous plot to show the estimated intercepts AND the effects of sex?

```{r}
Order_specific_models |&gt;
  unnest() |&gt;
  # subset(term == "sexM") |&gt;
  group_by(Order) |&gt;
  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high,
             color = term
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2)
```

#### Challenge

How would you retrieve model fits for each Order in base R?

```{r, include=F}
for (i in 1:nrow(Order_specific_models)){
  print(summary(Order_specific_models$mod[[i]]))
}
```

#### Challenge

Adjust the plot above so that it the size of the estimates depend on the number of observations in an Order? _Hint: determine the number of observations per Order and then use the `merge()` function with the `Order_specific_models` tibble. To adjust the range of point sizes, use `scale_size()`._

```{r, include=F}
mammal_long |&gt; 
  group_by(Order) |&gt;
  summarise(number_obs = n()) |&gt;
  merge(Order_specific_models) |&gt;
  unnest() |&gt;
  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high,
             color = term,
             size = number_obs
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2) +
  scale_size(range = c(0, 2))
```

#### Pros and cons

There are several advantages to preforming a group-by-group analysis:

- **Fitting more complex models (e.g., those with random effects) can be difficult.** There may be convergence issues, and interpretation of effects and $p$-values can be tricky.
- The group-by-group analysis is **robust in the face of unbalanced data** (i.e., when there are more observations for some groups than others).
- **The conclusions from a group-by-group analysis are _conservative_.**
- The group-by-group analysis is **fairly easy to implement**.

Among the disparages to this approach are the following:

- With fewer samples per group, the analysis **may be under-powered**.
- Splitting the data into groups means there are more coefficients to estimate, and thus confidence intervals to be estimated and hypothesis tests to be performed. This means there is a greater chance that we obtain a **spurious association**.*
- It is **difficult to draw conclusions about the variance between groups.** In some applications, this is of interest. In others, it is not.

*One solution is to adjust the significant level based on the number of tests conducted. If $k$ hypotheses are tested, an [common adjustment](https://en.wikipedia.org/wiki/Bonferroni_correction) is to set $\alpha = 0.05/k$.

### Controlling for phylogeny

A common reason data are dependent in biology is that **species share a common history of descent with modification.** When we assume that the observations are independent, we make implicit assumptions about the degree to which the characters at the tips of a phylogeny have underwent independent evolution. Sometimes, when species are diverged by many millions of years and traits evolve quickly, it is reasonable to ignore the phylogenetic constraints on the data. In other cases, it is essential to consider the role of phylogeny.

Several methods can control for phylogeny (if known). In fact, such methods can _use_ information in the branching pattern of species to draw inferences about the evolution of ecologically-important traits (such as body and brain size, dispersal rate, etc.). We will not discuss how to implement phylogenetic comparative methods, but it is good to know they exist and how, at a surface level, they work.

Intuition for how PCMs work is easiest to grasp when we consider a tree with $n$ species at the tips. If we know the pairwise divergence times for all species, then we can _transform_ the data so that observations are independent by looking at all _differences_ of traits. Not all differences are equally informative; if species have diverged a long time ago, there has been more time for differences to build up. PCMs account for this by specifying how the distribution of trait differences between species $i$ and $j$ depends on the time that has elapsed since these species diverged, In particular, the larger the divergence time, the greater the variance in $Y_i-Y_j$, the difference in trait values between species $i$ and $j$. A simple way to do this is to write $\sigma_{ij} = \sigma^2/T_{ij}$.^[Note: this gives rise to a likelihood function that is functionally VERY similar to the one for the linear model with constant error variance.]

### Random effects!

Another way one can account for dependent data is by including _random effects_. Random effects are often used to control for the fact that observations are clustered (e.g., trait data for species belonging to a higher taxonomic unit, measurements of plant biomass from plots of land).

#### Structure and assumptions

A common way models with random effects are formulated is as follows:

$$Y_{ij} \sim \text{Normal}(\beta_0 + \beta_1 x_{1ij} + \cdots + \beta_{p} x_{pij} + b_{0i} + b_{1i} z_{1ij} + \cdots + b_{qi} z_{qij}, \sigma_{ij}^2),$$

where $ij$ is the $i$th observation from the $j$th cluster and

$$b_{ki} \sim \text{Normal}(0,\tau_k^2).$$

This gives rise to a distribution for $Y$ which depends on the values of the random effects $b_0,\dots,b_q$. Under the hood, methods that fit models of this form numerically maximize a version of the likelihood function that results from these assumptions.

#### Challenge

In each of the following examples, which effects might be reasonably treated as fixed vs. random? Justify your answer.

1. Suppose we are working with rodents that have been infected with an evolved strain of the parasite that causes malaria. Some rodents have been treated with a prospective vaccine and others sham-vaccinated. We are interested if a proxy for virulence (e.g., density of infected red blood cells) depends on vaccination status.

2. Suppose we conduct the same experiment, except rodents are caged are sets of four.

3. Suppose we measure the time between sightings of a raccoon in a Toronto neighborhood using six camera traps (strategically placed in the neighborhood). We do this for year, and want to ask if mean daily temperature predicts the frequency of raccoon occurrence.

4. Suppose that, every year, we go to the Amazon and measure the number of bird calls that come from $n=30$ trees. Assume that the trees are far enough apart we can treat them as independent. We measure the number of birds in a tree, characteristics of the tree (cover, height, width, age), the year in which a measurement was done, and the mean temperature that year. We want to know if tree cover affects the frequency of bird calls, and if it interacts with temperature.

For more on the difference between fixed and random effects, check out the following resources

- [this Cross Validated post](https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-in-mixed-effect-model)
- [this Dynamic Ecology post](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)
- [this book chapter](https://bookdown.org/steve_midway/DAR/random-effects.html)

#### Using `lme4` to fit random and mixed effect models

We will start by fitting a model of log body size on log length where the intercept is random depending on the Order. Based on a quick visualization of the data, such a model may be appropriate.

```{r}
ggplot(data = mammal_long, aes(y = log(mass), 
                               x = log(length)
                               )
       ) + 
    geom_point(aes(color = Order), size = 3) -&gt; p

p 
```

```{r, include=F}
# no Order-dependence:
p + geom_smooth(method = "lm")

# intercept AND slope fixed and specific to the Order:
p + geom_smooth(method = "lm") + facet_wrap(~Order) 
```

To fit regress the response on a set of fixed effects with random _intercepts_ that depends the values assumed by a random effect `x`, we call `lmer` and write a linear model with `(1|x)`.

```{r}
## random intercept for Order

model &lt;- lmer(formula = log(mass) ~ log(length) + (1|Order), data = mammal_long)
summary(model)

fixef(model)
ranef(model)
```

From top to bottom, the output is telling us that the model was fit using a method called REML (restricted maximum likelihood). It returns information about the residuals, random effects, and fixed effects. The output also tells us about the **estimated variance for the random effects** in the model. Here, the variance associated with Order is 4.256. The variance explained by Order is 4.256/(4.256+0.847) _after controlling for the fixed effects_. Note the denominator here is the total variance, including from the residuals. As usual, we also have information about the fixed effects.

To visualize the model, we can predict the overall and Order-specific relationship of log mass on log length for all of the Orders represented in the data.

```{r}
mammal_long |&gt; ungroup() |&gt; select(mass, length, Order) |&gt; 
  mutate(fit.m = predict(model, re.form = NA), # does not include random effects
         fit.c = predict(model, re.form = NULL) # includes random effects
         ) -&gt;
  predicted_values

predicted_values |&gt;
  ggplot(aes(x = log(length), y = log(mass), color = Order)) +
  geom_point(size = 3) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = "black", size = 2)
```

The thick black line corresponds to the fitted values associated with the fixed-effect component of the model. The colored lines correspond to the fitted values estimated for each Order. 

Perhaps a model with Order-specific random intercepts AND slopes would be better. We fit this model using the code below. The key difference in syntax is that we write `(1+fixed effect|random effect)` to indicate that the random effect has an effect on both the intercept _and_ slope of the response on the fixed effect.

```{r}
## random intercept and slope for Order

model2 &lt;- lmer(formula = log(mass) ~ log(length) + (1+log(length)|Order), data = mammal_long)
summary(model2)

fixef(model2)
ranef(model2)
```

```{r}
mammal_long |&gt; ungroup() |&gt; select(mass, length, Order) |&gt; 
  mutate(fit.m = predict(model2, re.form = NA),
         fit.c = predict(model2, re.form = NULL)
         ) -&gt;
  predicted_values

predicted_values |&gt;
  ggplot(aes(x = log(length), y = log(mass), color = Order)) +
  geom_point(size = 3) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = "black", size = 2)
```

Why does this look like a mess? As stated above, **mixed models do not work well when datasets are unbalanced.** Indeed, the number of observations in the different Orders are quite variable.

#### Challenge

Regress log body size on sex with Order as a random effect that affects the intercept AND slope of the sex-size relationship.

```{r, include=F}
Model &lt;- lmer(log(mass) ~ sex + (1+sex|Order), mammal_long)

mammal_long |&gt; ungroup() |&gt; select(Scientific_Name, mass, sex, Order) |&gt; 
  mutate(fit.m = predict(Model, re.form = NA),
         fit.c = predict(Model, re.form = NULL)
         ) -&gt;
  predicted_values

predicted_values |&gt;
  ggplot(aes(x = sex, y = log(mass))) +
  geom_line(aes(group = Scientific_Name), color = "lightgrey") +
  geom_point(color = "lightgrey", size = 2) +
  geom_point(inherit.aes = F, aes(x = sex, y = fit.c, color = Order), size = 3) +
  geom_line(inherit.aes = F, aes(x = sex, y = fit.c, color = Order, group = Order), size = 2) +
  geom_point(inherit.aes = F, aes(x = sex, y = fit.m), color = "black", size = 3) +
  geom_line(inherit.aes = F, aes(x = sex, y = fit.m, group = ""), color = "black", size = 3) +
  theme_classic()
```</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignment-00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment00: individual interest description</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignment-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 01: base R, command line, &amp; Git(Hub)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignment-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 02: data wrangling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignment-03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 03: data visualisation and exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignment-04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 04: inference!</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project description</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projects_databases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Some open-access databases</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Datasets</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/portal_data.csv" class="sidebar-item-text sidebar-link">
 <span class="menu-text">portal_data.csv</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/pseudo.ara.busco" class="sidebar-item-text sidebar-link">
 <span class="menu-text">pseudo.ara.busco</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/pseudo.LTRs" class="sidebar-item-text sidebar-link">
 <span class="menu-text">pseudo.LTRs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/disease_distance.csv" class="sidebar-item-text sidebar-link">
 <span class="menu-text">disease_distance.csv</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/SSDinMammals.csv" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SSDinMammals.csv</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/data/meas.csv" class="sidebar-item-text sidebar-link">
 <span class="menu-text">meas.csv</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Miscellaneous notes</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lesson-preamble" id="toc-lesson-preamble" class="nav-link active" data-scroll-target="#lesson-preamble"><span class="header-section-number">10.1</span> Lesson preamble:</a></li>
  <li><a href="#linear-models-why-we-care" id="toc-linear-models-why-we-care" class="nav-link" data-scroll-target="#linear-models-why-we-care"><span class="header-section-number">10.2</span> Linear models: why we care</a></li>
  <li><a href="#the-simple-linear-model" id="toc-the-simple-linear-model" class="nav-link" data-scroll-target="#the-simple-linear-model"><span class="header-section-number">10.3</span> The simple linear model</a>
  <ul class="collapse">
  <li><a href="#challenge" id="toc-challenge" class="nav-link" data-scroll-target="#challenge"><span class="header-section-number">10.3.1</span> Challenge</a></li>
  <li><a href="#challenge-1" id="toc-challenge-1" class="nav-link" data-scroll-target="#challenge-1"><span class="header-section-number">10.3.2</span> Challenge</a></li>
  <li><a href="#challenge-2" id="toc-challenge-2" class="nav-link" data-scroll-target="#challenge-2"><span class="header-section-number">10.3.3</span> Challenge</a></li>
  </ul></li>
  <li><a href="#multiple-regression" id="toc-multiple-regression" class="nav-link" data-scroll-target="#multiple-regression"><span class="header-section-number">10.4</span> Multiple regression</a>
  <ul class="collapse">
  <li><a href="#interpreting-the-regression-coefficients" id="toc-interpreting-the-regression-coefficients" class="nav-link" data-scroll-target="#interpreting-the-regression-coefficients"><span class="header-section-number">10.4.1</span> Interpreting the regression coefficients</a></li>
  <li><a href="#transformations" id="toc-transformations" class="nav-link" data-scroll-target="#transformations"><span class="header-section-number">10.4.2</span> Transformations</a></li>
  <li><a href="#categorical-predictors" id="toc-categorical-predictors" class="nav-link" data-scroll-target="#categorical-predictors"><span class="header-section-number">10.4.3</span> Categorical predictors</a></li>
  <li><a href="#interactions-higher-order-terms" id="toc-interactions-higher-order-terms" class="nav-link" data-scroll-target="#interactions-higher-order-terms"><span class="header-section-number">10.4.4</span> Interactions, higher order terms</a></li>
  </ul></li>
  <li><a href="#using-lm-to-fit-a-multivariate-regression-model" id="toc-using-lm-to-fit-a-multivariate-regression-model" class="nav-link" data-scroll-target="#using-lm-to-fit-a-multivariate-regression-model"><span class="header-section-number">10.5</span> Using <code>lm</code> to fit a multivariate regression model</a></li>
  <li><a href="#checking-assumptions-of-the-model-are-satified" id="toc-checking-assumptions-of-the-model-are-satified" class="nav-link" data-scroll-target="#checking-assumptions-of-the-model-are-satified"><span class="header-section-number">10.6</span> Checking assumptions of the model are satified</a></li>
  <li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example"><span class="header-section-number">10.7</span> An example!</a>
  <ul class="collapse">
  <li><a href="#in-mammals-is-there-an-effect-of-sex-on-body-size" id="toc-in-mammals-is-there-an-effect-of-sex-on-body-size" class="nav-link" data-scroll-target="#in-mammals-is-there-an-effect-of-sex-on-body-size"><span class="header-section-number">10.7.1</span> In mammals, is there an effect of sex on body size?</a></li>
  <li><a href="#adding-interactions" id="toc-adding-interactions" class="nav-link" data-scroll-target="#adding-interactions"><span class="header-section-number">10.7.2</span> Adding interactions…</a></li>
  <li><a href="#challenge-5" id="toc-challenge-5" class="nav-link" data-scroll-target="#challenge-5"><span class="header-section-number">10.7.3</span> Challenge</a></li>
  <li><a href="#visualizing-fitted-models" id="toc-visualizing-fitted-models" class="nav-link" data-scroll-target="#visualizing-fitted-models"><span class="header-section-number">10.7.4</span> Visualizing fitted models</a></li>
  <li><a href="#challenge-6" id="toc-challenge-6" class="nav-link" data-scroll-target="#challenge-6"><span class="header-section-number">10.7.5</span> Challenge</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../lectures/lec01-r_and_rstudio.html">Lectures</a></li><li class="breadcrumb-item"><a href="../lectures/lec10-linear-models-1.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear models I</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear models I</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="lesson-preamble" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="lesson-preamble"><span class="header-section-number">10.1</span> Lesson preamble:</h2>
<blockquote class="blockquote">
<h3 id="lesson-objectives" data-number="10.1.1" class="anchored"><span class="header-section-number">10.1.1</span> Lesson objectives</h3>
<ul>
<li>Understand the logic of the general linear model, including the assumptions that are placed on the data, parameters, and errors.</li>
<li>Understand the meaning of regression coefficients and how they are estimated.</li>
<li>Understand how to implement linear models in R.</li>
<li>Learn how to respond when data violate assumptions, visualize fitted models, etc.</li>
</ul>
<h3 id="lesson-outline" data-number="10.1.2" class="anchored"><span class="header-section-number">10.1.2</span> Lesson outline</h3>
<ul>
<li>Theory
<ul>
<li>Structure and assumptions, including interpretation of the effects</li>
<li>Likelihood-based estimation and inference</li>
<li>Transformations of the response, dummy variables, and interactions between covariates</li>
</ul></li>
<li>Practice
<ul>
<li>Implement multivariate linear model using sexual size dimorphism dataset</li>
<li>Develop intuition for model diagnostics</li>
<li>Visualizing fitted models</li>
</ul></li>
</ul>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>SSDdata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/SSDinMammals.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 691 Columns: 18
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (6): Order, Family, Species, Scientific_Name, Comments, Source
dbl (12): massM, SDmassM, massF, SDmassF, lengthM, SDlengthM, lengthF, SDlen...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
</div>
</section>
<section id="linear-models-why-we-care" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="linear-models-why-we-care"><span class="header-section-number">10.2</span> Linear models: why we care</h2>
<p>Linear models are at the heart of statistical practice in the physical, life, and social sciences! Linear regression actually refers to a <em>family</em> of modeling approaches that attempt to learn how the mean and/or variance of a response variable <span class="math inline">\(\boldsymbol{y} = (y_1,\dots,y_n)\)</span> depend on (linear) combinations of variables <span class="math inline">\(\boldsymbol{x}_i = (x_{i1},\dots,x_{in})\)</span> called predictors. In this lecture, we will discuss various forms of the linear model and assumptions placed on the data to make estimation and inference of the relationships between variables tractable. Our goal will be to become familiar with how these models work – namely, how their parameters are inferred using maximum likelihood — and practice fitting them in R.</p>
</section>
<section id="the-simple-linear-model" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="the-simple-linear-model"><span class="header-section-number">10.3</span> The simple linear model</h2>
<p>The simple linear models describes how a response <span class="math inline">\(Y\)</span> depends on a contentious explanatory variable, <span class="math inline">\(x\)</span>, which is fixed. The model is</p>
<p><span class="math display">\[Y \sim \text{Normal}(\beta_0 + \beta_1 x, \sigma^2).\]</span></p>
<p>In turn, this specifies what the likelihood function have data <span class="math inline">\((y_1,x_1),\dots,(y_n,x_n)\)</span>. (As usual, we assume the <span class="math inline">\(y\)</span>s are independent.)</p>
<p>Below is a <em>visual</em> representation of how the data generative process for <span class="math inline">\(Y\)</span> is modeled. At each <span class="math inline">\(x\)</span>, <span class="math inline">\(Y\)</span> is Normal with a mean that depends on the explanatory variable and fixed variance (i.e., changing <span class="math inline">\(x\)</span> does not change the variance in the observed response).</p>
<p><img src="figures/regression.jpg" class="img-fluid"></p>
<section id="challenge" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="challenge"><span class="header-section-number">10.3.1</span> Challenge</h3>
<p>Form the likelihood <span class="math inline">\(L(\beta_0,\beta_1,\sigma^2|\boldsymbol{x}_i,\boldsymbol{y}_i)\)</span>. Recall that the probability distribution of the <span class="math inline">\(Normal(\mu,\sigma^2)\)</span> distribution is</p>
<p><span class="math display">\[\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-(y-\mu)^2/2\sigma^2}.\]</span></p>
<p><em>Hint: notice how, in the regression model, the mean value of the response is <span class="math inline">\(\beta_0 + \beta_1 x.\)</span></em></p>
</section>
<section id="challenge-1" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="challenge-1"><span class="header-section-number">10.3.2</span> Challenge</h3>
<p>What assumptions are we making about the data when we fit simple linear model? What must be true of the data? Discuss.</p>
</section>
<section id="challenge-2" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="challenge-2"><span class="header-section-number">10.3.3</span> Challenge</h3>
<p>Suppose we think <span class="math inline">\(Y\)</span> is not normally distributed (and constant variance <span class="math inline">\(\sigma^2\)</span>), but that it’s logarithm (or, say, square root) is. How might we adjust the model to account for this?</p>
</section>
</section>
<section id="multiple-regression" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="multiple-regression"><span class="header-section-number">10.4</span> Multiple regression</h2>
<p>It is straightforward to extend the simple regression model to include multiple covariates/predictors. Suppose, for each realization of <span class="math inline">\(Y\)</span>, we have associated measurements <span class="math inline">\(x_1,\dots,x_p\)</span>. We can model how <span class="math inline">\(Y\)</span> changes with these predictors as follows:</p>
<p><span class="math display">\[Y \sim \text{Normal}(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p, \sigma^2).\]</span> The likelihood that arises from data <span class="math inline">\((y_i,x_{1i},\dots,x_{pi})\)</span> where <span class="math inline">\(i=1,\dots,n\)</span> is</p>
<p><span class="math display">\[L(\beta_0,\dots,\beta_p,\sigma^2) = \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-(y_i-\beta_0-\beta_1 x_{1i}-\cdots-\beta_p x_{pi})^2/2\sigma^2}.\]</span></p>
<p>Again, assumptions of this model include</p>
<ol type="1">
<li>The data, i.e., observations of the response <span class="math inline">\(Y\)</span>, are independent and Normally distributed.</li>
<li>The <em>mean</em> response is a linear function of the predictors.</li>
<li>The error variance <span class="math inline">\(\sigma^2\)</span> is constant and, thus, does not depend on the predictors.</li>
<li>The parameters <span class="math inline">\(\beta_0,\dots,\beta_p\)</span> (called regression coefficients or effect sizes) are non-random.</li>
<li>The predictors are known with certainty.</li>
</ol>
<p>Maximum likelihood estimation gives rise to point and interval estimates for <span class="math inline">\(\beta_1,\dots,\beta_p,\sigma^2\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="interpreting-the-regression-coefficients" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="interpreting-the-regression-coefficients"><span class="header-section-number">10.4.1</span> Interpreting the regression coefficients</h3>
<p>We must be careful how we interpret the parameters of <em>any</em> statistic model after we fit the model to data. This is definitely true of the regression coefficients <span class="math inline">\(\beta_1,\dots,\beta_p\)</span>. The estimates are not the same as the “true” values the parameters assume; they are our best guess of the “true” regression coefficients, given the (limited, imperfect, incomplete, noisy) data that we have. Moreover, <span class="math inline">\(\beta_j\)</span> must be understood as the amount the average value of the response variable changes when the predictor <span class="math inline">\(x_j\)</span> increases by one unit, <em>assuming all else is constant</em>.</p>
<p>That is, <span class="math inline">\(\beta_j\)</span> is a measure of the sensitivity of <span class="math inline">\(E(Y)\)</span> to <span class="math inline">\(x_j\)</span> — how much does <span class="math inline">\(Y\)</span> change, on average, if we increase <span class="math inline">\(x_j\)</span> by one unit.</p>
</section>
<section id="transformations" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="transformations"><span class="header-section-number">10.4.2</span> Transformations</h3>
<p>If you suspect the raw data are not normally distributed, but transformed versions of the data are, you can replace <span class="math inline">\(Y\)</span> with <span class="math inline">\(f(Y)\)</span> where <span class="math inline">\(f(\cdot)\)</span> is the transformation and proceed with the analysis. The only thing to keep in mind is how to interpret the regression coefficients.</p>
<p>If <span class="math inline">\(\beta_1 = 0.1\)</span> when regression <span class="math inline">\(f(Y)\)</span> on <span class="math inline">\(x_1,\dots,x_p\)</span>, then that means _per unit change in <span class="math inline">\(x_1\)</span>, all else constant, <span class="math inline">\(f(Y)\)</span> increases, on average, by unit 0.1. This does NOT mean that <span class="math inline">\(Y\)</span>, on the raw scale, increases by that amount.</p>
</section>
<section id="categorical-predictors" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="categorical-predictors"><span class="header-section-number">10.4.3</span> Categorical predictors</h3>
<p>We can regress <span class="math inline">\(Y\)</span> on discrete, as well as continuous, predictor variables. To see how this is done, and how to interpret the resulting regression coefficients, suppose a predictor has <span class="math inline">\(K\)</span> levels. To estimate the effect of one of these levels on the response variable (say, of sampling individuals in a particular country), one of the levels of the discrete variable is treated as a “reference” and effects are estimated for all other levels. That is, we define the model in terms of a <em>baseline</em> and to interpret the regression coefficients <em>relative</em> to this baseline. This involves coding “dummy variables” for all but one the <span class="math inline">\(K\)</span> values the predictor can take assume and estimating regression coefficients for each of these variables.</p>
<p><strong>The regression coefficient for a “dummy variable” (associated to one of the values a categorical predictor) measures the expected change in the response, all else constant, if we were to change from the baseline to the level of interest.</strong></p>
</section>
<section id="interactions-higher-order-terms" class="level3" data-number="10.4.4">
<h3 data-number="10.4.4" class="anchored" data-anchor-id="interactions-higher-order-terms"><span class="header-section-number">10.4.4</span> Interactions, higher order terms</h3>
<p>Finally, linear models can accommodate non-linear interactions between explanatory variables. If <span class="math inline">\(x_2 = x_1^2\)</span>, one can estimate an effect for <span class="math inline">\(x_2\)</span> (and do the same for all higher order terms for <span class="math inline">\(x_1\)</span> and the other covariates). This effect sizes that are estimated have to be interpreted carefully but does not pose a difficulty to forming the likelihood nor maximizing it.</p>
<p>Other interactions can also be modeled. For example, suppose we were interested in the combined effects of changing salinity and temperature on the number of species in an ecosystem because we suspect that changing salinity has little effect on the effect on the number of species if temperature in high (e.g., there are no species left). Then, letting <span class="math inline">\(x_1\)</span> be salinity and <span class="math inline">\(x_2\)</span> temperature, their interaction would be included as a covariate <span class="math inline">\(x_3 = x_1 x_2\)</span> and the associated effect estimated from the data.</p>
<p><strong>When there are interactions, coefficients are interpreted as follows. We can say that <span class="math inline">\(\beta_1\)</span> is the expected change in the response if we increase <span class="math inline">\(x_1\)</span> by one unit and set all covariates with which it interacts equal to zero. The effect size for the interaction between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> measures the change in the the expected response if <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> were to BOTH increase by one unit that is on top of or <em>in addition to</em> the change due each variable in isolation.</strong></p>
</section>
</section>
<section id="using-lm-to-fit-a-multivariate-regression-model" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="using-lm-to-fit-a-multivariate-regression-model"><span class="header-section-number">10.5</span> Using <code>lm</code> to fit a multivariate regression model</h2>
<p>One can use the likelihood above to derive estimates of <span class="math inline">\(\beta_0,\dots,\beta_p,\sigma^2\)</span> and confidence intervals for those parameters. (In fact, one can use calculus to maximize the likelihood and derive expressions for the estimates which maximize the probability of the observed data.)</p>
<p><strong>Maximization of the likelihood, assuming the data are independent draws of a normal distribution with the mean and varience specified above, is <em>exactly</em> what happens when one fits a regression model in R using the function <code>lm()</code>.</strong></p>
<p>For example, using the sexual size dimorphism data set, one to estimate the effects of Order (a variable) on the logarithm mean male mass as follows.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(massM) <span class="sc">~</span> Order, <span class="at">data =</span> SSDdata)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(massM) ~ Order, data = SSDdata)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.9361 -0.8298 -0.1617  0.7102  6.4749 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)            3.3101     0.2800  11.823  &lt; 2e-16 ***
OrderArtiodactyla      7.5459     0.3584  21.054  &lt; 2e-16 ***
OrderCarnivora         5.1631     0.3530  14.627  &lt; 2e-16 ***
OrderChiroptera       -0.5865     0.2982  -1.967 0.049623 *  
OrderCingulata         4.7213     0.6625   7.127 2.65e-12 ***
OrderDasyuromorphia    2.8644     0.6625   4.324 1.77e-05 ***
OrderDidelphimorphia   1.2473     0.4052   3.078 0.002169 ** 
OrderDiprotodontia     4.4899     0.4105  10.938  &lt; 2e-16 ***
OrderEulipotyphla     -0.1853     0.3584  -0.517 0.605292    
OrderLagomorpha        3.3687     0.5086   6.624 7.15e-11 ***
OrderMacroscelidea     0.5654     0.6625   0.853 0.393752    
OrderPeramelemorphia   3.4938     0.7274   4.803 1.92e-06 ***
OrderPerissodactyla    9.1769     0.9898   9.271  &lt; 2e-16 ***
OrderPilosa            5.4604     0.6155   8.872  &lt; 2e-16 ***
OrderPrimates          4.1313     0.3152  13.108  &lt; 2e-16 ***
OrderRodentia          1.1136     0.2943   3.784 0.000168 ***
OrderScandentia        1.8380     0.8242   2.230 0.026065 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.343 on 674 degrees of freedom
Multiple R-squared:  0.7588,    Adjusted R-squared:  0.7531 
F-statistic: 132.5 on 16 and 674 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>After a call to <code>lm()</code>, R returns <em>a lot</em> of information. Here is what is in the table above:</p>
<ul>
<li><strong>Descriptive statistics for the “residuals”</strong> <span class="math inline">\(\varepsilon_i = y_i - \widehat{\beta_0} - \widehat{\beta_1} x_i\)</span>, which tell us about how much variability there is in the data relative to the linear model specified and fitted.</li>
<li>The <strong>regression coefficients minimizing the likelihood of the data and <span class="math inline">\(95\%\)</span> confidence intervals for each</strong>. The CIs are expressed as standard errors, since the estimators have an approximate Normal distribution. A <em>joint</em> confidence region for the coefficients can also be found using the LLR statistic which have been using to construct confidence intervals.</li>
<li>A <strong>suite of test statistics</strong>! The <span class="math inline">\(t\)</span> statistics and their <span class="math inline">\(p\)</span> values are associated to the test <span class="math inline">\(H_0: \beta_i = 0\)</span> vs <span class="math inline">\(H_1: \beta_i \neq 0\)</span>. Significance codes specify the level <span class="math inline">\(\alpha\)</span> at which we have evidence to reject the null hypothesis for each coefficient.</li>
<li>Measures of goodness-of-fit: <strong>the multiple <span class="math inline">\(R^2\)</span> and the adjusted <span class="math inline">\(R^2\)</span></strong>. These explain the <em>proportion of variance</em> that are explained by the model. The latter measures the proportion of variance explained by the linear model upon adjusting for sample size and <span class="math inline">\(\#\)</span> of predictors.</li>
</ul>
<section id="challenge-3" class="level4" data-number="10.5.0.1">
<h4 data-number="10.5.0.1" class="anchored" data-anchor-id="challenge-3"><span class="header-section-number">10.5.0.1</span> Challenge</h4>
<p>How would we interpret the coefficient associated to the Order Dasyuromorphia?</p>
</section>
<section id="challenge-4" class="level4" data-number="10.5.0.2">
<h4 data-number="10.5.0.2" class="anchored" data-anchor-id="challenge-4"><span class="header-section-number">10.5.0.2</span> Challenge</h4>
<p>Why did we log-transform the mean mass of males in the previous call to <code>lm()</code>? <em>Hint: think about the assumptions of the linear model.</em></p>
</section>
</section>
<section id="checking-assumptions-of-the-model-are-satified" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="checking-assumptions-of-the-model-are-satified"><span class="header-section-number">10.6</span> Checking assumptions of the model are satified</h2>
<p>One can do a quick check to see if the assumptions of the regression model — e.g., that the data are normal — by calling the function <code>plot()</code> on the model fitted using <code>lm</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model) <span class="co"># returns diagnostics (are the data normal, are there points with high leverage...)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/Diagnostics-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/Diagnostics-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/Diagnostics-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/Diagnostics-4.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>More on how to read diagnostic plots can be found <a href="https://ademos.people.uic.edu/Chapter12.html#3_regression_diagnostics">here</a>.</p>
</section>
<section id="an-example" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="an-example"><span class="header-section-number">10.7</span> An example!</h2>
<section id="in-mammals-is-there-an-effect-of-sex-on-body-size" class="level3" data-number="10.7.1">
<h3 data-number="10.7.1" class="anchored" data-anchor-id="in-mammals-is-there-an-effect-of-sex-on-body-size"><span class="header-section-number">10.7.1</span> In mammals, is there an effect of sex on body size?</h3>
<p>Recall how you cleaned the sexual size dimorphism dataset in the second homework. We will use the cleaned dataset to do a very crude test of the hypothesis that males and females differ in size. In particular, we will determine the <em>quantitative</em> effect of sex is on the size of a typical individual, regardless of their species, sampling effort, etc. Much more complicated models can be constructed, but it turns out <a href="https://www.nature.com/articles/s41467-024-45739-5">these models give rise to qualitatively-similar conclusions</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>mammal_length <span class="ot">&lt;-</span> SSDdata <span class="sc">%&gt;%</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">c</span>(<span class="st">"Order"</span>, <span class="st">"Scientific_Name"</span>, <span class="st">"lengthM"</span>, <span class="st">"lengthF"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">c</span>(lengthM, lengthF), <span class="at">names_to =</span> <span class="st">"sex"</span>, <span class="at">values_to =</span> <span class="st">"length"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_pattern =</span> <span class="st">"length(.)"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>mammal_mass <span class="ot">&lt;-</span> SSDdata <span class="sc">%&gt;%</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">c</span>(<span class="st">"Order"</span>, <span class="st">"Scientific_Name"</span>, <span class="st">"massM"</span>, <span class="st">"massF"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">c</span>(massM, massF), <span class="at">names_to =</span> <span class="st">"sex"</span>, <span class="at">values_to =</span> <span class="st">"mass"</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_pattern =</span> <span class="st">"mass(.)"</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>mass_nodup <span class="ot">&lt;-</span> mammal_mass <span class="sc">%&gt;%</span> </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Scientific_Name, sex) <span class="sc">%&gt;%</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(Scientific_Name, sex, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>length_nodup <span class="ot">&lt;-</span> mammal_length <span class="sc">%&gt;%</span> </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Scientific_Name, sex) <span class="sc">%&gt;%</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(Scientific_Name, sex, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>mammal_long <span class="ot">&lt;-</span> <span class="fu">full_join</span>(mass_nodup, length_nodup, </span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                         <span class="at">by =</span> <span class="fu">join_by</span>(<span class="st">"Scientific_Name"</span>, <span class="st">"sex"</span>, <span class="st">"Order"</span>))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(mammal_long)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,282
Columns: 5
Groups: Scientific_Name, sex [1,282]
$ Order           &lt;chr&gt; "Afrosoricida", "Afrosoricida", "Afrosoricida", "Afros…
$ Scientific_Name &lt;chr&gt; "Amblysomus hottentotus", "Amblysomus hottentotus", "E…
$ sex             &lt;chr&gt; "M", "F", "M", "F", "M", "F", "M", "F", "M", "F", "M",…
$ mass            &lt;dbl&gt; 80.6, 66.0, 28.0, 23.1, 102.4, 99.9, 7.3, 7.0, 111.0, …
$ length          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(mass) <span class="sc">~</span> sex, <span class="at">data =</span> mammal_long)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(mass) ~ sex, data = mammal_long)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.0267 -2.0625 -0.7779  1.8266 11.2988 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   5.0586     0.1048   48.25   &lt;2e-16 ***
sexM          0.0667     0.1483    0.45    0.653    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.655 on 1280 degrees of freedom
Multiple R-squared:  0.000158,  Adjusted R-squared:  -0.0006231 
F-statistic: 0.2023 on 1 and 1280 DF,  p-value: 0.6529</code></pre>
</div>
</div>
<p>Remarkably, no effect! Males are not larger than females. The <span class="math inline">\(p\)</span> value is not only <span class="math inline">\(&gt;\alpha = 0.05\)</span>, the size of the estimated effect is quite small. This is pretty suprising, given the large number of papers that <em>claim</em>, despite the lack of evidence, that there are stark differences in size between male and female individuals.</p>
</section>
<section id="adding-interactions" class="level3" data-number="10.7.2">
<h3 data-number="10.7.2" class="anchored" data-anchor-id="adding-interactions"><span class="header-section-number">10.7.2</span> Adding interactions…</h3>
<p>To include multiple variables in a regression, without their interaction, one writes <code>y ~ x + z</code>. To include their interaction, the syntax is <code>y ~ x*z</code>. (This is equivalent to <code>y ~ x + z + x:z</code> where the color indicates to fit an interaction-only model. <strong>In general, it is best to avoid fitting interaction-only models. As <a href="https://stats.stackexchange.com/questions/11009/including-the-interaction-but-not-the-main-effects-in-a-model">this</a> post explains, interactions can be due to dependence of the response on the covariates in the interaction, or non-linear functions of those covariates. Plus, interpreting the estimated coefficients is really difficult.</strong>)</p>
<p>How would you fit a model in which there is an effect of sex and, separately, effects of belonging to a given Order on mean body size? How would you fit a model where, in addition to these effects, an interaction between sex and Order?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>OrderSpecificModel <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(mass) <span class="sc">~</span> sex<span class="sc">+</span>Order, <span class="at">data =</span> mammal_long)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(OrderSpecificModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(mass) ~ sex + Order, data = mammal_long)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.3025 -0.8503 -0.1681  0.7009  6.6448 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)           3.26470    0.20065  16.271  &lt; 2e-16 ***
sexM                  0.06670    0.07469   0.893 0.372003    
OrderArtiodactyla     7.48041    0.25681  29.128  &lt; 2e-16 ***
OrderCarnivora        4.98832    0.25238  19.765  &lt; 2e-16 ***
OrderChiroptera      -0.51539    0.21144  -2.437 0.014926 *  
OrderCingulata        4.75527    0.46652  10.193  &lt; 2e-16 ***
OrderDasyuromorphia   2.67286    0.46652   5.729 1.26e-08 ***
OrderDidelphimorphia  1.04768    0.29311   3.574 0.000364 ***
OrderDiprotodontia    4.46041    0.28907  15.430  &lt; 2e-16 ***
OrderEulipotyphla    -0.13484    0.25681  -0.525 0.599633    
OrderLagomorpha       3.16969    0.38807   8.168 7.54e-16 ***
OrderMacroscelidea    0.58336    0.46652   1.250 0.211367    
OrderPeramelemorphia  3.38116    0.51219   6.601 5.98e-11 ***
OrderPerissodactyla   9.19047    0.69700  13.186  &lt; 2e-16 ***
OrderPilosa           5.56738    0.46652  11.934  &lt; 2e-16 ***
OrderPrimates         4.06503    0.22279  18.246  &lt; 2e-16 ***
OrderRodentia         1.12542    0.20796   5.412 7.46e-08 ***
OrderScandentia       1.83724    0.58037   3.166 0.001584 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.337 on 1264 degrees of freedom
Multiple R-squared:  0.7495,    Adjusted R-squared:  0.7461 
F-statistic: 222.5 on 17 and 1264 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>OrderSexInteractionModel <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(mass) <span class="sc">~</span> Order<span class="sc">*</span>sex, <span class="at">data =</span> mammal_long)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(OrderSexInteractionModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(mass) ~ Order * sex, data = mammal_long)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.2349 -0.8424 -0.1661  0.6973  6.6406 

Coefficients:
                           Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                3.286023   0.280406  11.719  &lt; 2e-16 ***
OrderArtiodactyla          7.391554   0.365279  20.235  &lt; 2e-16 ***
OrderCarnivora             4.864594   0.358973  13.551  &lt; 2e-16 ***
OrderChiroptera           -0.480737   0.300745  -1.598 0.110187    
OrderCingulata             4.789225   0.663561   7.217 9.17e-13 ***
OrderDasyuromorphia        2.481360   0.663561   3.739 0.000193 ***
OrderDidelphimorphia       0.985744   0.416903   2.364 0.018210 *  
OrderDiprotodontia         4.430888   0.411156  10.777  &lt; 2e-16 ***
OrderEulipotyphla         -0.168853   0.365279  -0.462 0.643977    
OrderLagomorpha            3.206508   0.551980   5.809 7.96e-09 ***
OrderMacroscelidea         0.601359   0.663561   0.906 0.364973    
OrderPeramelemorphia       3.268528   0.728516   4.487 7.91e-06 ***
OrderPerissodactyla        9.204062   0.991385   9.284  &lt; 2e-16 ***
OrderPilosa                5.618670   0.663561   8.467  &lt; 2e-16 ***
OrderPrimates              4.009450   0.316885  12.653  &lt; 2e-16 ***
OrderRodentia              1.108223   0.295791   3.747 0.000187 ***
OrderScandentia            1.836437   0.825493   2.225 0.026283 *  
sexM                       0.024053   0.396554   0.061 0.951643    
OrderArtiodactyla:sexM     0.177712   0.516582   0.344 0.730893    
OrderCarnivora:sexM        0.247443   0.507665   0.487 0.626050    
OrderChiroptera:sexM      -0.069299   0.425317  -0.163 0.870596    
OrderCingulata:sexM       -0.067905   0.938418  -0.072 0.942326    
OrderDasyuromorphia:sexM   0.382991   0.938418   0.408 0.683252    
OrderDidelphimorphia:sexM  0.123879   0.589590   0.210 0.833615    
OrderDiprotodontia:sexM    0.059034   0.581462   0.102 0.919148    
OrderEulipotyphla:sexM     0.068022   0.516582   0.132 0.895261    
OrderLagomorpha:sexM      -0.073637   0.780617  -0.094 0.924861    
OrderMacroscelidea:sexM   -0.035996   0.938418  -0.038 0.969409    
OrderPeramelemorphia:sexM  0.225269   1.030277   0.219 0.826959    
OrderPerissodactyla:sexM  -0.027191   1.402030  -0.019 0.984530    
OrderPilosa:sexM          -0.102580   0.938418  -0.109 0.912973    
OrderPrimates:sexM         0.111163   0.448142   0.248 0.804134    
OrderRodentia:sexM         0.034388   0.418312   0.082 0.934496    
OrderScandentia:sexM       0.001603   1.167423   0.001 0.998904    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.345 on 1248 degrees of freedom
Multiple R-squared:  0.7498,    Adjusted R-squared:  0.7432 
F-statistic: 113.3 on 33 and 1248 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Notice that in the <code>OrderSexInteractionModel</code> model, there are significant effects of the Order on body size but the effect of sex, even when order-specific, on size is not significant. That is, the associated regression coefficients have confidence intervals overlapping zero, so that we fail to reject the null hypothesis <span class="math inline">\(H_0: \beta_j = 0\)</span>.</p>
</section>
<section id="challenge-5" class="level3" data-number="10.7.3">
<h3 data-number="10.7.3" class="anchored" data-anchor-id="challenge-5"><span class="header-section-number">10.7.3</span> Challenge</h3>
<p>Use a for loop to regress log body size on sex for <em>each</em> Order? Print the coefficients from inside the loop.</p>
</section>
<section id="visualizing-fitted-models" class="level3" data-number="10.7.4">
<h3 data-number="10.7.4" class="anchored" data-anchor-id="visualizing-fitted-models"><span class="header-section-number">10.7.4</span> Visualizing fitted models</h3>
<p>For the first model we fit, it is straightforward to visualize the (lack of an) effect of sex on size:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(mass) <span class="sc">~</span> sex, <span class="at">data =</span> mammal_long)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>mammal_long <span class="sc">|&gt;</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> sex, <span class="at">y =</span> <span class="fu">log</span>(mass))) <span class="sc">+</span> </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_violin</span>() <span class="sc">+</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">width =</span> <span class="fl">0.1</span>) <span class="sc">+</span> </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">group =</span> <span class="dv">1</span>), <span class="at">method =</span> <span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>For the model fitted for <em>each</em> Order, we can visualize the effects as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>mammal_long <span class="sc">|&gt;</span> </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> sex, <span class="at">group =</span> Order, <span class="at">y =</span> <span class="fu">log</span>(mass))) <span class="sc">+</span> </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">width =</span> <span class="fl">0.1</span>) <span class="sc">+</span> </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Order)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec10-linear-models-1_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Notice differences in sample size (i.e., number of sampled species per order).</p>
</section>
<section id="challenge-6" class="level3" data-number="10.7.5">
<h3 data-number="10.7.5" class="anchored" data-anchor-id="challenge-6"><span class="header-section-number">10.7.5</span> Challenge</h3>
<p>Regress log body size on log length, visualize the effect, and interpret the coefficient for length. Then do the same but including sex and its interaction with length as an effect.</p>
<p><em>Hint: when interpreting the coefficient for length, recall that it has been log-transformed and, in the interaction, everything is measured relative to a baseline (in this example, males relative or the other way around). A per unit increase in the covariate does not imply a per unit increase in length.</em></p>
<p><strong>CAUTION: do not fit your models using ggplot. Use <code>lm()</code>. Visualizing the model should be, well, a visualization exercise. It is quite dangerous to draw conclusions when you are not 100 percent sure what model (with or without interaction, by factor, etc.) was fit and then plotted. To avoid these issues, many folks visualize models fitted in <code>lm()</code> using base R.</strong></p>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>It is worth noting that what is often used in theory and practice is a <em>matrix</em> formulation of the model we have written down: <span class="math display">\[\boldsymbol{y} = \begin{bmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}
\end{bmatrix} = \begin{bmatrix}
1 &amp; x_{11} &amp; x_{21} &amp; \cdots &amp; x_{p1} \\
1 &amp; x_{12} &amp; x_{22} &amp; \cdots &amp; x_{p2} \\
\vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
1 &amp; x_{1n} &amp; x_{2n} &amp; \cdots &amp; x_{pn}
\end{bmatrix} \begin{bmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{p}
\end{bmatrix} + \begin{bmatrix}
\varepsilon_{1} \\
\varepsilon_{2} \\
\vdots \\
\varepsilon_{n}
\end{bmatrix} = \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}.\]</span> Here, <span class="math inline">\(\boldsymbol{y} = (y_1,\dots,y_n)'\)</span> is a vector of measurements for the response, <span class="math inline">\(\boldsymbol{x_i} = (x_{i1},\dots,x_{in})'\)</span> is a vector of measurements for the <span class="math inline">\(k\)</span>th predictor, and <span class="math inline">\(\boldsymbol{\varepsilon} = (\varepsilon_1,\dots,\varepsilon_n)'\)</span> is a vector of measurement errors. The <span class="math inline">\('\)</span> symbol denotes transposition, the operation where the rows and columns of a vector or matrix are interchanged. In R, the function <code>t()</code> can be used to transpose a vector or matrix.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../lectures/lec09-intro-inference-2.html" class="pagination-link" aria-label="Introduction to inference II">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to inference II</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../lectures/lec11-linear-models-2.html" class="pagination-link" aria-label="Linear models II

## Lesson preamble

> ### Learning objectives
>> - Learn how dependent data can be modeled, and the sitations in which one may encounter such data.
> - Understand the structure, assumptions, and implementation of GLMs.
> - Understand the structure, assumptions, and implementation of LLMs.
> - Learn how to use simulation to inform what data that should be collected, and how.
> 
> ### Lesson outline
> -   Generalized linear models
>     - Structure and assumptions, including interpretation of the effects
>     - Implement logistic regression using dataset of Farrell and Davies (2019)
>     - Other types of GLMs (Poisson, negative binomial, etc.)
> -   Power analysis!
> -   Dealing with dependent data
>     - Splitting the data into groups...
>     - Controlling for phylogeny
>     - Linear mixed models: structure and assumptions
>       - Difference between fixed, random effects; examples
>       - Implement mixed models using sexual size dimorphism data

```{r, message=F, warning=F}
library(tidyverse)
library(broom)
library(lme4)
```

## Generalized linear models: theory and examples

So far we have seen how linear models can be used to describe relationships between a response variable and predictors when the data is normally distributed or can be transformed so that this assumption is not violated. What if we were, say, interested in a *binary* response (e.g., infection status of a host with a particular parasite) and how it changes with a continuous predictor (e.g., age of the host)? In this case, one can use a special kind of linear model called *logistic regression* to estimate the additive effect of predictor(s) on the binary response. Logistic regression is a special kind of **generalized linear model**.

### GLMs: structure and assumptions

Generalized linear models describe how the mean of a response variable changes as a function of the predictors when important assumptions of the linear modeling framework (normality, constant error variance, etc.) are violated. In particular, **GLMs allow us to work with data that are not normal, whose range is restricted, or whose variance depends on the mean.** The latter might be important if, say, larger values of the response were also more variable.

A GLM models the transformed mean of a response variable $Y_i$ as a linear combination of the predictors $x_1,\dots,x_p$. The goal of using a GLM is often to estimate how the predictors (e.g., sex and previous exposure to the disease) affect the response (e.g., infection status). sThe transformation of the response is done using a &quot;link&quot; function $g(\cdot)$ that is specific to the distribution which used to model the data. Written out, a GLM is of the form

$$g(\mu_i) = \beta_0 + \beta_1 x_{1i} + \cdots \beta_p x_{pi}.$$

The link functions for the Normal, Gamma, Exponential, Poisson, and Multinomial distributions are known. In general, GLMs apply when the data are modeled using a member of the [exponential family](https://en.wikipedia.org/wiki/Exponential_family). The distributions will have a mean parameter $\mu$ and, sometimes, a parameter $\tau$ which characterizes the dispersion around the mean. _GLMs are fitted using by maximizing the likelihood function that results from assuming the data arise from a distribution in the exponential family (with a mean and dispersion that depend on the predictors), using using numerical optimization methods._

### Interpretation of the effects

Notice that, in a GLM, because the mean of the response been transformed in a particular way, the coefficients must be interpreted carefully. In particular, $\beta_{j}$ is how a per-unit change in $x_{j}$ increases or decreases the _transformed_ mean $g(\mu_i)$.

### Example: logistic regression

In a previous class, we estimated the probability of death given infection for the wild boar when infected with viruses in the family _Coronaviridae_. In your current homework, you have been tasked with extending that model to all host and parasite family combinations. Excitingly, the dataset which have used includes information about the mean evolutionary isolation of all hosts that are infected with a parasite from all other hosts which are known to be infected.

Farrell and Davies tested if the mean evolutionary isolation affected the probability of death. They used a complex model to control for sampling bias and other confounding aspects of the data. We will ignore those complexities and see if, using a GLM, we can recapitulate their findings. To get started, load the `disease_distance.csv` dataset.

```{r}
disease_distance <- read_csv(&quot;data/disease_distance.csv&quot;)

disease_distance %>% 
  mutate(AnyDeaths = case_when(Deaths > 0 ~ 1,
                               Deaths == 0 ~ 0)) -> DataBern

DataBern |>  ggplot(aes(x = EvoIso, y = AnyDeaths)) + 
  geom_point()
```

These are binary data. We CANNOT use a linear model, as this assumes the data are Normal. In fact, these data are distributed according to a Bernoulli($p$) distribution. This is a member of the exponential family and the type of generalized linear model when the data are distributed in this way (i.e., are binary) is called **logistic regression**.

The mean of Bernoulli($p$) data is just $p$, and the link function for $p$ is

$$ \text{logit}(p) = \log\frac{p}{1-p}.$$

$\text{logit}(p)$ is called the *log-odds*, which can be thought of as a likelihood the response takes on the value one. In logistic regression, the log-odds ratio is modeled as a linear combination in the predictors:

$$ \text{logit}(p_i) =  \beta_0 + \beta_1 x_{1i} + \cdots + \beta_p x_{pi}.$$

Notice that increasing $x_j$ by one unit results in change $\beta_j$ to the link-transformed response.This is how the effect sizes are interpreted for GLMs such as this one.


```{r}
model <- glm(AnyDeaths ~ EvoIso, 
             family = &quot;binomial&quot;, 
             data = DataBern)
summary(model)
```

#### Challenge

How do we interpret the regression coefficient above?

#### Challenge

What are the log-odds of death if the evolutionary isolation of hosts is $EI = 200$? How much does this quantity change if the evolutionary isolation were to increase by 20 million years?

#### Visualizing the fitted model

```{r}
DataBern |>  ggplot(aes(x = EvoIso, y = AnyDeaths)) + 
  geom_point() +
  geom_smooth(method = &quot;glm&quot;, 
              method.args = list(family = &quot;binomial&quot;)
              )

### base R implementation

EvoIso <- seq(0, 200, 0.1)
predicted_prob <- predict(model, list(EvoIso = EvoIso), type = &quot;response&quot;)

plot(DataBern$EvoIso, DataBern$AnyDeaths)
lines(EvoIso, predicted_prob)
```

### Other GLMs

Here are some common types of response variables and their corresponding distributions:

-   **Count data**: the **Poisson** distribution
-   **Over-dispersed count data** (when the count data is more spread out than &quot;expected&quot;): the **negative binomial** distribution
-   **Binary data** (two discrete categories): the **binomial** distribution
-   Counts of occurrences of $K$ different types: the **multinomial** distribution
-   **Times** between $r$ events: the **gamma** distribution, which is equivilent to the exponential when $r=1$

You will have the opportunity to implement such models in your homework and on the challenge assignment!

## Power analysis

When designing experiments or how best to collect data, it is best to think about the model you will fit and the kind of experiment you need to design in order to have sufficient power to detect an effect of interest. For example, if we thought that age affected the likelihood that a host dies of a disease, then we would likely fit a logistic regression-type model. By _simulating_ data from such a model, we can determine

- the minimum sample size required to reliably estimate an effect of a certain size
- the minimum sample size required to detect an effect of a certain size at a fixed significance level
- the minimum effect size that can be detected at a fixed significance level and sample size

### Example

Below is an example of a simulation in which binary disease data (death/no death; 0/1) are simulated hosts of various ages, assuming the the log-odds of disease is a linear function of age. (Notice that we assume that host lifetimes are exponentially distributed with rate parameter $\lambda = 1/10$ years. This means that hosts, in this simulation, live for an average of 10 years.) We then fit a logistic regression to this data to determine the effect of age on disease risk.

```{r}
data_generator <- function(sample_size = 100, effect = 0.1){
  age <- rexp(n = sample_size, rate = 1/10)
  linear_predictor <- effect*age
  prob <- 1/(1+exp(-linear_predictor))
  
  disease_status <- c()
  
  for (i in 1:length(prob)){
  disease_status[i] <- rbinom(n = 1, size = 1, prob = prob[i])
  }
  
  return(data.frame(age = age, disease_status = disease_status))
}

data <- data_generator()

data %>% pivot_longer(! age) %>% 
  ggplot(aes(x = age, y = value)) + geom_point() + 
  geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)
              ) + labs(y = &quot;prob. of disease (i.e., disease status =1)&quot;)

model <- glm(disease_status~scale(age), family = binomial, data = data)
summary(model)
```

Next, we will write a function that performs a **power analysis**. We will use this function determine the sample size that is required so that simulating the age-disease data repeatedly we identify a significant effect of age on disease status (i.e., reject the null hypothesis) at level $\alpha = 0.01$ *at least $95\%$ of the time*.

```{r}
power_analysis_function <- function(sample_size){
  
  sims <- 1000
  pvalues <- c()
  for (i in 1:sims){
  data <- data_generator(sample_size)
  model <- glm(disease_status~scale(age), family = binomial, data = data)
  pvalues[i] <- summary(model)$coefficients[2,4]
  }
  
  power_estimate <- length(which(pvalues < 0.01))/length(pvalues)
  
  return(power_estimate)
}

sample_sizes <- seq(150,200,10); power_estimates <- c()

for (i in 1:length(sample_sizes)){
  power_estimates[i] <- power_analysis_function(sample_size = sample_sizes[i])
}

knitr::kable(cbind(n = sample_sizes, power = power_estimates))
```

## Dealing with dependent data!

To illustrate how mixed models work and what kinds of questions we can answer using them, we will use the sexual size dimorphism data which we analyzed last class. Recall that we did NOT find a significant effect of sex on the average body size. There was no effect of the interaction between Order and sex on body size. Indeed, this matches what you saw in the homework questions where you had to visualize the data --- most of the variation in body size was _between_ orders.

In the models we built, we ignored a pretty important fact about the data: species have a common history (i.e., phylogeny). Thus, observations are not independent! This can make drawing inferences from comparative data difficult. **We will address how to deal with the non-independence of data (due to a common history of species, replication in blocks, etc.) using three approaches.**

But, first, let's download the data we will use in this section!

```{r}
SSDdata <- read_csv(&quot;data/SSDinMammals.csv&quot;)
```

```{r}
mammal_length <- SSDdata %>%
  select(c(&quot;Order&quot;, &quot;Scientific_Name&quot;, &quot;lengthM&quot;, &quot;lengthF&quot;)) %>%
  pivot_longer(c(lengthM, lengthF), names_to = &quot;sex&quot;, values_to = &quot;length&quot;,
               names_pattern = &quot;length(.)&quot;)

mammal_mass <- SSDdata %>%
  select(c(&quot;Order&quot;, &quot;Scientific_Name&quot;, &quot;massM&quot;, &quot;massF&quot;)) %>%
  pivot_longer(c(massM, massF), names_to = &quot;sex&quot;, values_to = &quot;mass&quot;,
               names_pattern = &quot;mass(.)&quot;)

mass_nodup <- mammal_mass %>% 
  group_by(Scientific_Name, sex) %>%
  distinct(Scientific_Name, sex, .keep_all = TRUE)

length_nodup <- mammal_length %>% 
  group_by(Scientific_Name, sex) %>%
  distinct(Scientific_Name, sex, .keep_all = TRUE)

mammal_long <- full_join(mass_nodup, length_nodup, 
                         by = join_by(&quot;Scientific_Name&quot;, &quot;sex&quot;, &quot;Order&quot;)) |>  drop_na()

glimpse(mammal_long)
```

### Group-by-group analyses

**One first way we can handle dependent data is to split observations into groups such that, within each group, observations are independent (or approximately so).** This is what we did last class when we fit order-specific regression coefficients of sex on body size. We saw that ALL order-specific effects had confidence intervals which overlapped zero!

```{r, warning=F, message=F}
# run linear model of size on sex for EACH Order

Order_specific_models <- 
  mammal_long |> 
  group_by(Order) |>  do(model = tidy(lm(log(mass) ~ sex, data = .), conf.int = T))
  
# get coefficients for each Order

Order_specific_models |>  unnest() |>  select(Order, estimate)

# visualize effects, CIs, and p values

Order_specific_models |>  unnest() |>  subset(term == &quot;sexM&quot;) |>  group_by(Order) |>  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2)
```

No effect of sex on body size, for any of the orders!

#### Challenge

How would you adjust the previous plot to show the estimated intercepts AND the effects of sex?

```{r}
Order_specific_models |>  unnest() |>  # subset(term == &quot;sexM&quot;) |>  group_by(Order) |>  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high,
             color = term
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2)
```

#### Challenge

How would you retrieve model fits for each Order in base R?

```{r, include=F}
for (i in 1:nrow(Order_specific_models)){
  print(summary(Order_specific_models$mod[[i]]))
}
```

#### Challenge

Adjust the plot above so that it the size of the estimates depend on the number of observations in an Order? _Hint: determine the number of observations per Order and then use the `merge()` function with the `Order_specific_models` tibble. To adjust the range of point sizes, use `scale_size()`._

```{r, include=F}
mammal_long |> 
  group_by(Order) |>  summarise(number_obs = n()) |>  merge(Order_specific_models) |>  unnest() |>  ggplot(aes(y = Order, x = estimate, 
             xmin = conf.low,
             xmax = conf.high,
             color = term,
             size = number_obs
             )
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0, lty = 2) +
  scale_size(range = c(0, 2))
```

#### Pros and cons

There are several advantages to preforming a group-by-group analysis:

- **Fitting more complex models (e.g., those with random effects) can be difficult.** There may be convergence issues, and interpretation of effects and $p$-values can be tricky.
- The group-by-group analysis is **robust in the face of unbalanced data** (i.e., when there are more observations for some groups than others).
- **The conclusions from a group-by-group analysis are _conservative_.**
- The group-by-group analysis is **fairly easy to implement**.

Among the disparages to this approach are the following:

- With fewer samples per group, the analysis **may be under-powered**.
- Splitting the data into groups means there are more coefficients to estimate, and thus confidence intervals to be estimated and hypothesis tests to be performed. This means there is a greater chance that we obtain a **spurious association**.*
- It is **difficult to draw conclusions about the variance between groups.** In some applications, this is of interest. In others, it is not.

*One solution is to adjust the significant level based on the number of tests conducted. If $k$ hypotheses are tested, an [common adjustment](https://en.wikipedia.org/wiki/Bonferroni_correction) is to set $\alpha = 0.05/k$.

### Controlling for phylogeny

A common reason data are dependent in biology is that **species share a common history of descent with modification.** When we assume that the observations are independent, we make implicit assumptions about the degree to which the characters at the tips of a phylogeny have underwent independent evolution. Sometimes, when species are diverged by many millions of years and traits evolve quickly, it is reasonable to ignore the phylogenetic constraints on the data. In other cases, it is essential to consider the role of phylogeny.

Several methods can control for phylogeny (if known). In fact, such methods can _use_ information in the branching pattern of species to draw inferences about the evolution of ecologically-important traits (such as body and brain size, dispersal rate, etc.). We will not discuss how to implement phylogenetic comparative methods, but it is good to know they exist and how, at a surface level, they work.

Intuition for how PCMs work is easiest to grasp when we consider a tree with $n$ species at the tips. If we know the pairwise divergence times for all species, then we can _transform_ the data so that observations are independent by looking at all _differences_ of traits. Not all differences are equally informative; if species have diverged a long time ago, there has been more time for differences to build up. PCMs account for this by specifying how the distribution of trait differences between species $i$ and $j$ depends on the time that has elapsed since these species diverged, In particular, the larger the divergence time, the greater the variance in $Y_i-Y_j$, the difference in trait values between species $i$ and $j$. A simple way to do this is to write $\sigma_{ij} = \sigma^2/T_{ij}$.^[Note: this gives rise to a likelihood function that is functionally VERY similar to the one for the linear model with constant error variance.]

### Random effects!

Another way one can account for dependent data is by including _random effects_. Random effects are often used to control for the fact that observations are clustered (e.g., trait data for species belonging to a higher taxonomic unit, measurements of plant biomass from plots of land).

#### Structure and assumptions

A common way models with random effects are formulated is as follows:

$$Y_{ij} \sim \text{Normal}(\beta_0 + \beta_1 x_{1ij} + \cdots + \beta_{p} x_{pij} + b_{0i} + b_{1i} z_{1ij} + \cdots + b_{qi} z_{qij}, \sigma_{ij}^2),$$

where $ij$ is the $i$th observation from the $j$th cluster and

$$b_{ki} \sim \text{Normal}(0,\tau_k^2).$$

This gives rise to a distribution for $Y$ which depends on the values of the random effects $b_0,\dots,b_q$. Under the hood, methods that fit models of this form numerically maximize a version of the likelihood function that results from these assumptions.

#### Challenge

In each of the following examples, which effects might be reasonably treated as fixed vs. random? Justify your answer.

1. Suppose we are working with rodents that have been infected with an evolved strain of the parasite that causes malaria. Some rodents have been treated with a prospective vaccine and others sham-vaccinated. We are interested if a proxy for virulence (e.g., density of infected red blood cells) depends on vaccination status.

2. Suppose we conduct the same experiment, except rodents are caged are sets of four.

3. Suppose we measure the time between sightings of a raccoon in a Toronto neighborhood using six camera traps (strategically placed in the neighborhood). We do this for year, and want to ask if mean daily temperature predicts the frequency of raccoon occurrence.

4. Suppose that, every year, we go to the Amazon and measure the number of bird calls that come from $n=30$ trees. Assume that the trees are far enough apart we can treat them as independent. We measure the number of birds in a tree, characteristics of the tree (cover, height, width, age), the year in which a measurement was done, and the mean temperature that year. We want to know if tree cover affects the frequency of bird calls, and if it interacts with temperature.

For more on the difference between fixed and random effects, check out the following resources

- [this Cross Validated post](https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-in-mixed-effect-model)
- [this Dynamic Ecology post](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)
- [this book chapter](https://bookdown.org/steve_midway/DAR/random-effects.html)

#### Using `lme4` to fit random and mixed effect models

We will start by fitting a model of log body size on log length where the intercept is random depending on the Order. Based on a quick visualization of the data, such a model may be appropriate.

```{r}
ggplot(data = mammal_long, aes(y = log(mass), 
                               x = log(length)
                               )
       ) + 
    geom_point(aes(color = Order), size = 3) -> p

p 
```

```{r, include=F}
# no Order-dependence:
p + geom_smooth(method = &quot;lm&quot;)

# intercept AND slope fixed and specific to the Order:
p + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~Order) 
```

To fit regress the response on a set of fixed effects with random _intercepts_ that depends the values assumed by a random effect `x`, we call `lmer` and write a linear model with `(1|x)`.

```{r}
## random intercept for Order

model <- lmer(formula = log(mass) ~ log(length) + (1|Order), data = mammal_long)
summary(model)

fixef(model)
ranef(model)
```

From top to bottom, the output is telling us that the model was fit using a method called REML (restricted maximum likelihood). It returns information about the residuals, random effects, and fixed effects. The output also tells us about the **estimated variance for the random effects** in the model. Here, the variance associated with Order is 4.256. The variance explained by Order is 4.256/(4.256+0.847) _after controlling for the fixed effects_. Note the denominator here is the total variance, including from the residuals. As usual, we also have information about the fixed effects.

To visualize the model, we can predict the overall and Order-specific relationship of log mass on log length for all of the Orders represented in the data.

```{r}
mammal_long |> ungroup() |> select(mass, length, Order) |> 
  mutate(fit.m = predict(model, re.form = NA), # does not include random effects
         fit.c = predict(model, re.form = NULL) # includes random effects
         ) ->  predicted_values

predicted_values |>  ggplot(aes(x = log(length), y = log(mass), color = Order)) +
  geom_point(size = 3) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = &quot;black&quot;, size = 2)
```

The thick black line corresponds to the fitted values associated with the fixed-effect component of the model. The colored lines correspond to the fitted values estimated for each Order. 

Perhaps a model with Order-specific random intercepts AND slopes would be better. We fit this model using the code below. The key difference in syntax is that we write `(1+fixed effect|random effect)` to indicate that the random effect has an effect on both the intercept _and_ slope of the response on the fixed effect.

```{r}
## random intercept and slope for Order

model2 <- lmer(formula = log(mass) ~ log(length) + (1+log(length)|Order), data = mammal_long)
summary(model2)

fixef(model2)
ranef(model2)
```

```{r}
mammal_long |> ungroup() |> select(mass, length, Order) |> 
  mutate(fit.m = predict(model2, re.form = NA),
         fit.c = predict(model2, re.form = NULL)
         ) ->  predicted_values

predicted_values |>  ggplot(aes(x = log(length), y = log(mass), color = Order)) +
  geom_point(size = 3) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +
  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = &quot;black&quot;, size = 2)
```

Why does this look like a mess? As stated above, **mixed models do not work well when datasets are unbalanced.** Indeed, the number of observations in the different Orders are quite variable.

#### Challenge

Regress log body size on sex with Order as a random effect that affects the intercept AND slope of the sex-size relationship.

```{r, include=F}
Model <- lmer(log(mass) ~ sex + (1+sex|Order), mammal_long)

mammal_long |> ungroup() |> select(Scientific_Name, mass, sex, Order) |> 
  mutate(fit.m = predict(Model, re.form = NA),
         fit.c = predict(Model, re.form = NULL)
         ) ->  predicted_values

predicted_values |>  ggplot(aes(x = sex, y = log(mass))) +
  geom_line(aes(group = Scientific_Name), color = &quot;lightgrey&quot;) +
  geom_point(color = &quot;lightgrey&quot;, size = 2) +
  geom_point(inherit.aes = F, aes(x = sex, y = fit.c, color = Order), size = 3) +
  geom_line(inherit.aes = F, aes(x = sex, y = fit.c, color = Order, group = Order), size = 2) +
  geom_point(inherit.aes = F, aes(x = sex, y = fit.m), color = &quot;black&quot;, size = 3) +
  geom_line(inherit.aes = F, aes(x = sex, y = fit.m, group = &quot;&quot;), color = &quot;black&quot;, size = 3) +
  theme_classic()
```">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Linear models II## Lesson preamble&gt; ### Learning objectives&gt;&gt; - Learn how dependent data can be modeled, and the sitations in which one may encounter such data.&gt; - Understand the structure, assumptions, and implementation of GLMs.&gt; - Understand the structure, assumptions, and implementation of LLMs.&gt; - Learn how to use simulation to inform what data that should be collected, and how.&gt; &gt; ### Lesson outline&gt; - Generalized linear models&gt; - Structure and assumptions, including interpretation of the effects&gt; - Implement logistic regression using dataset of Farrell and Davies (2019)&gt; - Other types of GLMs (Poisson, negative binomial, etc.)&gt; - Power analysis!&gt; - Dealing with dependent data&gt; - Splitting the data into groups…&gt; - Controlling for phylogeny&gt; - Linear mixed models: structure and assumptions&gt; - Difference between fixed, random effects; examples&gt; - Implement mixed models using sexual size dimorphism data<code>{r, message=F, warning=F}library(tidyverse)library(broom)library(lme4)</code>## Generalized linear models: theory and examplesSo far we have seen how linear models can be used to describe relationships between a response variable and predictors when the data is normally distributed or can be transformed so that this assumption is not violated. What if we were, say, interested in a <em>binary</em> response (e.g., infection status of a host with a particular parasite) and how it changes with a continuous predictor (e.g., age of the host)? In this case, one can use a special kind of linear model called <em>logistic regression</em> to estimate the additive effect of predictor(s) on the binary response. Logistic regression is a special kind of <strong>generalized linear model</strong>.### GLMs: structure and assumptionsGeneralized linear models describe how the mean of a response variable changes as a function of the predictors when important assumptions of the linear modeling framework (normality, constant error variance, etc.) are violated. In particular, <strong>GLMs allow us to work with data that are not normal, whose range is restricted, or whose variance depends on the mean.</strong> The latter might be important if, say, larger values of the response were also more variable.A GLM models the transformed mean of a response variable <span class="math inline">\(Y_i\)</span> as a linear combination of the predictors <span class="math inline">\(x_1,\dots,x_p\)</span>. The goal of using a GLM is often to estimate how the predictors (e.g., sex and previous exposure to the disease) affect the response (e.g., infection status). sThe transformation of the response is done using a “link” function <span class="math inline">\(g(\cdot)\)</span> that is specific to the distribution which used to model the data. Written out, a GLM is of the form<span class="math display">\[g(\mu_i) = \beta_0 + \beta_1 x_{1i} + \cdots \beta_p x_{pi}.\]</span>The link functions for the Normal, Gamma, Exponential, Poisson, and Multinomial distributions are known. In general, GLMs apply when the data are modeled using a member of the </span></span></a><a href="https://en.wikipedia.org/wiki/Exponential_family">exponential family</a>. The distributions will have a mean parameter <span class="math inline">\(\mu\)</span> and, sometimes, a parameter <span class="math inline">\(\tau\)</span> which characterizes the dispersion around the mean. <em>GLMs are fitted using by maximizing the likelihood function that results from assuming the data arise from a distribution in the exponential family (with a mean and dispersion that depend on the predictors), using using numerical optimization methods.</em>### Interpretation of the effectsNotice that, in a GLM, because the mean of the response been transformed in a particular way, the coefficients must be interpreted carefully. In particular, <span class="math inline">\(\beta_{j}\)</span> is how a per-unit change in <span class="math inline">\(x_{j}\)</span> increases or decreases the <em>transformed</em> mean <span class="math inline">\(g(\mu_i)\)</span>.### Example: logistic regressionIn a previous class, we estimated the probability of death given infection for the wild boar when infected with viruses in the family <em>Coronaviridae</em>. In your current homework, you have been tasked with extending that model to all host and parasite family combinations. Excitingly, the dataset which have used includes information about the mean evolutionary isolation of all hosts that are infected with a parasite from all other hosts which are known to be infected.Farrell and Davies tested if the mean evolutionary isolation affected the probability of death. They used a complex model to control for sampling bias and other confounding aspects of the data. We will ignore those complexities and see if, using a GLM, we can recapitulate their findings. To get started, load the <code>disease_distance.csv</code> dataset.<code>{r}disease_distance &lt;- read_csv("data/disease_distance.csv")disease_distance %&gt;%   mutate(AnyDeaths = case_when(Deaths &gt; 0 ~ 1,                               Deaths == 0 ~ 0)) -&gt; DataBernDataBern |&gt;  ggplot(aes(x = EvoIso, y = AnyDeaths)) +   geom_point()</code>These are binary data. We CANNOT use a linear model, as this assumes the data are Normal. In fact, these data are distributed according to a Bernoulli(<span class="math inline">\(p\)</span>) distribution. This is a member of the exponential family and the type of generalized linear model when the data are distributed in this way (i.e., are binary) is called <strong>logistic regression</strong>.The mean of Bernoulli(<span class="math inline">\(p\)</span>) data is just <span class="math inline">\(p\)</span>, and the link function for <span class="math inline">\(p\)</span> is<span class="math display">\[ \text{logit}(p) = \log\frac{p}{1-p}.\]</span><span class="math inline">\(\text{logit}(p)\)</span> is called the <em>log-odds</em>, which can be thought of as a likelihood the response takes on the value one. In logistic regression, the log-odds ratio is modeled as a linear combination in the predictors:<span class="math display">\[ \text{logit}(p_i) =  \beta_0 + \beta_1 x_{1i} + \cdots + \beta_p x_{pi}.\]</span>Notice that increasing <span class="math inline">\(x_j\)</span> by one unit results in change <span class="math inline">\(\beta_j\)</span> to the link-transformed response.This is how the effect sizes are interpreted for GLMs such as this one.<code>{r}model &lt;- glm(AnyDeaths ~ EvoIso,              family = "binomial",              data = DataBern)summary(model)</code>#### ChallengeHow do we interpret the regression coefficient above?#### ChallengeWhat are the log-odds of death if the evolutionary isolation of hosts is <span class="math inline">\(EI = 200\)</span>? How much does this quantity change if the evolutionary isolation were to increase by 20 million years?#### Visualizing the fitted model<code>{r}DataBern |&gt;  ggplot(aes(x = EvoIso, y = AnyDeaths)) +   geom_point() +  geom_smooth(method = "glm",               method.args = list(family = "binomial")              )### base R implementationEvoIso &lt;- seq(0, 200, 0.1)predicted_prob &lt;- predict(model, list(EvoIso = EvoIso), type = "response")plot(DataBern$EvoIso, DataBern$AnyDeaths)lines(EvoIso, predicted_prob)</code>### Other GLMsHere are some common types of response variables and their corresponding distributions:- <strong>Count data</strong>: the <strong>Poisson</strong> distribution- <strong>Over-dispersed count data</strong> (when the count data is more spread out than “expected”): the <strong>negative binomial</strong> distribution- <strong>Binary data</strong> (two discrete categories): the <strong>binomial</strong> distribution- Counts of occurrences of <span class="math inline">\(K\)</span> different types: the <strong>multinomial</strong> distribution- <strong>Times</strong> between <span class="math inline">\(r\)</span> events: the <strong>gamma</strong> distribution, which is equivilent to the exponential when <span class="math inline">\(r=1\)</span>You will have the opportunity to implement such models in your homework and on the challenge assignment!## Power analysisWhen designing experiments or how best to collect data, it is best to think about the model you will fit and the kind of experiment you need to design in order to have sufficient power to detect an effect of interest. For example, if we thought that age affected the likelihood that a host dies of a disease, then we would likely fit a logistic regression-type model. By <em>simulating</em> data from such a model, we can determine- the minimum sample size required to reliably estimate an effect of a certain size- the minimum sample size required to detect an effect of a certain size at a fixed significance level- the minimum effect size that can be detected at a fixed significance level and sample size### ExampleBelow is an example of a simulation in which binary disease data (death/no death; 0/1) are simulated hosts of various ages, assuming the the log-odds of disease is a linear function of age. (Notice that we assume that host lifetimes are exponentially distributed with rate parameter <span class="math inline">\(\lambda = 1/10\)</span> years. This means that hosts, in this simulation, live for an average of 10 years.) We then fit a logistic regression to this data to determine the effect of age on disease risk.<code>{r}data_generator &lt;- function(sample_size = 100, effect = 0.1){  age &lt;- rexp(n = sample_size, rate = 1/10)  linear_predictor &lt;- effect*age  prob &lt;- 1/(1+exp(-linear_predictor))    disease_status &lt;- c()    for (i in 1:length(prob)){  disease_status[i] &lt;- rbinom(n = 1, size = 1, prob = prob[i])  }    return(data.frame(age = age, disease_status = disease_status))}data &lt;- data_generator()data %&gt;% pivot_longer(! age) %&gt;%   ggplot(aes(x = age, y = value)) + geom_point() +   geom_smooth(method = "glm", method.args = list(family = "binomial")              ) + labs(y = "prob. of disease (i.e., disease status =1)")model &lt;- glm(disease_status~scale(age), family = binomial, data = data)summary(model)</code>Next, we will write a function that performs a <strong>power analysis</strong>. We will use this function determine the sample size that is required so that simulating the age-disease data repeatedly we identify a significant effect of age on disease status (i.e., reject the null hypothesis) at level <span class="math inline">\(\alpha = 0.01\)</span> <em>at least <span class="math inline">\(95\%\)</span> of the time</em>.<code>{r}power_analysis_function &lt;- function(sample_size){    sims &lt;- 1000  pvalues &lt;- c()  for (i in 1:sims){  data &lt;- data_generator(sample_size)  model &lt;- glm(disease_status~scale(age), family = binomial, data = data)  pvalues[i] &lt;- summary(model)$coefficients[2,4]  }    power_estimate &lt;- length(which(pvalues &lt; 0.01))/length(pvalues)    return(power_estimate)}sample_sizes &lt;- seq(150,200,10); power_estimates &lt;- c()for (i in 1:length(sample_sizes)){  power_estimates[i] &lt;- power_analysis_function(sample_size = sample_sizes[i])}knitr::kable(cbind(n = sample_sizes, power = power_estimates))</code>## Dealing with dependent data!To illustrate how mixed models work and what kinds of questions we can answer using them, we will use the sexual size dimorphism data which we analyzed last class. Recall that we did NOT find a significant effect of sex on the average body size. There was no effect of the interaction between Order and sex on body size. Indeed, this matches what you saw in the homework questions where you had to visualize the data — most of the variation in body size was <em>between</em> orders.In the models we built, we ignored a pretty important fact about the data: species have a common history (i.e., phylogeny). Thus, observations are not independent! This can make drawing inferences from comparative data difficult. <strong>We will address how to deal with the non-independence of data (due to a common history of species, replication in blocks, etc.) using three approaches.</strong>But, first, let’s download the data we will use in this section!<code>{r}SSDdata &lt;- read_csv("data/SSDinMammals.csv")``````{r}mammal_length &lt;- SSDdata %&gt;%  select(c("Order", "Scientific_Name", "lengthM", "lengthF")) %&gt;%  pivot_longer(c(lengthM, lengthF), names_to = "sex", values_to = "length",               names_pattern = "length(.)")mammal_mass &lt;- SSDdata %&gt;%  select(c("Order", "Scientific_Name", "massM", "massF")) %&gt;%  pivot_longer(c(massM, massF), names_to = "sex", values_to = "mass",               names_pattern = "mass(.)")mass_nodup &lt;- mammal_mass %&gt;%   group_by(Scientific_Name, sex) %&gt;%  distinct(Scientific_Name, sex, .keep_all = TRUE)length_nodup &lt;- mammal_length %&gt;%   group_by(Scientific_Name, sex) %&gt;%  distinct(Scientific_Name, sex, .keep_all = TRUE)mammal_long &lt;- full_join(mass_nodup, length_nodup,                          by = join_by("Scientific_Name", "sex", "Order")) |&gt;  drop_na()glimpse(mammal_long)</code>### Group-by-group analyses<strong>One first way we can handle dependent data is to split observations into groups such that, within each group, observations are independent (or approximately so).</strong> This is what we did last class when we fit order-specific regression coefficients of sex on body size. We saw that ALL order-specific effects had confidence intervals which overlapped zero!<code>{r, warning=F, message=F}# run linear model of size on sex for EACH OrderOrder_specific_models &lt;-   mammal_long |&gt;   group_by(Order) |&gt;  do(model = tidy(lm(log(mass) ~ sex, data = .), conf.int = T))  # get coefficients for each OrderOrder_specific_models |&gt;  unnest() |&gt;  select(Order, estimate)# visualize effects, CIs, and p valuesOrder_specific_models |&gt;  unnest() |&gt;  subset(term == "sexM") |&gt;  group_by(Order) |&gt;  ggplot(aes(y = Order, x = estimate,              xmin = conf.low,             xmax = conf.high             )         ) +  geom_pointrange() +  geom_vline(xintercept = 0, lty = 2)</code>No effect of sex on body size, for any of the orders!#### ChallengeHow would you adjust the previous plot to show the estimated intercepts AND the effects of sex?<code>{r}Order_specific_models |&gt;  unnest() |&gt;  # subset(term == "sexM") |&gt;  group_by(Order) |&gt;  ggplot(aes(y = Order, x = estimate,              xmin = conf.low,             xmax = conf.high,             color = term             )         ) +  geom_pointrange() +  geom_vline(xintercept = 0, lty = 2)</code>#### ChallengeHow would you retrieve model fits for each Order in base R?<code>{r, include=F}for (i in 1:nrow(Order_specific_models)){  print(summary(Order_specific_models$mod[[i]]))}</code>#### ChallengeAdjust the plot above so that it the size of the estimates depend on the number of observations in an Order? <em>Hint: determine the number of observations per Order and then use the <code>merge()</code> function with the <code>Order_specific_models</code> tibble. To adjust the range of point sizes, use <code>scale_size()</code>.</em><code>{r, include=F}mammal_long |&gt;   group_by(Order) |&gt;  summarise(number_obs = n()) |&gt;  merge(Order_specific_models) |&gt;  unnest() |&gt;  ggplot(aes(y = Order, x = estimate,              xmin = conf.low,             xmax = conf.high,             color = term,             size = number_obs             )         ) +  geom_pointrange() +  geom_vline(xintercept = 0, lty = 2) +  scale_size(range = c(0, 2))</code>#### Pros and consThere are several advantages to preforming a group-by-group analysis:- <strong>Fitting more complex models (e.g., those with random effects) can be difficult.</strong> There may be convergence issues, and interpretation of effects and <span class="math inline">\(p\)</span>-values can be tricky.- The group-by-group analysis is <strong>robust in the face of unbalanced data</strong> (i.e., when there are more observations for some groups than others).- <strong>The conclusions from a group-by-group analysis are <em>conservative</em>.</strong>- The group-by-group analysis is <strong>fairly easy to implement</strong>.Among the disparages to this approach are the following:- With fewer samples per group, the analysis <strong>may be under-powered</strong>.- Splitting the data into groups means there are more coefficients to estimate, and thus confidence intervals to be estimated and hypothesis tests to be performed. This means there is a greater chance that we obtain a <strong>spurious association</strong>.<em>- It is <strong>difficult to draw conclusions about the variance between groups.</strong> In some applications, this is of interest. In others, it is not.</em>One solution is to adjust the significant level based on the number of tests conducted. If <span class="math inline">\(k\)</span> hypotheses are tested, an <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">common adjustment</a> is to set <span class="math inline">\(\alpha = 0.05/k\)</span>.### Controlling for phylogenyA common reason data are dependent in biology is that <strong>species share a common history of descent with modification.</strong> When we assume that the observations are independent, we make implicit assumptions about the degree to which the characters at the tips of a phylogeny have underwent independent evolution. Sometimes, when species are diverged by many millions of years and traits evolve quickly, it is reasonable to ignore the phylogenetic constraints on the data. In other cases, it is essential to consider the role of phylogeny.Several methods can control for phylogeny (if known). In fact, such methods can <em>use</em> information in the branching pattern of species to draw inferences about the evolution of ecologically-important traits (such as body and brain size, dispersal rate, etc.). We will not discuss how to implement phylogenetic comparative methods, but it is good to know they exist and how, at a surface level, they work.Intuition for how PCMs work is easiest to grasp when we consider a tree with <span class="math inline">\(n\)</span> species at the tips. If we know the pairwise divergence times for all species, then we can <em>transform</em> the data so that observations are independent by looking at all <em>differences</em> of traits. Not all differences are equally informative; if species have diverged a long time ago, there has been more time for differences to build up. PCMs account for this by specifying how the distribution of trait differences between species <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> depends on the time that has elapsed since these species diverged, In particular, the larger the divergence time, the greater the variance in <span class="math inline">\(Y_i-Y_j\)</span>, the difference in trait values between species <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. A simple way to do this is to write <span class="math inline">\(\sigma_{ij} = \sigma^2/T_{ij}\)</span>.### Random effects!Another way one can account for dependent data is by including <em>random effects</em>. Random effects are often used to control for the fact that observations are clustered (e.g., trait data for species belonging to a higher taxonomic unit, measurements of plant biomass from plots of land).#### Structure and assumptionsA common way models with random effects are formulated is as follows:<span class="math display">\[Y_{ij} \sim \text{Normal}(\beta_0 + \beta_1 x_{1ij} + \cdots + \beta_{p} x_{pij} + b_{0i} + b_{1i} z_{1ij} + \cdots + b_{qi} z_{qij}, \sigma_{ij}^2),\]</span>where <span class="math inline">\(ij\)</span> is the <span class="math inline">\(i\)</span>th observation from the <span class="math inline">\(j\)</span>th cluster and<span class="math display">\[b_{ki} \sim \text{Normal}(0,\tau_k^2).\]</span>This gives rise to a distribution for <span class="math inline">\(Y\)</span> which depends on the values of the random effects <span class="math inline">\(b_0,\dots,b_q\)</span>. Under the hood, methods that fit models of this form numerically maximize a version of the likelihood function that results from these assumptions.#### ChallengeIn each of the following examples, which effects might be reasonably treated as fixed vs.&nbsp;random? Justify your answer.1. Suppose we are working with rodents that have been infected with an evolved strain of the parasite that causes malaria. Some rodents have been treated with a prospective vaccine and others sham-vaccinated. We are interested if a proxy for virulence (e.g., density of infected red blood cells) depends on vaccination status.2. Suppose we conduct the same experiment, except rodents are caged are sets of four.3. Suppose we measure the time between sightings of a raccoon in a Toronto neighborhood using six camera traps (strategically placed in the neighborhood). We do this for year, and want to ask if mean daily temperature predicts the frequency of raccoon occurrence.4. Suppose that, every year, we go to the Amazon and measure the number of bird calls that come from <span class="math inline">\(n=30\)</span> trees. Assume that the trees are far enough apart we can treat them as independent. We measure the number of birds in a tree, characteristics of the tree (cover, height, width, age), the year in which a measurement was done, and the mean temperature that year. We want to know if tree cover affects the frequency of bird calls, and if it interacts with temperature.For more on the difference between fixed and random effects, check out the following resources- <a href="https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-in-mixed-effect-model">this Cross Validated post</a>- <a href="https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/">this Dynamic Ecology post</a>- <a href="https://bookdown.org/steve_midway/DAR/random-effects.html">this book chapter</a>#### Using <code>lme4</code> to fit random and mixed effect modelsWe will start by fitting a model of log body size on log length where the intercept is random depending on the Order. Based on a quick visualization of the data, such a model may be appropriate.<code>{r}ggplot(data = mammal_long, aes(y = log(mass),                                x = log(length)                               )       ) +     geom_point(aes(color = Order), size = 3) -&gt; pp ``````{r, include=F}# no Order-dependence:p + geom_smooth(method = "lm")# intercept AND slope fixed and specific to the Order:p + geom_smooth(method = "lm") + facet_wrap(~Order)</code>To fit regress the response on a set of fixed effects with random <em>intercepts</em> that depends the values assumed by a random effect <code>x</code>, we call <code>lmer</code> and write a linear model with <code>(1|x)</code>.<code>{r}## random intercept for Ordermodel &lt;- lmer(formula = log(mass) ~ log(length) + (1|Order), data = mammal_long)summary(model)fixef(model)ranef(model)</code>From top to bottom, the output is telling us that the model was fit using a method called REML (restricted maximum likelihood). It returns information about the residuals, random effects, and fixed effects. The output also tells us about the <strong>estimated variance for the random effects</strong> in the model. Here, the variance associated with Order is 4.256. The variance explained by Order is 4.256/(4.256+0.847) <em>after controlling for the fixed effects</em>. Note the denominator here is the total variance, including from the residuals. As usual, we also have information about the fixed effects.To visualize the model, we can predict the overall and Order-specific relationship of log mass on log length for all of the Orders represented in the data.<code>{r}mammal_long |&gt; ungroup() |&gt; select(mass, length, Order) |&gt;   mutate(fit.m = predict(model, re.form = NA), # does not include random effects         fit.c = predict(model, re.form = NULL) # includes random effects         ) -&gt;  predicted_valuespredicted_values |&gt;  ggplot(aes(x = log(length), y = log(mass), color = Order)) +  geom_point(size = 3) +  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = "black", size = 2)</code>The thick black line corresponds to the fitted values associated with the fixed-effect component of the model. The colored lines correspond to the fitted values estimated for each Order. Perhaps a model with Order-specific random intercepts AND slopes would be better. We fit this model using the code below. The key difference in syntax is that we write <code>(1+fixed effect|random effect)</code> to indicate that the random effect has an effect on both the intercept <em>and</em> slope of the response on the fixed effect.<code>{r}## random intercept and slope for Ordermodel2 &lt;- lmer(formula = log(mass) ~ log(length) + (1+log(length)|Order), data = mammal_long)summary(model2)fixef(model2)ranef(model2)``````{r}mammal_long |&gt; ungroup() |&gt; select(mass, length, Order) |&gt;   mutate(fit.m = predict(model2, re.form = NA),         fit.c = predict(model2, re.form = NULL)         ) -&gt;  predicted_valuespredicted_values |&gt;  ggplot(aes(x = log(length), y = log(mass), color = Order)) +  geom_point(size = 3) +  geom_line(inherit.aes = F, aes(x = log(length), y = fit.c, color = Order), size = 1) +  geom_line(inherit.aes = F, aes(x = log(length), y = fit.m), color = "black", size = 2)</code>Why does this look like a mess? As stated above, <strong>mixed models do not work well when datasets are unbalanced.</strong> Indeed, the number of observations in the different Orders are quite variable.#### ChallengeRegress log body size on sex with Order as a random effect that affects the intercept AND slope of the sex-size relationship.<code>{r, include=F}Model &lt;- lmer(log(mass) ~ sex + (1+sex|Order), mammal_long)mammal_long |&gt; ungroup() |&gt; select(Scientific_Name, mass, sex, Order) |&gt;   mutate(fit.m = predict(Model, re.form = NA),         fit.c = predict(Model, re.form = NULL)         ) -&gt;  predicted_valuespredicted_values |&gt;  ggplot(aes(x = sex, y = log(mass))) +  geom_line(aes(group = Scientific_Name), color = "lightgrey") +  geom_point(color = "lightgrey", size = 2) +  geom_point(inherit.aes = F, aes(x = sex, y = fit.c, color = Order), size = 3) +  geom_line(inherit.aes = F, aes(x = sex, y = fit.c, color = Order, group = Order), size = 2) +  geom_point(inherit.aes = F, aes(x = sex, y = fit.m), color = "black", size = 3) +  geom_line(inherit.aes = F, aes(x = sex, y = fit.m, group = ""), color = "black", size = 3) +  theme_classic()</code> <i class="bi bi-arrow-right-short"></i>
      
  </div>
</nav>
</div> <!-- /content -->




</body></html>